【生成式 AI】07.檢索增強生成(RAG)的原理及實作 - 逐字稿 (第一部分)

時間範圍： 00:00:00 - 00:40:53
講者： 蔡炎龍老師 (政大應用數學系)

[00:00:00] RAG 的介紹與重要性

大家好。我們今天要介紹一個很酷炫的東西，就是我們學生成式 AI 一定要知道的事情。至少我們在外面聽到很多人在談論時，一定會偷說到，簡單的說你今天到外面，如果你今天去應徵一個工作，然後你跟他說你會生成式 AI，他一定會問你的問題，就是你能不得不做 RAG (Retrieval-Augmented Generation)。好，就這樣子。所以我們今天就要介紹大家這個酷炫的技術，也是大家一定要知道的一個技術叫做 RAG。

RAG 簡單的說要做的目標就是，因為我們知道生成式的原理，現在大家都已經知道天生就是「唬爛王」。那本來訓練就是唬爛王，不要想說他會答什麼正確答案，他就是後面接那個字順，他就接下去了。好，那會產生的影響當然就是他會唬爛，那我們很多的時候都不太希望他會唬爛。

比方說我們今天會舉一個例子，例如說我們今天會用一個學校裡面的規定。例如說你今天很想要——不知道不管什麼原因——就很想要希望說能夠在學校裡面被記很多功或是很多的嘉獎等等，那你就會需要......我們就可以放進去那個政大（對政大同學來說當然就放進政大的獎懲的一些規定規範）。好，然後你就可以問 ChatGPT 或是任何的語言模型說：「這個我如果做了這件事情，我會不會有機會被記嘉獎或者小功啦？」或者等等這樣子。好，就可以問他這類似這樣問題。或是相反的比較悲傷的說：「我不小心做了這件事情，我會不會被記過？」好，再等等也可以問他。

那當然這樣的情境之下，那對政大的同學來說，你就希望他回應的時候是看著政大的規定回應的，而不是自己幻想出來的。因為他可能今天說我是政大的學生，然後我做了一件什麼什麼樣的事情，不知道這樣的事情我有沒有機會被嘉獎？那他都會開始胡說八道一陣，那他會不管他說會還是不會，可能都跟現實是不一樣的。好，所以今天我們就希望說，可不可以要求他就是依照我們給他的資料來回應這些事情。好，這個技術就是叫做 RAG。我們今天就要來看說這個 RAG 到底是怎麼做到的。它就是現在可以說是最有名的減少幻覺的方式，所以非常非常的重要。

[00:03:00] AI Agent 與 Prompt 的概念

好，那我們再一次回憶這個 Prompt 要做的時候，它其實只有兩個原則。第一個原則就是我們需要給他足夠多的資訊，這是第一件事情。因為他就是看我們的那些前面的字，然後去預測下一個字應該放什麼字是合理的。你既然要他能夠回應正確的資訊，那前面一定要給他正確的資訊，就這樣。然後第二件事情，要很清楚的告訴他，你希望他要做什麼。

那我們從今天開始到之後有一個很重要的一個概念叫做 AI Agent。從現在開始，其實 RAG 就是某種的 AI Agent。AI Agent 的最簡單的說法其實就是：我們本來是要人工幫他做到更好的，可不可能由這個電腦自己去做？那比方說我們本來提供正確的資訊，我們要提供給他，那像是剛剛舉的例子，我們要做一件......我們想要知道說我們做了一件會不會被處分或是會不會被嘉獎。那這件事情我們當然需要有一個正確的規定。

那或是說未來到公司裡面，我們想要知道這個請假的規則，那我做了多久之後，我到底有多少天的假可以休等等的。那我當然輸入就是需要是我們公司裡面的規定。好，但是我今天就是不太清楚我們自己的規定，所以有沒有可能讓他自己......我就提供給他這個完整的規定，那完整的規定可能很長，那我可不可以讓 AI 自己幫我去找出那個相關的規定來這樣子。好，所以要做的事情就是這樣。

所以我們一樣就是我們需要提供的 Prompt，但是這個 Prompt 可不可以電腦自己去找？然後找到了以後放到我們的 Prompt 裡，就把正確的資料放上去，然後我們再指引他、引導他說他應該要怎麼樣的回應。這個基本上就是 RAG 的系統。

[00:05:00] RAG 的運作原理：切塊與 Embedding

好，那 RAG 這個系統，這件事情我們已經說過了，這非常非常的重要。你去查 Google 一下 RAG 的話，你會發現哦，這個搜尋太多了（這還是一陣子之前查的，現在查可能就更多了）。你會發現說，而且不只是科技相關的媒體，那幾乎所有的媒體都可能去報 RAG 這件事情，因為他真的是現在一個非常重要的技術。再說一次，他簡單的說就是：他可以根據我們希望他要依循的那些正確的資訊，然後去回答問題。就是這樣子。那很多人就說是避免他產生幻覺，就是他不會自己......他要先搜尋了以後，他才會做回答。

好，那 RAG 要怎麼做呢？其實也非常非常的簡單，它原理也很簡單。就是今天呢，我們先把文字切成一塊一塊的——說文件有點大了，因為等一下我們會說到這個有很多要考量的事情——就是把一段一段的文字切成文字塊。一塊一塊的文字，然後呢，我們找一個語言模型，然後找到它最適合代表它的特徵代表向量，也就是 Embedding。Embedding 就是特徵代表向量，然後這個特徵代表向量就代表那個文字的語意。

那你當然、我們當然有時候會覺得這個好神奇哦，他怎麼知道怎麼樣找特徵代表？現在大家應該已經有經驗，反正我們就是去訓練，覺得他需要懂他的語意的話，他才能達成的任務的話，那那個中間的某一個隱藏層的輸出，我們就可以（當作 Embedding）。

好，就這樣。總而言之、言而總之呢，他就會找一個語言模型去做這樣的事。我可不可以找大型語言模型去做這樣的事？也可以，但是有點浪費，有點殺雞用牛刀。因為大型模型通常都是比較大，這大很多啦，現在都是幾十億、百億個參數，太大了。那我們只是要做一個特徵代表向量，那個不用那麼大。好，所以我們就是找一個專門、特別是通常都是專門做 Embedding 的模型。那訓練的時候就是看各家的想法，總而言之、言而總之，大家都知道我們做這個 Embedding 的目標就是希望能讓我們把每一段文字都找到一個很好的特徵代表向量。

那我們就會把這個向量資料庫存起來。那之後我們如果人家使用者有問題的話，我們就會比對看哪一個特徵代表向量是最近的就好了。好，就這樣子。所以我就會把文字先切一塊一塊的，然後就去找它的特徵代表向量。好，然後比方說這文件一，它的特徵代表向量叫 K1，就是一個向量。當然不會只有三個數字（三維）那麼小，看它的切的通常是什麼 512 或者 768 之類這種數字。好，就是切成一段一段的，然後它會有它自己的特徵代表向量。

[00:08:36] 準備資料與文件上傳

好，那大家會有一個小問題：那我文字、我這些檔案要怎麼準備給他？哦，這有一個非常好的消息，就是我們的示範的程式碼已經幫大家寫好了。所以大家需要做的事情呢，就是建一個資料夾。我們有預設這個資料夾的名字叫做什麼？loaded_documents，就是上傳的文件。你也可以取一個比較像樣的檔名。總而言之你就建一個資料夾，然後我們這個資料夾裡面呢，你就把所有的你覺得相關的文件全部丟進去。可以丟很多個，它可以是純文字檔，它可以是 PDF 檔，它可以是 Word 檔都可以。也就是說幾乎你想像得到的檔案你都可以丟進去。就這樣，就這麼簡單。

所以你回家的作業其實就是做這件事情。就是你今天心中有一個想法說，我想要做一件事情，但是他不能亂說，所以我需要把那個相關的資料全部丟給他，然後他就依這些相關的資料，然後能夠回答我的問題。然後我回答問題需要根據裡面的資訊回答它，就是這樣子。

[00:09:55] RAG 的細節考量：Chunk Size 與 Overlap

好，這就我們要做的事情。然後另外一個要考量的事情就是我們的文字塊到底要切多大？就是文字塊切的比較大——當然這個是很直覺的想法——文字塊切比較大，你就會發現說這個很細微的那些意思可能比較不見；但文字塊切太小的話，你有時候也會發現說這個文字塊實在切的太小了，這整個陳述都還沒有完整，你就把它切下來了。所以這個文字塊要切多大這件事情，其實也是要考慮的事情。不過先開始的時候先不要管那麼多啦，反正今天的目標呢，就是你也不用管太多事情，反正這個先能夠做出來再說。

好，那能夠做出來的時候，你就會有成就感。然後你就會開始想，這個為什麼我的跑的沒有旁邊同學跑的好？像他跑得比較好，我們明明做很類似的問題，為什麼他跑比較好？就是文字塊的大小要考慮。

第二件事情呢，就是可能需要有重疊的字（Overlap）。重疊的部分因為呢，這個就是切的時候，它搞不好剛剛好斷在一個很奇怪的地方。那如果沒有上下文的話，我們這個不太能夠知道它的意思是什麼。所以有時候在切文字塊的時候，我們需要考慮它有重疊。但這都小事，也不能說是小事，這個皆都是你在做了之後，你就慢慢會體會到說的確需要考量這些事情。但是在開始的時候，我們不要那麼緊張，反正就是切了一段一塊一塊的文字，然後就丟進去餵它。好，然後它就會找到每一段文字的特徵代表向量，就這樣子。

[00:11:39] 檢索與回應流程

好，然後這使用者也有問題了，就用同樣的語言模型，它就會找到它的 Embedding，就它的特徵代表向量。也就是這個問題的意涵，只是它是抽象的意涵，我們拿出來了以後，我們完全不知道他到底在想什麼，就抽象的意涵。這樣可以？就這樣子。所以他就做出了這樣的事情，然後我們就可以做......然後我們要做的事情就是開始去比對文件。

好，比對文件的時候呢，它就會開始就是比對文件。也就是找這一個向量——就是問題的這個向量，就是 Q 啦，就是我們上次那個 Q、K、V 很熟悉的——就去跟每一個、每一個剛剛的那個向量資料庫裡面的每一個向量去做比對。看它跟誰最接近。那最接近有很多種看法，比方說什麼 Cosine Similarity 或其他的方式，反正總而言之、言而總之就是看兩個向量中間的距離，你覺得哪一個比較合理，你就用哪一個就好。

好，所以就是看那個兩個向量中間的距離。它就會發現說，哦，我跟 K2 這個向量可能最接近。意思就是說我這個問題可能跟 K2 它是最近的向量。那這時呢，我們就會把 K2 這一段文字找出來。可以嗎？就是我現在就會把 K2 這段文字找出來。意思就是說我現在有兩個文字型的資訊：第一個 Question 就是原來使用者問的問題，就是使用者下的 Prompt，這是他原來的問題，所以它是一段文字的資訊；第二個呢，我們根據那個相近的向量，就相近的文字呢，它就把它找出來，所以我們就可以找出來這個搜尋出來的資訊。

好，所以這兩段都是文字。那於是呢，我們就可以開始設計一下我們的 Prompt，最終的 Prompt。這個 Prompt 呢，就可能通常可能會長類似這樣子（我們今天做例子的時候大家也會發現，那你回去的時候你去想看，你就會知道說那你應該要怎麼放進去）：就是我們現在有一個比較動態的 Prompt，這個動態的 Prompt 裡面呢，上面的一邊就是找出來的資訊，那我們就說「請根據這些找出來（請前面就是實際找出來的找到的文字的資訊），然後回答使用者的問題」，就這樣子。然後他當然因為現在就有自動、他自動幫我們搜出來的資訊，那他就根據這個資訊回答，所以他當然會回答比較好。就是這樣子。因為再一次，他就是把這些 Prompt 已經放在裡面了，他已經把這些資訊放在裡面，你後面接的字要順，你總不能跟前面是相反的，或是意思是不一樣的，那聽起來就怪怪的。就是這樣子。

[00:14:26] 流程總結與向量資料庫

好，好，所以大致的情景就是這樣子。那你在外面會看到很多這個 RAG 的畫出來的圖，其實這個不太需要管它。你就想清楚了以後，你就會發現就是這樣子：
就是首先呢，我們會先找一個叫做 Embedding 的 Model（我們在這裡寫成是 f embedding model）。大家有看見，Embedding Model 就是 f 這個 Embedding Model。然後呢，這個時候呢，就是把我們的文章切成一塊一塊一塊的，然後經過這個 Embedding Model，那就會產生變成一個向量，一個一個一個的向量。好，這個一個一個向量我們就會把它存成一個資料庫。就是它就是固定的，它只要算一次。所以呢，這邊 RAG 的重點就是一開始的時候，我們就要把所有我們的資訊都把它換成向量，一堆的向量。那這堆的向量當然就是不要動了，就存起來。不用每一次我要做一次 RAG 我就再一次再算一次。沒有，除非我有更新資料，不然的話這個向量資料庫永遠就是不動的。

然後第二件事情呢，就是我們的語言模型。我們在這邊寫成......對不起，還是 Embedding Model。這兩個通常是一樣的，就是 f 這兩個通常是一樣的。我們當然也可以在很特殊的情況也可以找不一樣，在一般正常的心理狀態下，我們都是找一樣的。好，我們都是找一樣的。這邊還是一個 Embedding Model，還是一個還是剛剛的 Embedding Model。就是我 Prompt 來了以後就經過這個 Embedding Model，然後呢，我就去就會產生一個向量。我就再比對說這跟原來的這個資料庫裡面（就是它的 Database 裡面）那個到底有沒有什麼哪一個是最接近的。哪一個最近的我就把它抽出來，就放在這邊，然後就放到這個新的 Prompt 裡面。那還有這個舊的 Prompt 就是它的問題，然後就把這兩個結合放進去這個大型語言模型。那我們就下一個 Prompt 說：「參考這個找到的資料，然後去回答原來使用者的問題。」然後這個時候就會做出來回應。

那在這個回應當中，因為我們原來的 Prompt 就有問題，那我們的 System 也可以很清楚的指引他應該要怎麼樣的回應問題。然後再來就是我們就會根據這個剛找出來的資料、正確的資訊，然後丟給他，然後他就會回應問題，而且是回應是正確的。這樣子就是一切都、一切都是在這個完美的執行狀態之下，它就會回應正確的問題。大家可以試試看。

[00:16:53] RAG 的進階考量 (Advanced RAG)

然後試完了以後，大家當然會發現一些問題。但是我覺得有很多的細節，我們不用講得太清楚。然後我馬上就要打臉自己，因為我馬上就要跟大家講說 RAG 會碰到的一些基本的狀況。那我剛剛說那一段話意思是說，如果這一段沒有很明白，那是因為我們還沒有做過第一次。沒有做過第一次的時候，有時候我們真的會覺得說這個幹嘛這個這些比較細節的東西到底在說什麼比較不能理解。但先聽一下說這個稍微就是我們要注意的地方啦。

你在做作業的時候碰到了一些狀況問題的時候，你也可以去想是不是有可能我需要去調整這些東西。但是呢，因為我們這個本來就是快樂型的課程，所以呢，如果你沒有要想，你暫時沒有要想，你先要看到有成果也沒有問題。這個要有成果非常的容易，就勇敢的去嘗試，你一定會、你一定會做出一個讓你覺得很有成就感的。就是你也會感覺你已經會 RAG。

好，第一件事情要考量的就是剛剛我們有說過這個「切法」的考量。就是你到底要切多少字是一段？這件事情是蠻重要的事情。好，這個你倒是也可以問 ChatGPT 如果說到底要切多少段，我可能是比較適合的切法吧。但他說的當然不一定是準確的。就是再一次，就是很直覺的就是如果切的文字比較長，他有可能把那個意思會稀釋在這個茫茫大海之中，所以你找出來的最接近的可能不一定是最接近。好，然後那但是你切得太短，又可能沒有辦法完整的表達那個意思。所以這個文字是需要我們去拿捏。

然後第二個我們「重疊的字」到底要多大？就是一段跟文字跟另一段文字到底要多少的重疊。然後或是說呢，我們的切法到底要不要同一章、同一篇，就是不能跨文章切啦。那這個就是我們需要稍微的做一些......寫一些基本的程式。也就是說這篇文章跟下一篇文章那個段落不能......因為我們可能是 500 字或是 1000 字好。比方是 1000 字，1000 字切那總會這一篇文章切完了，我可能就切到下一篇文章去了。對於一本書的時候，我可能會覺得這比較沒有關係，反正就切到下一個段落去，沒有關係。但是對律書有可能我們也不希望這樣子。那或是如果是都是一篇一篇獨立的文章，我們更不希望這樣子，就是這一篇會切到別的文章去。所以我們可能會需要做這樣的考量。

然後有時候有一些法規法條，我們可能會考慮是不是要一條一條的切，免得它那個每一次切的沒有完整這樣子，或是每一次切可能切到下一條法條去了，這樣就等等等。我們要考慮的事情很多。但是我再說一次，我們第一次的作業，你也可以不用考慮這麼多，你先做出來了以後，覺得很有成就感，很高興你中真的做出來這看起來、聽起來好像很高級的 RAG 之後呢，然後你再去考慮這件事情。就是你覺得說這個好像成果沒有這麼好，那我是不是可以做一些調整再去考慮這件事情。好，先做出來再說。

好，這個第一件事情。第二件事情呢，這個你真的找到了這一段文字的時候，有很多種的考量。第一件事情呢，我是不是要把「上下文」也一起丟進去好像比較合理？就是這段文字雖然是最相關的文字，但是我可能應該要考慮前文啊、後文啊，應該要都要考慮。這個其實都是很自然，你認真想的話就是這一段我們其實好像也不用說，因為你在做那個之後，你就會自然而然的發現說你真的要考慮的事情比較多。那我們現在只是讓大家知道說真的會有很多要考慮的事情。不是 RAG 不是說我今天有一個自動化的 RAG 系統，我想再按一個鈕，全部就幫我把 RAG 做好了，那通常是需要做調整的。

那第二件事情呢，有可能我們找出來一段文字的時候，我就要把那個原來的整篇文章一起把它給他丟進去。這當然聽起來很有道理嘛。第三種是個聽起來更厲害，就是我今天的找出來文字，我應該要把相關的文章一起把它丟進來，就這樣。

那當然大家就會問：那到底什麼是相關的文章？這就有很多種做法，這個比方說 Graph RAG。就基本上我們想要做這件事情，就是我們一開始的時候先算好文章跟文章中間的關聯性，就用其實是用任何你高興的演算法都可以啦。你當然也可以直接算他們相近的程度等等或是說其他的分類。然後總而言之、言而總之呢，你會定義好這個文章跟文章中間的關聯性，你就把比較相關的文章全部一起找進來，為了要萬無一失。好，所以有很多種的做法。

[00:22:40] Re-ranking (重新排序)

那這些做法在你真的去做 RAG 之後，你就會發現這個很自然嘛，就應該要做這樣的考量。我再強調一次，我們在開始的時候你不要想太多，反正就做那個最傻瓜版的 RAG。那只是說......只是說要讓大家知道說這個我這個為什麼在外面聽說這個會做 RAG 好像薪水也還蠻好的，這個是大家都會覺得好像很不錯、好像很厲害。但有什麼難的哦？就是這邊要跟大家講的，其實要考量的事情還是很多。但這些考量的事情也不用太緊張，因為它通常都是很自然的就應該要考量的事情。

好，然後再來呢，就是呢，這個也是這個所有的推薦系統裡面......因為這個 RAG 很有趣，就會找出來、搜尋出來，其實通常是不止一篇文章。特別是你的資料庫很大的時候，這個那我們可能有時候會設定說我的某一個門檻值，然後說這個過這個門檻，我就覺得都是相關的。你就會發現這個真的很......那我當然也可以找那個最高分的前三名。但這個通常、通常、通常，因為在做 RAG 的時候，畢竟他是看比較大的範圍的一段，就是所以它的評分也是根據比較大範圍的評分，覺得說這跟我們的搜尋的那個問題是很接近的。

但是呢，這個真的是不是最接近的？其實不一定。那也許進來了以後，我們要再做更細的看說到底誰是比較真的最接近的，誰是第二名，誰是第三名。也就是我們這個排序有可能要重新排。那這個重新排的方法就看我們高興，我們覺得應該要怎麼重新排都可以。好，就是這樣子。所以這個還有一個高級的技術叫做——沒有高級啊，就是學名（不是學名）就是專門、專門的術語叫 Re-ranking。所以在人家問到你 RAG 的時候，你就可以開始大方跟他這樣講，他就一定覺得你真的是專家。即使你沒有做過 Re-ranking，你也要知道為什麼要做 Re-ranking 這件事情。那你知就會發現說這個真的是很自然的事情。

[00:24:08] Metadata (元資料) 的應用

好，然後呢，最後呢，RAG 呢，通常還有一個跟那個原來的向量資料庫基本上是沒有什麼關係的，這種就是附加的資訊，這種叫 Metadata。很多的文字裡面，比方說網頁裡面也會有 Metadata，就是跟去描述這個網頁到底是什麼網頁啦，然後作者是誰等等的。RAG 也是每一個文字塊你都可以加入 Metadata。這個在高階應用，我們今天的我們的範例裡面並沒有加 Metadata，那你的作業也不用不用加。那但是呢對於這個本來就很會寫程式的那個，非常鼓勵大家，如果你想要加這個真的很鼓勵，你就把它加進去，因為這個真的會有幫助。

Metadata 到底是記什麼呢？比方說呢，記得這篇文章——就這一段文字到底是從哪一篇文章來的。就是可能就是每一篇文章我們都給他一個 ID，然後呢，那我就告訴他說 Metadata 的第一件事情就是告訴他說這就是要知道說這一小段文字到底是在哪一篇大文字裡面來的，我要知道那個文章的 ID。那所以我一找出來的時候，有可能剛剛說我們有可能是要把整篇文章放進去嘛，那我就把整篇都要找出來，就是這樣。那我只要看到他 ID 我就知道他文章在哪裡。

那或者說他是一本書的時候，有可能我們需要記得它的頁數是什麼。因為我們在跟那個使用者說的時候，搞不好我們今天是要做一個「可愛小老師」AI。那這個小老師呢，今天呢問他的學生問就問了一個問題啊，那你當然就會回答你。那因為我們做了這個 RAG 之後，他可能就會根據課本的內容去回答他。所以那個沒問題，所以他比較不會說這個課本是這樣說的，結果你自己天馬行空的說法是不一樣的說法，這樣子比較不會出現這樣的問題。但是呢，為了要取信於同學，你可能有時候或是要指導他、指引他去再讀那一段，所以你可能要告訴他在文章的哪一頁有這些資料。就這樣子。所以他就是呢，他就會告訴他說：「哎，這個其實在文章的哪一頁你可以去讀一下這樣子。」

好，然後或是說呢，這個文章的標題啦，或是作者啦，或是日期或是分類單等等。你覺得你會用到的任何的資訊都可以把它放到 Metadata，就是幫助你更能夠把應該要有的資訊放進來的，你就可以把它放到 Metadata。Metadata 完全是自己做的，每個人在做的時候，它 Metadata 是不樣的，所以這完全是自己做的，就你愛放什麼就放什麼。

那需要 Metadata 的例子，我跟大家講一下。就比方說你今天想要知道什麼是 Agent，但是你要特別的跟他提醒說不要管：如果那一段文字是「炎龍老師」說的，你就不要管他，因為你都覺得他亂講。好，就這樣子。好，比方說這樣。那所以說你的那套 Data 可能有作者，那作者就是只要是炎龍老師，你全部把它砍掉。這在原來的那個 RAG 並不容易做到這件事情，這並不容易做到。即使你跟他說「只要是炎龍老師說的文章，你都我們都不要管」，不太容易做到這件事。因為他都是用「語意」去看的，他可能只會看到什麼 AI Agent 啦，那他不會......他不是真的這個寫一個程式做條件判斷說出現炎龍老師我就不要了，要這樣子。他不是真的這樣做的。所以說那個他很有可能搜尋出來，很多都是炎龍老師說的這樣。好，那但是那是你不要的。

那包括這樣類似這樣的例子，比方說今天就是要看某一隊的——就是中華職棒某一隊的那個戰績、某一段等等等等等。那你不是要問中華職棒所有的球隊的情況，你只是要問某一隊的。那所以在那個 Metadata 裡面就可以設定這個是哪一隊的資訊，哪一隊的資訊這樣子，之類之類的。所以說呢在在那個我們搜尋出來正確資訊的時候，有 Metadata 其實有很多很多的幫助。

我要再強調一件事情，就是這些在你做 RAG 做久了之後，你就會發現這些都是正常的，你會想到需要考慮的。但是對於我們第一次做的時候，我可以不要管他，先亂做，先做出一個亂做版本的 RAG。我們的作業要求只有亂做版本，就是你真的可以做出來，然後真的可以動，這個你就會很有成就感。你先不要管那麼多的細節。然後但是你就記得說這個其實我們在考慮的時候應該要考慮一些細節，就實際上去做的。比方說你去公司實習說我們今天要做一個生成式 AI 專案，你就知道說你可能會需要考慮的細節還蠻多的，包括你 Prompt 是怎麼寫的，這個也是要考慮的。

[00:29:25] 長上下文 (Long Context) 與 RAG 的競爭

好，前面就是把 RAG 我們大概的介紹完畢了。然後現在後面要說一個悲傷的事情。不什麼叫悲傷的事情？就是呢最近，特別是最近你會聽到很多人開始覺得「我們真的要做 RAG 嗎？」。因為語言模型這個......因為我們前面介紹過 Transformer 就知道說它輸入的時候，比方說在 GPT 剛剛開始可能是 2048 啦，就是輸入的字都、它的模型的大小可能是 2048 可以當輸入。那它扣掉它的這需要的一些做 Token 的那些，它可能再扣掉幾個字。所以但不不管怎麼樣就是 2000 多個字，你可以輸入 2000 多個字。

但如果你有這一直持續的注意的話，你會發現語言模型可以輸入的上下文越來越長。有時候甚至到上萬字、上千字（不對，本來就上千字）、上萬字，然後甚至更多，十萬字、100 萬字。你可以去注意他們的規格，你會發現它輸入越來越......這個其實也是另外一個有趣的主題。它並不是真正的把它的 Transformer 的模型做很大，讓它可以就是一次輸入例如兩萬字。它通常不是這樣，不然的話因為這樣的做的話，真的會耗掉太多的資源，這可能很難。然後但是呢，大家就會想說那我還是希望他把所有的上下文看完，有沒有可能、有沒有機會可以讓他本來輸入的其實只有還是 2000 多個字，但是可以讓他擴充？好，所以有很多的技術在討論這件事情。這不是我們課程的範圍啊，這個但是如果有興趣的，所以很多技術可以去讓我們的上下文可以擴充的越來越長。甚至 Model 一直覺得他有可能會做出他有能力、應該未來有希望做出上下文是無限制的，就是你要多長的上下文都可以，你要 Prompt 要放多少字都可以。

好，然後但當然大家就會有一個問題：那這跟我們家這個 RAG 到底有啥關係啊？這個有關係就是呢，我們剛剛說我們為什麼要做 RAG？其實一個很重要的原因就是因為我們為什麼要把那個上下文......乾脆我們把所有的資料全部放進去？就是因為我們上下文......因為我們資料可能很多啊。就是我今天想要做我們公司裡面的一個什麼可以回答任何關於我們公司的（對，沒錯）。那公司的資訊其實很多啊，包括我們公司的到底怎麼成立、公司的歷史啊，那公司的那個規定啦，公司什麼什麼所有相關的那應該非常非常的多，甚至每一年的、每一年的營運的狀況或者每一年推出的新的產品等等等等等等。

那所以我們今天就要把它塞進到那個所有的東西，我們當然本來可以塞進到 Prompt 裡面去。但是它可能太多了。那比方說這個樣的字數可能在過去的語言模型可能只能讀 2000 多個字的語言模型裡面，那但是我們很容易那個規定就上萬字了，那這樣子我們就塞不進去。或是我們的法規可能就上萬字了，塞不進去。

那可是現在的語言模型，因為上下文越來越長，再加上剛剛說的 Model 一直覺得說他們有總有一天會有辦法做出「無限制上下文」的語言模型出來。然後在這樣的情境之下呢，那我們為什麼不把所有的文字直接丟進去呢？那樣會不會比較好？當然比較好啊。因為因為因為他就根據前面的那一大段的字，然後他已經把所有他應該知道的全部說完了，然後他就說根據上面的資訊你要回應這個問題。那他當然就會去根據上面的資訊要回應的順，他總不會我們規定是這樣，然後他就唱反調偏偏不跟你這樣講。那不當不會這樣，這樣就不順了。所以在這樣的情景之下，他就會非常完美的回應你的問題。

就這樣子好。所以就是全部放進去，不就結了？然後全部放進去到底有什麼樣子的問題所在？就是因為語言模型的文字越來越長了，所以呢那個全部放進去，那它跟 RAG 比較哪一個效果會比較好？答案就是全部放進去效果比較好。這是當然的。因為 RAG 可能會找錯，我們剛剛說過了，你根據你切的方法對種的考量，對，RAG 搞不好會找錯。RAG 的好處就是說那個再大也沒有什麼問題，因為反正它就向量資料庫存起來，那它只是要比對的向量比較多，那也沒有什麼問題。反正就比對出來，它就可以把那個那一段文字找出來。所以再大的資料庫都可以做 RAG 基本上啦。當然跑起來的時間有時候太多的資料，它為了要比對比較多，它可能還是會比較慢，這是當然的。但是理論上這個所有再大再多的資料它都可以做 RAG。

但是呢、但是呢，那個上下文全部放進去，雖然這效果會比較好，可是你每一次你就會發現說你的語言模型每一次要執行的時候，因為你可能把這些資訊都放在 System Prompt 裡面，你每一次語言模型在執行的時候，他對要從頭讀到尾。就是第一個人來問題的時候，你就把它從頭讀到尾一次；第二個人來問，他認定又從頭讀到尾一次。如果那個文件真的很長的話，那特別是你的 Token 需要花錢（其實你 Token 不管怎麼樣都要花錢），因為可能我們是在自己家裡的——不是不自己家裡——自己公司裡面的這個本地端的 Server 裡面去跑這個語言模型。但是問題還是一樣，就是他每一次都要從頭跑到尾。第一個是客戶可能會等得很不耐煩；第二件事情呢，就是他每一次都要耗掉這個運算的資源耗一次。就這樣子。所以就會發現說這件事情雖然理論上好像比較好，但實際上做起來好像很不合經濟效益。

因此大家就發現了一件事情。這是大家發現一件事情之前，我們先來介紹一下。那比方說現在就可以看到說越來越多的、越來越多的那個語言模型......但你大家之後也可以去看一下下說哪一些語言模型有這樣的特色。第一個呢，我們為了要做 RAG（那也可以不做 RAG 嘛），所以我們有沒有可能就是找一個那個上下玩比較長的文語言模型？你就可去看，就大家會越來越看、會越來越會看那個語言模型，我到底要看什麼？就是上下文。

比方說那個 Llama 4 的時候，他剛出來的時候有一個最受到注目的點有兩件事情：一個是呢，他居然可以看到上下文超過 1 千萬，超級長的上下文。第二個它是所謂的 Multimodal 多模態，也就是說他看得懂圖。但是現在看得懂圖的越來越多了，所以也不是什麼特別了不起的。現在說起來也不是什麼特別了不起，就看得懂圖的就是語言模型那個你也可以把那個圖輸進去。簡單的說就是這樣。好，然後呢，那他其他有很多的其他的一些特色，雖然他也被攻擊的很厲害，因為他出來以後大家都覺得他好像還沒有完全準備好就出來，但是至少提供給我們的是他有看可以看圖的，然後又有上下文超級長的。

所以上下文超級長的對於做 RAG 這件事（不是，對於我們想要去參考的時候）其實很有幫助。就是有可能我們完全不用做 RAG，把它全部放在 Prompt 裡面就好了。

[00:37:16] KV Cache 與 CAG (Cache-Augmented Generation)

但是全部放在 Prompt 又有一個缺點哦，又有個缺點就是說呢，就是說呢我們今天呢這個每一次都要重新計算一次。所以有一個技術就是用 KV Cache (KVC)。就是我們在算 Transformer 的時候，如果我今天這些文字要算的時候，我每次 Transformer 裡面都會算出它的 K 值跟 V 值。事實上它會算出一個值啊，然後這就會產生 K 值跟 V 值。就這樣。

那我們可不可以把這些 K 值跟 V 值全部存起來？因為問題的時候是 Query 要進來，就是那個 Q 值是那個問問題的時候產生的，所以那個 Q 來不及產生。但是沒有關係，我們就把 K 值跟 V 值就是計算的、就我們把原來的那個資料、資料它的 K 值跟 V 值全部給它存起來，可以嗎？KV 值全部存起來，那也就 KV 值不用再算一次了。

那有一篇文章非常非常的有名，好，這個順便大家也可以去查一下 CAG (Cache-Augmented Generation)。因為這個 CAG 的這個這篇的 Paper 寫得非常的好，因為他一開頭就跟大家講說不用做 RAG 了，那就請大家都來用 CAG 這樣子。那那個 CAG 基本上就是把它的 K 值跟 V 值存起來。

那 CAG 跟我們的關聯性就跟我們政大的關聯性非常的強烈，就是主導的黃老師呢，就是主導的黃老師，他現在在中研院，但本來也是我們政大資科系的老師。那很多很多一起做的同學都是我們政大資科系的同學。那這個歡迎大家參考。那大家也可以看到說在網路上有很多很多地方在討論區，而且不只是台灣，在全世界有很多很多地方。

那我們再一次說明他的基本的精神：就是因為現在的語言模型，它可以看的文字越來越多了、越來越多了。然後呢，所以說呢他今天呢、他今天呢我們那個不用去做......應該第一個考量不是去做 RAG，是第一個考量是把那個 Prompt 把他全部塞、把那個文章全部塞進 Prompt 裡面。但是比較遺憾的是我們今天是一定要做 RAG，因為我們就是要練習 RAG，這大家至少要練一次嘛。那你當然你好奇的話，你也可以比較（特別是你的資料沒有那麼長），你也可以比較說：那我是用 RAG 的版本，還是我乾脆把所有的資料全部丟給它？比較一下這個效果。這個也很好，這也很好。但是你一定要做 RAG 版，因為我們一定要練一下、練一下。至少出去以後，我們人家要我們做說的話，我們說我們會做 RAG，人家覺得我們很厲害。然後當然更厲害的，我們可以跟他說：「哦，你們這麼這些資料這麼少，其實 RAG 做都不用做，我們可以直接把這些資料全部放到 Prompt 裡面去。」好，那你可實際的比較看看。好，如果你真的可以做這件事情，非常鼓勵大家試試看這件事情。

好，所以這篇文章就是 CAG 基本上就是要跟大家就是要用 KV Cache 的技術，就是原來的文本就不用每一次都讀，就是先把它算出來它的 K 值跟 V 值，然後就把它存起來。每一段的 K 值跟 V 值都存起來。當然 CAG 還有做其他的事情，所以所以它不並不止是做 KVC，還有做其他事情。但是目標就是希望大家可以讓我們不用再去做 RAG，然後可以簡單的說就是要把它全部丟給他，但是又要符合那個運算的經濟效益。

好，這個這一個是我們大概 RAG 裡面要講的話已經講完了。

【生成式 AI】07.檢索增強生成(RAG)的原理及實作 - 逐字稿 (第二部分)

時間範圍： 00:40:53 - 01:22:45
講者： 蔡炎龍老師 (政大應用數學系)

$$00:40:53$$

 RAG 的應用：對話機器人的長期記憶

RAG 其實還有一個非常常見的應用。大家在使用對話機器人（像 ChatGPT）時，會考慮到一件事情：如果你跟它一直聊天，總有一天那個字數會超過它可容納的範圍。因為我們知道聊天的下一句話要怎麼放進去，基本上就是把前面對話過程的文字放進去。

當然我們也知道，未來的模型可能容納字數真的很多的時候，我們就不用考慮這件事情，把所有過去的對話記錄全部放進去。它會鉅細靡遺地記得你跟它講的什麼事情，甚至十年後你問它十年前的事情，它都記得。這相當厲害，但現在畢竟還不行。

在這樣的情境之下，其中的一個做法就是做 RAG。就是把你的記憶去做 RAG。這裡有一個有趣的事情，RAG 我們也可以用不同的向量資料庫。因為它有可能只是想要知道你的過去的對話記錄裡面有談過的事情，所以那個記憶就放成一個向量資料庫。第二個資料庫就是放那些你覺得希望它......比方說這是一個公司內部的或是一個團體內部的對話機器人，所以第一個它要知道公司裡的資訊；第二個因為你跟它在對談，所以它需要知道你所有過去跟它對談的一些東西。

語言模型裡面大家會有一個記憶的裝置，那記憶的裝置其實分成所謂的「短期記憶」跟「長期記憶」。這跟我們人類有點像。短期記憶就是我們現在跟它在對談的，它當然一定會記得。那我們怎麼樣做長期記憶？其實其中一個方式就是做 RAG。就是把過去的對話記錄全部用 RAG 的技術把它存起來。其實要多長就可以多長，不管多長都可以存起來。

那他每一次對話的時候，他覺得需要去看一下過去的對話經驗。比方說提到兄弟姐妹，不管什麼原因，就是我今天提到了我自己的兄弟姐妹的時候，他就會去搜尋說過去有提到兄弟姐妹相關的資訊，他就會把它撈出來。所以你在跟他談的時候，你會發現他真的好厲害，他都記得我以前說的一些事情。

那一種方法就是做 RAG。這個是 RAG 的另外一個常見的應用。你當然可以變成說，你在做那個客服機器人的時候，你會讓客人覺得這個真的是非常貼心的機器人。比方說你每一次去都是買一個東西，那他可能會跟你講說：「啊，那個不好意思，這個是今天我們那個東西沒有了。」那當然他還可以推薦你去買一些其他的東西。所以有記憶的機器人的時候，你會感覺更貼心一點點，就是他過去跟你談的事情他全部都記得。其中一個技術就是用 RAG 去做的。

$$00:44:55$$

 RAG 的金融與其他領域應用

好，我們舉一些例子。剛剛介紹完 RAG 了以後，RAG 到底可以做什麼樣子的用？當然這是你愛做什麼就做什麼。

特別在金融領域裡面（當然這是以金融舉例子，不一定大家都是做金融方面的）：

客戶的服務與問答系統 (客服)： 這是大家非常想要做的事情。但是客服機器人老實說做 RAG 還是有一些風險，因為他有可能還是會答錯。

內部的知識管理： 這比較好一點，它跟客服機器人類似，就是「對內部的客服」。比方說我們就是公司裡面的人，但是我們對所有的規定可能沒有那麼清楚，或是碰到的狀況其實沒有那麼清楚說應該要怎麼處理，或是法規應該是什麼。那這個時候如果是對內部的就比較安心。原因是：我今天還是可以很快的......我自己不知道這東西，我就可以問他。然後但是因為我們是人，所以我們也可以去驗證到底是不是真的這樣子，我們也還可以做各種的驗證的方式去驗證他。所以就比較不怕萬一我們的 RAG 出了一些差錯的話，會發生什麼事。

教育與培訓： 因為我們剛剛已經說過了，我們的課程的教材就是這一個，你不要給我亂說。這個是天馬行空的說別人的理論或別人的方法，反正我就是要根據我的教材回應那個問題。

個人化的理財建議： 我們可以把所有公司有的產品資料把它放進去。所以在客戶在問問題的時候，他就根據他的需求來推薦他比較適合的產品。而且不會推薦到別的公司的產品，或是說根本沒有這個產品推薦一下，客戶說好急我要買，結果我們說不好意思我們發現我們沒有，這個不行。所以就是一定要推薦自己公司的產品。

投資研究報告生成： 投資研究報告很明顯就是需要非常非常多的資訊，然後這些資訊都是要真實的資訊，都不能唬爛出來。就是各個以前有的一些資訊、以前的報告或是一些相關的報表，都要把它丟進去。然後在做的時候，我們就要引導他說你應該是要去看什麼資訊，然後最後寫成一篇很好的報告出來。

反詐欺行為： 你可以協助去偵測。當然另外一個是你現在也很多人就是用 AI 來做詐欺。比較有趣的事情就是因為很多人現在開始用 AI 詐欺了，所以現在大家知道很多地方都有做資安的檢核。資安的檢核就是來一個釣魚的信件，如果你被騙了、被打開、真的打開了那個連結，你就是被釣到了，你就會被扣分。現在比較過分的是很多的公司開始用 AI 去寫這個釣魚的信件，完全客製化給你。根據你的特性、你會打開的東西，完全客製化給你，所以你就比以前更容易被打開。

金融法規的合規資訊： 就是合規這件事情。這當然就是非常適合做 RAG，因為我們可以把所有的法條、所有的規定全部把它丟進去。那今天在問問題的時候，我們就可以產生一個問題，然後去看說它是不是真的符合我們對這件事情的規定。這個是常常看到的，這不只在金融上面，這已經非常非常多的學長姐、只要做 AI 相關的，特別是生成式 AI 相關的，大概很多都有做過這個合規相關的一些問題。

財經新聞的輿情總結： 就是找出一些相關的新聞把它找出來。大家可能會有點小看這件事情，事實上這件事情非常的重要。我舉一個例子（不方便說哪一家公司），總而言之有一位我們政大畢業的學長，他就是在大老闆身旁。他每天有一個非常重要的任務就是看報紙。所以他會花很多的時間去看報紙，因為所有的——不現在當然可能不只報紙，連網路上重要的媒體上面發布的新聞他都要知道看。所以他的工作幾乎是他最重要的工作就看報紙，然後他需要篩選出來哪一些是重要的、要給大老闆或是各個主管看的新聞（就跟我們公司有關那個特別重要的）。不一定就是我們公司的事情，可能是跟公司有關或是我們需要注意到的國際情勢。反正所有的東西他就要把它列出來，他還要需要去做一些......那聽完了以後大家是不是覺得這個好像 AI 可以幫我們做？沒錯，所以很多公司會做這件事情。

股票投資與交易： 對於股票投資的公司呢，他們每一天都要看很多的新聞。但是因為新聞實在太多了，他們人真的很難看完，所以他就需要說能不能用 AI 來幫我們去做這件事情。然後找出一些比較重要的新聞，然後摘要給我們看。那真的重要的時候我們人再點繼續看說它這個細節發生了什麼事情。所以這件事情真的也是非常非常的重要。

$$00:53:16$$

 作業說明：打造自己的 RAG 系統

所以呢，我們就準備要開始打造我們真的要開始打造我們的 RAG 系統了。

那這個 RAG 系統呢，等一下我們會介紹這一個範例，大家就可以根據這個範例來改成你自己的作業。所以簡單的說，我們作業就會有兩個程式：

程式 A (建立向量資料庫)： 我們的頭放我們的資料進去，然後要建立起自己的向量資料庫。我們會給一個非常簡單、沒什麼水準的例子。意思就是說大家隨便做都會超越我們上課的例子，這個其實就是我們的目標。那你就會感覺非常的有成就感，我做的例子比老師做的例子真的有意義多。程式 A 唯一的目標就是做出向量資料庫。

程式 B (RAG 服務實作)： 這個才是我們真正要做的服務，就是要給大家一直用下去的這個服務。就是把我們的資料庫變成一個 RAG 系統。我們剛剛前面就是建立了向量資料庫，這個向量資料庫再說一次，除非我們的資料有改，所以我們就不需要再重算。就是算完一次以後，它以後就可以開始上線了，就可以開始去回答問題了。

所以我們的作業就是這樣子：就找到一個你有興趣的文件。比方說你今天是要做一些規定，就是法規。就是規定實在太多了，然後你不知道這個規定到底要怎麼樣，所以你就可以把規定放進去。然後你就可以去問那個 RAG，說根據這個規定我可不可以怎樣啦。或是說有一個也蠻有趣的應用大家也可以嘗試看看，比方說相機說明書。我不知道大家這樣子，我都買相機幾乎沒有一本說明書從頭看到尾，因為實在是太長了，然後每次都找不到我真的想要找的地方。那我們可不可以把它做成 RAG？然後今天說：「我的那個對焦模式到底要怎麼樣調整？」那我就直接問他，那看他會不會做回答。

你去想一個你真的覺得有趣、它的資料不需要真的很長（因為理論上 RAG 應該要它的資料真的長得不得了，比方說相機說明書可能要 20 種相機的說明書，那種比較像我們真的應該做 RAG 的事情）。但是呢，因為我們今天是做練習，你也可以不用做那麼大。

所以一樣就是要別做程式 A 跟 B 出來。
程式 A 最重要就是做出向量資料庫，而且我們會需要把它壓縮成一個 zip 檔。 這大家不用擔心，因為我們的程式其實從頭到尾自動化，你唯一不自動的地方就是你要把你的文件丟進去，就這樣。然後就會做出一個你自己的 zip 檔，然後你就可以開始設計自己的 Prompt，打造自己的 RAG。

$$00:56:58$$

 實作示範：程式 A - 建立向量資料庫

好，那我們現在要兩個程式。第一個就是 ynung_memo_AI06A。
就我們有兩個程式，第一個是 A 的部分，就是要建立向量資料庫。我們就進去了。

你進來的時候，你就看到這一個，然後你就找到這個我們熟悉的 Open in Colab。按下去之後，我們要變成在雲端硬碟中儲存。這相信大家已經很熟悉，就雲端硬碟儲存，就變成我們自己的。那等一下看到一個 Google Drive 的時候，就會變成是我們的。在新頁面中開啟。

所以呢，這個就是你自己寫的這個在作業裡面，其實應該叫做 A 程式啦。RAG A 好了，A 就是打造向量資料庫。我們準備要做一個很簡單的規定。比方說我們剛剛說的，就是說如果我今天想要知道我做什麼事情可以被記功，或是我不小心做什麼事情可能會被記警告啦、記過啦等等的。所以我們在政大同學就可能要看《政大學生獎懲辦法》。

然後我們就去找到這個資料。我們把它下載下來，《學生獎懲辦法》。好，所以我現在有這一個檔案。

1. 上傳文件到 uploaded_documents：
我們現在就開始。先開始第一步呢，這一步執行的時候呢，它就會建立一個資料夾。你會發現說在旁邊的資料夾裡面，你會發現有一個剛剛我們的那個投影片裡面寫的這個 uploaded_documents 這個資料夾。這個就是我們要把我們的檔案放進去的地方。可以嗎？那我們前面有說過，這個名字其實我們自己取的啦，所以隨便自己取這個名字就好了。那你為了要程式要改得最少，你可以完全就叫這個名字，沒問題。
那我們現在就把我的檔案丟進去。然後他就會警告你說這個之後會被刪除哦，不要管他，本來就是要刪除的。好，那你就會發現說這個下面就有一個這個檔案。事實上你要放幾個檔案都可以，好，就這麼簡單。這個是唯一我們要手動做的地方。

2. 安裝與執行套件：
那接下來就可以開始一條一條執行。雖然有紅字，但是老師說我們也可以不要理他，因為我有試過就是不用理他。好，然後再來接著下來呢，我們會讀一些那個需要的套件。那這次的套件比較特別，因為有一個什麼以前我們沒有看過的什麼 TextLoader、PyPDFLoader，那基本上就是要讓我們讀進來這些 Word 檔啦、純文字檔啦、PDF 檔啦的小工具。

3. Hugging Face 登入 (重要)：
huggingface_hub 這邊我忘了說一件事情。就是大家需要在 Hugging Face 那邊註冊。這很重要。就是在 Hugging Face 這裡呢，你也要 Sign Up (註冊)。
其實我已經有了，就 Login 就好了。那一樣要申請很像 API 的那個東西，就是去申請一個 Hugging Face 的 API (Token)。那進去了之後也是要申請那個很像 API 的金鑰。為什麼需要做這件事情呢？原因是因等一下我們在做的 Embedding 的 Model 叫做 Gecko，它是 Google 出的新世代的 Embedding Model，相當好。因為它完全就是為了做 RAG 而產生的一個 Embedding 的 Model。而且它多種文字也處理得很好，例如說中文他也處理得很好。所以我們就是想要用這個叫 Embedding Gecko 嘛。

所以請大家要記得在 Hugging Face 要申請一個金鑰。所以在申請金鑰的時候，請大家在這邊就是要打入，就是在這個加入金鑰的地方要加一個 Hugging Face 的金鑰。如果來不及做的不要太緊張，就先看老師做，回去再慢慢做。

因為 Google 這個......大家認真的想的話會發現有一個小問題（事實上是很大的問題）：通常我們的那個切一塊一塊的文字塊，這個文字的長度都比較長，可能 500 字、1000 字那麼長。可是我們問題通常沒有那麼長，可能十個字就結束。所以呢，它在做那個向量比對它的相似度的時候，通常直接做效果會不太好。那現在這個新世代呢，包括 Google 他們的 Embedding 的 Model 都有考慮的很清楚。就是在做文字的 Embedding 的時候，它需要做前面的前綴詞 (Prefix)，就是要告訴他說 Title 啦等等等。也就是說我們每一次在文字，它是一個文字塊，不只是原來的文字塊裡面的文字而已，它還要把這些前綴詞加進去。所以他在做 Embedding 的時候，他就會考慮哦，這個是「原始資訊」的 Embedding。然後呢 Query (查詢) 的時候呢，它在做 Query 的 Embedding 的時候呢，它都需要加這些字眼。那它就會知道說這是要做 Query Embedding。那這個時候它的考量就會是......因為它訓練的時候就這樣訓練：如果這一段文字是可以回答這個問題的話，它就會把這些的 Embedding 的向量拉近。

4. 執行 Embedding 製作：
我們前面的廢話講完了，然後我們就可以開始執行了。然後我順便說一下下，這個以下這個寫的很噁心的段落，其實是 ChatGPT 寫的。就是我們就跟他講說我就是要用 Gecko 這個 Embedding 的 Model，那請你幫我把這一段寫出來。

再來接著下來就要開始做重頭戲了，我們就要正式的準備要做 Embedding 了。所以它就會先把一堆的文字讀進來。然後這裡是正式的要做向量資料庫。在那邊的時候，你可以改這些：如果你覺得這個切的文字 500 個字太長了，你就可以再切小一點；或者你覺得 500 字太短了，你可以切長一點。然後 chunk_overlap 也是我們剛剛說的 Overlap。那這邊 Overlap 是 100，這是很標準的定法。

然後再接著下來，我們要把 Hugging Face 的金鑰讀進來。這個以下就是做這件事情，所以你務必要有 Hugging Face 的金鑰，就是有這個名字的金鑰存在。這個剛剛的鑰匙裡面請大家都要存一樣的名字哦，不然的話助教在執行你的程式的時候是沒有辦法執行的。

然後就重點來了，現在就是要準備要把 Gecko 讀進來。所以它會執行比較久一點點。
它讀進來，而且他就開始做 Embedding，就是把那個文字切成一塊一塊。依我們的需求切成那個 500 字、500 字，而且中間每一個段落中間都會有 Overlap，就是重疊會有 100 字的重疊。這是我剛自己設的。

5. 儲存與下載向量資料庫：
然後這個重點來了哦，重點呢就是「儲存向量資料庫」。就是先把它做放到一個檔案裡面，叫做這個資料夾。所以我們再打開一下我們剛剛的那個資料夾，你就會發現有一個資料夾，這個就是我們的向量資料庫。這個其實有裡面這個資料夾裡面有兩個檔案。那這樣子下次要讀進來比較不方便，所以我們就把它壓縮成 zip 檔。所以這邊就是壓縮成 zip 檔。
好，然後他就會跟你講說 zip 檔已壓縮完畢，請記得要下載檔案備份。

好，所以我們就再打開，現在很重要，這個請大家也一定要做好。打開，然後你是不是看到這個可愛的 zip 檔？你就把它下載下來。
你下載下來，你就找到這個下載的檔案。從頭到尾你會發現事情很簡單，就是呢，剛剛我們做的真正的做的手動，我們有調整的動作（當然你真的作業的時候，你還是可以調整更多的），但是開始的時候你我們有做的動作只是把我們要讓電腦參考的資料直接丟到那個可愛的資料夾，結束，沒了。好，然後呢就一直執行之後，只要你在 Hugging Face 的這個 API 有設對，它最後執行出來以後，它最後就會幫你把你做的向量資料庫壓縮成一個 zip 檔。

那這 zip 檔要幹嘛呢？非常的簡單。就是呢，你就找到你的 Google Drive。就存存在一個你開心的地方。但是呢注意事項就是這個：剛剛這個資料夾，注意事項跟我們交作業的時候一樣，就是共用這邊，要是「公開」的才可以。好，那我們就複製這個連結。

好，請大家就記得一定要做出你自己的那個向量資料庫的 zip 檔，然後把它放到自己的 Google Drive 上面去。那設定的權限一定要是公開權限，然後這個時候就勇敢的複製連結。那你先把這個複製的連結稍微的用各種的方法存下來，因為等一下會用到。

$$01:15:27$$

 實作示範：程式 B - 打造 RAG 系統

好，等一下呢，我們就是要進行我們的第二段程式了。第二段程式呢，就是 ynung_memo_AI06B。這是我們的第二段程式，也就是我們的重點。就是已經做好的那個向量資料庫，我們就要根據這個向量資料庫，每次搜尋出相關的資訊。搜尋出相關的資訊之後，我們要回應使用者問題。

好，我們就再進入這一個，又要開始同樣的程序要再來一次。就是在這個時候呢，我們就看到這個可愛的 Open in Colab。這個已經是 B 程式了。
其實你會發現這個 A 程式應該大家都是長一樣，基本上 A 程式應該大家都長一樣。所以好像你交 B 程式也就可以啊。沒關係啊，A 程式一起交沒關係啊。因為 A 程式你有可能改，那你改的話你真的一定要提醒助教說你有千辛萬苦把那個程式改得真的太好了。

好，所以現在是第二號程式。那我們就把它叫做 RAG B 好了，就真的打造 RAG 系統了。

1. 安裝與載入資料庫：
那我們在這邊呢，我們可以先連線一下。沒關係，先安裝就好了，直接安裝。那這一個呢，這個安裝的 gdown 就是要下載 Google Drive 的檔案。你就讓它去安裝。
然後安裝好了以後呢，這邊有一個 URL (網址)。你就把剛剛的那個有分享權限的連結把它貼在這裡。好，請大家這邊一定要改到哦！你這邊沒有改到的話會發現非常有意思的事情：就是呢，你今天其實是做一個、你可能找了非常多的相機的介紹，然後呢，你就做成一個 RAG 系統。那其實你是想要讓那個使用者去問，然後要推薦他適合的相機。那結果呢，因為這個 RAG 就是你沒有改到，所以這個其實讀進來的是老師的剛剛的我們政大的生輔組發布的這個《政大學生獎懲辦法》。然後你就會發現他怎麼回答都看起來怪怪的。
好，所以你一定要改到這個 URL。好，就這樣子。

然後呢，它就會根據你的 URL 把你跟剛剛的那個 zip 檔給讀進來。我們可以欣賞一下。好，它就讀進來了。所以我們來欣賞一下這邊哦，果然出現了我們剛剛的這個 zip 檔，我們剛剛做出來的 zip 檔。就這樣子。然後所以就是開始解壓縮。因為它的本來的是一個那個資料夾，所以資料夾裡面有兩個檔案。對，沒錯，你會看到這個兩個檔案就表示說正確了。

2. LLM 與 Embedding 模型設定：
好了，再來就是一樣。就跟之前一樣，上一週我們做的事情一樣，我們也要用 aisuite 來呼叫我們的語言模型。那大家會發現說我們其實讀進了更多的東西。
我們應該不是要用 OpenAI 的，我這一段應該可以不用執行，因為我們應該要用 AI Suite，所以我應該不用執行這個 OpenAI 的。好，然後讀進來就是圖形化的介面。

我我的標題沒有改到。就是因為這個是另外一個 Embedding 的名字，其實我們現在是用 Gecko，就是 Google 出的 Embedding。這個只是我之前沒有改到。好，那我們就執行它。
就是一樣要把 Hugging Face 的這個 Token 就是它的金鑰給讀進來。那我們就要再就是授權，讓它可以讀進來。
然後繼續執行。然後這邊一樣這看起來比較可怕，這一段是 ChatGPT 寫的。那它基本上的功能就是我們說的：就是要用 Gecko 這個 Model，然後每一次他要看它是 Query 還是原來的文字塊，然後要去做這個 Embedding 的動作。事實上我們現在其實只需要這個 Query 的地方啦，所以我們也可以把它寫成簡單一點。因為我們在應用的時候其實我們可以不要管前面。我們就執行它。

3. 載入向量資料庫到記憶體：
然後這邊也是在呼叫 Model 的時候，就是我們要告訴他說這個要把這個向量資料庫給它讀進來。你就會發現它這個時候其實是沒有在重算的，它只是把我們原來的資料庫給讀進來。所以我們並沒有在......事實上我們也沒有給他原始的那個資訊，所以我們並沒有重新再把它再去做 Embedding 一次。那現在它在讀的是這個 Embedding 的 Model，就是讀進這個 Gecko 這一個 Model。所以這邊會花一些時間。

所以說呢，到目前為止感覺好像有點複雜，但是一點都沒有複雜。因為剛剛我們目前為止這個程式唯一做的真正的變動就是把那個檔案的連結改成你自己的、你自己的向量資料庫的 zip 檔的檔案連結。好，這個終於讀完了。

4. 設定 Groq 與 Llama 3：
所以它就已經安裝完。然後呢，我們就是告訴他說這個就是要去搜尋的，就有點像是搜尋引擎。然後我們跟上次一樣要用 Groq。所以如果記得上次應該有我們有做了 Groq 的金鑰，所以我們就去做 Groq。啊，它要授權。好，然後設定好 API 的金鑰。

然後這一次呢，給大家個人非常推薦，就是以前又是上一次開課的時候還沒有的，就是我們前面有介紹過 ChatGPT 他們出了一個新的開源的版本，這個是 Llama 3。啊，他那時候還沒有叫 Llama 3 之後，第一個 OpenAI 開源的大型語言模型（講者口誤，應指 Meta 的 Llama 3，或指 Groq 支援的開源模型，後續確認是 Llama 3 70B 或類似等級）。所以相當不容易，它其實也還蠻大的，它用 70B。那我們之前介紹過說我們怎麼樣去計算它大概需要的 VRAM 多少，這個 VRAM 至少要超過 60，其實會超過更多。所以它要的 VRAM 還蠻大的。
那但是現在我們用 Groq，Groq 它其實有提供這個模型，所以我們就可以開開心心的、方便便的使用它。那我們上次已經看過了，要打開這個 Client 就是這個對話機器人的時候，就是這樣子去打開對話機器人。

【生成式 AI】07.檢索增強生成(RAG)的原理及實作 - 逐字稿 (第三部分)

時間範圍： 01:24:37 - 02:04:39
講者： 蔡炎龍老師、助教呂佩真、助教采尼

[01:24:37] 實作示範：設定 System Prompt 與 RAG 樣板

好，這個下面的 Prompt 是完全請大家自己寫。我們的 Prompt 寫就是：你是 AI 的自主學習輔導員（為什麼只關心獎懲？那是因為我們目前只放入獎懲辦法）。所以「根據資料回應學生的問題，親切附帶具體建議，然後用台灣習慣的中文回應」。當然這個你可以看你自己的需求去改。這邊是自己一定要改的地方，這個其實就重點。

然後再來呢，就是「根據下列資料」。那你就要記得這一個大括號 {context} 裡面的資訊，就是真正找出來的、真正的找出來的資訊。然後「回答使用者的問題」，這個 {question} 這邊就是真正的使用者原來的問題。然後因為這個是獎懲辦法，所以「不清楚的同學資料不足，請告訴同學可以請教學務處生輔組的老師」，就這樣子。

這邊都是要自己寫的，就 System Prompt 跟 Prompt 的 Template (樣板)。大家又可以自己寫。好，所以這個是再一次，這是大家一定要改的地方，這個才會變成是你自己的 RAG。

[01:26:16] 執行 RAG 問答展示

好了，然後呢，我們就開始去執行這一個。後面基本上都是一直執行。好，這個獎懲諮詢師嘛，就這樣子。
好了，就是我們這樣執行出來以後，你就會看到一個「獎懲諮詢師」。其實有點醜啊，你也可以問那個語言模型，就是「我覺得這個我做的這個獎懲諮詢師真的有點醜，可不可以幫我弄得漂亮一點點」。

好，我們再直接執行給大家看。就看到獎懲諮詢。然後就是輸入你的問題，然後它就會根據這個學校的獎懲規定來回應。請問大家有什麼問題？沒有人有問題嗎？從小大沒做什麼好事，也沒做什麼壞事，所以不知道要問什麼問題。

我假設了，就是現在所有的學校都是校內禁菸哦。所以那比方說你問說——萬一要是啊，都是這樣問的——好，要是如果我朋友（事實上要問我，但我朋友）在學校裡面吸菸被抓到會有什麼處分？好，就這樣子。

好，那我們就問完了，然後就準備要開始回答了。它應該是就要開始去搜尋。好，開始搜尋。然後你就會發現說：根據那個校規的條文裡面，並沒有列出在校內吸菸的處分項。沒有錯，這個是政大目前還在修法的地方。但他說的是對的，目前沒有這個條文，就是未來可能會有。好，然他就會只能跟你講相關的什麼「違反校園公共秩序」、「危害健康的行為」，通常是記小過或是申誡之類。那真正的要看學校的那個情節，這樣是不是重複啦，或者是是不是造成他人困擾。寫的還蠻好的。

好，那我們再問一個問題好了，不要都是問那個悲傷的問題啊。有沒有人做了什麼好事，想要問一下說我會不會被記功嗎？生命中間我們從來沒有做什麼好事嗎？好，我在路上撿到......我在學校裡（這個時候就是我了，好事就是我，壞事就是我朋友），我在學校裡撿到 10 塊錢交給老師，那不知道有沒有機會被獎勵？撿到 10 塊錢還想要獎勵。好，不管啦，我們就問了。

好，他就會去搜尋。好，他要開始搜尋了。然後「根據那個學校的獎懲規定，把 10 塊錢交給老師屬於拾金不昧，可以受到嘉獎哦」。真的是太好了。好，那自己把 10 塊錢掏出來交給老師好了。然後那個大功太誇張了，拾金不昧行為可嘉，然後那個申請流程就是這樣子。老師會填寫，對，他說的沒有錯，我們自己不用填。

好，大致上就是這樣子。所以說呢，我們今天的作業其實就是要做這樣的 RAG 系統。就它真的是要根據事實來回應。所以說那個你就把找一個你真的很有信心、你覺得很有趣（它不一定要真的很實用，還是要實用，但是那個有實用可以是有趣的實用）。就是他不一定要對國家社會人類有什麼偉大重大的貢獻，但你覺得真的很好玩，而且你是自己覺得實用、你覺得有趣實用就可以。

那再一次，資料不用很多。再一次，你不需要改很多的地方，你可以用最簡版本交出來也可以。就是最少需要改的地方。因為你至少要做出來的就是：你真的要把你的那個向量資料庫做出來，你要會存到你的 Google Drive 裡面，然後你要會去把那個再從 Google Drive 裡面叫出來，然後再來你要下你自己的 Prompt，就是這樣。那是必要的，而且幾乎也是全部需要的。

所以如果還不太習慣寫程式的同學，你不用太擔心，你就是改好剛剛那些事情。然後再一次強調，這個其實還是會有助教來協助大家去做這樣的事情。所以如果你中間做的時候真的有困難，你也可以趕快就是在各個助教的 Office Hours 的時間請教各個助教要怎麼樣做這件事情。然後你做出來了以後真的會很有成就感，因為在做 RAG 這件事情真的是一個現在非常重要的事情。

雖然我們的作業大家做了 RAG 只能說是一個品味 RAG 的版本。如果你沒有改多的話（當然有很多程式反正就寫得很好，然後或是很會問 GPT 的，可能會交出一個相當好的、已經非常成熟的 RAG 的作品），但是我們的作業的基本需求是大家都做出一個看起來不錯、蠻有趣的、也讓你自己覺得很有信心很有趣的一個 RAG 系統。

[01:33:10] 課程結尾與問答時間 (Q&A)

好，這是我們今天的內容跟作業哦。那等一下我們就要進行這個我們的助教時間。不知道大家有沒有什麼問題？現場同學有沒有什麼問題？或是中間有困難的地方，沒有聽懂的？那個網路上在線上同學有沒有什麼問題？

Q1：請問可以丟大量的資料嗎？
哦，可以、可以。可以丟大量的資料，沒有問題。RAG 本來就是可以丟大量的資料。然後唯一的事情是因為這個我們的 Colab 它給我們的記憶體是有限的，所以你丟太多的資料，你可以試試看看它那個記憶體會不會爆。但是理論上就是大量資料是沒有問題的。那當然如果我們在現實的世界中，這其實再長的資料也可以。那剛剛說的記憶體問題怎麼解決？其實沒有什麼怎麼解決，就是我們就是分段去做那個向量資料庫就對了。但你的問題如果需要到分段的話，你願意解決也很好，但是也可以問 ChatGPT 要怎麼解決。所以總而言之、言而總之就是這是可以的。如果你覺得你想挑戰看看是可以的，因為 RAG 本身就是希望是一個大量資料庫的、非常非常多文字、檔案非常非常多的情景，我們來做 RAG 系統。那個才是最有意義的情景。

Q2：老師可以示範一下怎麼申請 Hugging Face 金鑰嗎？
這抱歉，我現在登不進 Hugging Face。我知道了，助教們誰可以錄一段給大家看的就對了。可以吧？好，這個我們請助教就是之後錄一段給大家看，就是怎麼樣申請 Hugging Face 的金鑰。誰的 Office Hour 時間是最接近的？哎呀，就你嗎？哎呀，笑這麼開心。好，我們因為我剛剛問 Office Hour 最接近的就是請助教在 Office Hour 的時間就乾脆幫我們錄一段 Hugging Face 的金鑰是怎麼申請的。

好，大家還有什麼問題？沒有什麼問題，我們就準備要休息哦。
那再一次，這一次的作業看起來複雜，沒有很複雜，大家做了以後就知道沒有真的很複雜。而且做完了你會對自己真的非常有信心，因為你會做這個。大家在企業裡面希望大家如果（真的）要希望你會運用的生成式 AI 來真的要會的技術就是去做 RAG。所以這個會做的時候就真的會覺得哦，我真的是相當厲害。那當然還是要提醒大家，在實際上、在實務上面就是做的時候會有很多還需要去考量或是調整的地方。但是我們今天品味出來以後，相信大家就會有自信說這個我慢慢去調整到更完美，應該是有能力去做到這樣的事情。

好，那我們就先休息 10 分鐘，我們等一下馬上就會進行我們的助教時間。

[01:38:06] 助教分享 1：DeepSeek R1 純強化學習 (呂佩真)

(助教彩尼主持)
各位同學，那我們第三節課的助教時間由我彩尼來主持。那我們今天有一位呂佩真同學。

(助教呂佩真)
喂，大家這樣有聽到嗎？OK，好。那個大家好，我今天要介紹的是 DeepSeek R1 的 Pure Reinforcement Learning，就是純強化式學習。然後簡單介紹一下它的原理跟成效還有缺點。

背景與 GRPO 概念：
那首先看一下背景的話，就是大型語言模型通常要去訓練它，然後提升他的推理能力的話，主流的做法就是人類去示範給他看，然後並且用人類的偏好去校正他。那這種路線有效，但是會有兩個問題：

成本高： 可能需要很多人力去標註他，然後去評分他。

思維限制： 模型會被限制在我們示範過的思考方式裡面，就是它可能就無法去自己去找到更好的推理路徑。

所以核心的做法就是 GRPO (Group Relative Policy Optimization)。那它的概念就是說：它一次會生成很多個答案，然後這些答案去彼此比較（就是有點像是一個小型的考試或比賽這樣）。那正確的答案就會給他獎勵，那錯的就會扣分。然後他再根據這些分數來調整自己的策略。所以在這個過程中，他就不需要像傳統那樣有一個 Reward Model (獎勵模型) 或者是有去評分的人，所以它的開銷會更小。

運作步驟：

群體取樣 (Group Sampling)： 就是像我剛說的，它會一次問同一個問題，然後產生可能八個或者是很多個答案，然後去互相比較。

優勢計算： 它會先給出一個獎勵是 R，然後再去讓它做標準化，然後得出一個這個平均叫做 A。然後這個平均呢會作為策略權重更新的依據。

策略更新： 它會先比較新跟舊的策略，然後再用 Clip 函數去限制每一次更新的幅度。然後還用一叫 KL 散度 (KL Divergence) 的方式去維持它跟上一版策略的距離，就是讓它不要離得太遠，否則它可能模型會走偏這樣。

所以簡單來說，它就是靠不斷的比較，然後不斷的微調來修正自己的思考路徑。

訓練過程與成效：
那訓練的時候呢，他們是把所要求模型用結構化的格式來輸出。所以它會把推理的過程放在 <think> 裡面，然後結論在答案 <answer>。那它就是有點像是接口一樣讓他們直接對答案，然後直接丟進那個測資來測試。那整個評分的過程就是自動完成，用機器來驗證，不需要人力打分。

那在這個過程中就可以看到那個機器它可能會出現一些話，像是他會說：「等一下，讓我再重新思考一下」、「讓我再重新修正這個步驟」。那所以就是可以從中發現說他是會自己發現矛盾或錯誤，然後去暫停，然後重評，還有修正路徑。

那在成果上來說，剛開始他們用一個高中數學題，那初期的訓練表現就只有 15.6% 的正確率。那等到後來純強化式學習不斷的穩定提升以後，就提升到 79.8% (逐字稿可能誤聽為 7.9，依上下文應為大幅提升)。然後後來再採用多次的自採樣整合答案，然後甚至可以達到 86.7%，就是幾乎就等於人類示範的模型的表現。

多階段訓練 (Multi-stage Training)：
那當然也不可能全部都只用機器人自己去訓練。就是它也會有副作用，就像是最早期的 R1 的模型，它可能就是很難讀那些文字，然後有時候出現的東西會是中英夾雜的。那為了改善這一點呢，DeepSeek 的團隊後來就採用多階段的訓練流程：

Cold Start (冷啟動)： 先用一些很少量的、就人類自己做的示範資料去啟動這個模型。

第一輪 RL： 採取第一輪的 RL 去建立它的推理能力。

SFT (監督式微調)： 接著用「拒絕抽樣」，就是丟掉錯的樣本，然後還有監督微調來補回一些品質或者是語言上的錯誤等。

第二輪 RL： 等到最後呢再做第二次的 RL，那這時候就會加入一些就是它會去給他有一個標準是讓他判斷「有用」還有「無害」的獎勵。

總結與挑戰：
那這項研究就是這個模型是代表說它有可靠的自動驗證機制。所以就會像數學標準答案或者是程式測資，那模型就可以不用靠人類示範就可以去提高他的推理能力。但是當然他也會有一些挑戰，像是「獎勵駭客 (Reward Hacking)」或者是開放任務會難以自動評分。也就是說他可能會就是得到正確的答案以後......得到正確答案不一定等於做對的事情，但是他可能就會開始鑽漏洞，或者是只比較結果沒有比較過程，來藉由這樣來得到比較高的分數。但是整體來說就是這個模型還是開比較新的方式這樣。

[01:45:16] 助教分享 2：Lovable No-code 工具 (助教采尼)

(助教采尼)
好，那謝謝佩真今天閃電秀的分享。好，那我今天要跟大家分享的 AI 工具呢是 Lovable。那這是一個就是不用寫程式就可以做一個簡單的頁面跟系統的一個工具。那就是提醒一下大家期末我們有個專案嘛，所以就是為了要幫助大家在期末專案的呈現上可以有更多可以使用的工具，所以我今天介紹這個 Lovable 就很適合大家期末的時候可以拿來做使用。

Lovable 的優點：

自然語言開發： 像對我來說，我不是寫程式的背景，我是會計系的嘛。那對我來說我就可以用自然語言來使用這一個 AI 的工具，它就可以幫我做出一可譬如說可能午餐下單系統，或者是一個點名的系統。

不用安裝： 透過線上編輯的方式在網路上線上就直接像 GPT 一樣跟他溝通，把你要的需求寫清楚，那它就會幫你把系統完成。

線上輸出： 可以直接線上做輸出。

程式碼下載： 那有些人的程式能力比較好的，其實可以把它（它會提供一包程式碼）下載到地端，然後再去做調整。

適合做雛形 (Prototype)： 它是一個 AI 工具，所以它很適合拿來做雛形。做雛形的話，就是你在開發的初期，你就可以花很少時間先做一個最簡單的、最小 POC (Proof of Concept) 的樣子，然後來確認說你原本的構想是不是可行的。

Lovable 的缺點與限制：
如果不大家一開始是用免費版的話，它有一個缺點就是在這個「發布」的部分。如果你是使用免費版的話，它就會先你的專案分享在網路上，所以變成你的系統是其他人都可以看到的。那如果你想要保你的隱私性的話，有兩個方式：第一個方式是你把它下載到地端，在你的電腦上面去做使用；第二個方式呢是升級成付費版。

實務價值：

打破程式能力門檻： 譬如說有一些 PM 或者是你需要去跟工程師做溝通，或者是像同學在分組報告，你可能會需要跟一些資工系的同學去做溝通。其實我們就可以透過 Lovable 的這個 AI 工具，先把你的想法、你想要做出什麼樣的系統、你需要的功能先請 Lovable 快速的幫你做一個雛形。做完雛形之後，你就可以去跟不管是你們組上比較有程式能力的同學，或者是像同學未來如果到科技業去工作，需要跟工程師做溝通的話，你們是可以有一個視覺化的一個東西、一個雛形一起去做溝通。

快速迭代與斷捨離： 在過往還沒有這種快速開發產品雛形的時代，可能光是要做一個產品的雛形就要花很多很多的時間。那花了很多時間之後，大家對於這樣的你的產品就會有捨不得的想法，就比較不容易去做調整。不過也因為就像 Lovable 這樣的 AI 工具它的出現，幫助我們可以更快的去斷捨離，把一些產品讓它可以往更有市場性或更好的方向去做調整。

[01:50:41] 實作示範：模糊指令 vs. 精確指令

好，既然它這麼好，那來跟大家分享一下它是怎麼樣去做使用的。我這邊呢會介紹三個方式，然後給大家看就是雖然說它是不用程式背景就可以透過自然語言去生成一個系統，但其實最難的部分是你怎麼樣把你的指令講清楚。

Demo 1：模糊的指令 (Bad Example)
所以我第一個呢，我會先下一個模糊的指令給大家看看效果。我的指令呢就是我很粗略：「我想要建立一個午餐預訂系統，讓學生可以在線上訂午餐。」但我什麼功能都沒有講清楚，我就是很模糊。

好，這個版本呢就是我用一個很模糊的指令做出的一個學生午餐預定系統。我沒有講使用者不管是學生還是說店家他們有什麼樣的權限，我也沒有說我需要什麼樣的功能。所以大家不知道大家有沒有發現，就是雖然 Lovable 可以幫我們做出一個看起來好像很漂亮的系統，可是光是時間它就定死了。所以我一個午餐預訂系統，我卻沒有辦法去調整我要預訂的時間，然後也沒有辦法去......譬如說我下訂完我的午餐之後，到底這些資料存到哪裡去都沒有。所以呢這個就告訴我們一件事情，就是如果要使用這種不用程式就可以寫系統的軟體來做一個 Demo 的話，其實你的功能要寫得很仔細。

Demo 2：詳細的指令 (Good Example)
這時候我就加了很多哪些東西呢？

角色權限： 登入的角色有誰？我就設定有「學生」跟「管理者」。學生這個角色它可以可到自己訂的午餐；管理者他可以看到所有人的記錄。

預訂功能： 我可以選擇日期、選擇取餐的時間。我可以輸入備註（譬如說可能醬多一點，或者是說加番茄醬、不要香菜等等的）。那訂單建立完成之後，我還可以去做修改。然後我還可以加上一個限制是早上 10 點半之後就不能再做更改。

歷史記錄與圖表： 大家在使用這種午餐預訂系統的時候，其實也會很需要去看到自己過去的一個歷史記錄嘛。包含你有沒有訂成功、你的付款、你的有沒有未付款、然後有沒有取餐。以及你過去到底都訂了哪一些的餐點、總金額等的這些圖表，會想要看一個圖示化。

管理者功能： 他可能也會想要看到就是使用這個平台上面的用戶（不管是學生還是說是使用的用戶），他們都訂哪一些的餐點。那這時候可能就可以回饋給店家，讓他們針對這些使用者常訂的一些餐點，可能可以去做出一些組合優惠合等的，或者是可以銷售捆綁等的策略。

好，那第二個版本呢，就是我把指令寫得很清楚。我可以去選擇像今天是 10 月 15 號，取餐時間可能是 12 點，然後我想要點飲料。其實這個系統呢，它其實還有登入跟登出的功能。我先註冊，好，進來了。這時候呢，我再做重複一次剛剛的動作，它會幫我記錄在我的預訂的訂單中。然後統計分析的話，因為可能時間是明天，所以他就還沒有統計。但我從頭到尾其實我下的指令是什麼，其實都是自然語言，我沒有寫程式，就可以做出一個產品的雛形。

[01:58:23] 使用 GPT 協助產出需求規格

好，我知道接下來同學可能就會想問說：可是我不知道要怎麼樣寫的像助教一樣把這個系統的需求寫的這麼細，怎麼辦？好，為了就是回應同學這個問題，我們又做了一個「需求收集機器人」。

這個因為這些簡報我們都會放在雲端上面，所以如果之後同學有需要也可以直接掃 QR code，那就會進到就是我寫的一個我的 GPT。那這個 GPT 呢，它就可以幫大家去把你的需求寫得很清楚。

舉例來說，譬如說我想要設計一個餐廳訂位系統好了。就是透過問答的方式，GPT 先幫你生成一個像 List 一樣的需求的細節，你再回應它的需求的細節，它就會幫你產出一個可以丟到這個 Lovable 的這個網站裡面的指令。

這個就是我想要建立一個午餐預定系統，然後按送出。那 GPT 它就有說，就是我們可以去回答他提供這些問題。好，這時候你就可以不斷的跟 GPT 去做互動，讓你的需求可以寫得很仔細。

為什麼要先在 GPT 把需求寫清楚？

節省 Credit (額度)： 如果各位使用的是免費版，那你會有下指令的額度。現在每天有五個 Credit。可是它也不是完全的五次，怎麼說呢？就是像我如果想要做的系統很複雜，那那個複雜的系統它可能對應到的 Credit 就不會是問一次問題就是一分。像舉例來說像我做這個午餐預訂系統，因為它是個比較完整的系統，我的指令很長，所以我做了這個系統的過程，其實 Credit 五分就全部用完了。那如果我還想要繼續用，我就是必須要等到明天。所以才會建議同學先透過 GPT 把你的需求釐清楚之後，我們再丟回來這個 Lovable。

釐清功能細節： 你在做系統之前，你一定要先很清楚知道你現在到底要做什麼功能。那其實你在跟 GPT 在互動的過程，就像同學之間在報告之前在開會一樣。其實在這個互動過程，你也會很清楚的去知道哪些功能其實我漏掉了，或者說哪些功能它很重要要我一定要把這一塊做得很仔細。

好，那第三個我想請 GPT 幫我設計「使用者流程」以及「介面畫面」的設計的描述。因為我們剛在講的其實都只有我的功能需要什麼，但有些人他會很在意你畫面的呈現嘛，所以你其實也可以透過這個方式先問 GPT。你就是你希望畫面的呈現流程：登入的流程是常常會忘記學生登入的流程、老師登入的流程、我畫面呈現的方式什麼、譬如說什麼圖案要放在上面，你都可以在這個時間點把這些細節、你的系統的細節都把它寫清楚。

好，所以最後就會生成一個這個午餐預訂系統。
[02:04:39] Lovable 介面介紹與自然語言微調

好，所以最後就會生成一個這個午餐預訂系統。那這邊也可以跟大家分享，就是它的這個介面的介紹。我們通常會這樣做：這邊是你打自然語言的地方，我舉例（打字），然後我複製到這邊，然後你按送出，它就會開始幫你跑你的系統。

然後這個系統呢，你如果關掉之後，你隔天回來繼續打，它可以繼續調整。然後我剛說每天只有五個免費的 Credit，但實際上如果你是發現你的這個系統有一些功能好像跟你想的不一樣，你想要微調功能，你可以直接跟它做自然語言的互動。你就說譬如說：「我的最常點的這個餐點，我希望它呈現可能是圓餅圖之類的。」就是你是調小的功能，你直接跟它做互動，這時候它是不會去扣你的 Credit 的。

也就是說，如果你跟他溝通的內容是屬於修改程式，那它不一定會扣你的 Credit；但如果你跟他溝通的內容是「我要一個全新的系統」，那它就會算在你的每天的五個免費的額度裡。

[02:05:56] 專案發布 (Publish) 與隱私設定

好，然後再來另外一個跟大家分享是：大家在寫完這樣的系統之後，你一定會想知道我怎麼發布？以及如果我想要儲存到地端去修改程式碼，我怎麼做？

好，所以它的介面這個 Publish 的這邊你就可以去做發布。那你發布呢，有些人會想要去調整你的網域，那這邊就可以去做調整。好，那我們可能先發布。

那這邊也提醒大家，就是如果你使用的是免費版的話，你發布上去之後，你的模版就會被別人看到。那如果你很在意隱私權的話，那你可能要改成付費版。好，那這時候呢，你就會擁有一個你系統的連結，你可以把它分享到任何社群軟體上。

然後我們重新開一個無痕視窗。好，這就是剛剛寫的那個午餐預訂系統，它就可以直接變成一個互動式的網頁去做互動。好，我分享另外一個，分享這個比較 Version 2 的、這個比較仔細的。好，那就是變成一個互動式的網頁，你就可以直接跟他去互動。項說[02:08:00] 參考範本與 Remix 功能

好，那回頭過來。再來還有就是我們除了自己做系統，我們也可以參觀別人做的系統。所以就有一句話是說：我們創新是建立在可能別人已經做好的一些東西，然後去優化他，我們不一定要自己從頭開始做。好，那這邊就跟大家分享一下 Lovable 它的範本在哪邊。

它的範本呢，就在下方這邊 Explore 其他的社群嘛。那像有些人我們可以看看比較熱門的大家都在做些什麼。像可能有些人會想要去做這種儀表板監控的。好，我們看一下。哦，這個人他做的就是一個儀表板，他去監控他的股票的一個情況。如果有同學想要做這種金融相關的專案，就可以上去看看別人是怎麼樣去做這種金融專案的系統。

好，沒關係，那另外一個我們再看看其他人還有做一些什麼樣的範本。像網站，網站也是很多人會使用這個平台來做練習。好，那這邊就是一個網站，所以這個網站你還可以登入，然後登出，然後你可以去搜尋。所以如果有同學的期末專案是想要做網站，那也可以去使用這個 AI 工具來做一個網站的一個簡單的呈現。而且它的網站是互動式的，所以你可以去加上譬如說儀表板啊，然後你的可能潛在合作廠商啊等等的一個示範。

我之前還看到有人是做那種問卷收集。對，你可以做一些問卷的一個互動式的軟體或者系統，然後就是透過 Lovable 快速的做出一個產品的雛形，然後去收集一些使用者的一個回饋。這、好，我們看一下他們的......好，這邊有一個「你也可以創造你自己的」。其實正常來說點這個 Remix 的話，它的那個用法跟 Notion 很像，就是你可以複製別人的模版，複製到你自己的專案裡。這時候你就可以直接在別人的模版上去做調整。那這就是另外一個你可以做出你自己系統的方式，就是我們去優化別人的系統。

好，所以我剛剛介紹了很多種透過 Lovable 去做一個最小的一個期末專案的呈現的一個方式，就是可以建議推薦給大家。那如果大家有其他的工具可以使用，那這就是一個參考。

[02:12:17] 匯出程式碼 (GitHub & Download)

好，再來要回到剛剛就是有些人可能會在意說你的軟體、你的系統不想讓別人看到。那你要怎麼樣把這樣的專案下載下來到地端，然後再去做調整呢？

好，這邊示範一次給大家看。那以我的這個午餐系統為例，那這邊 GitHub 這邊點下去。好，它其實會......它可以連接到你的 GitHub 上。那就是 Lovable 它其實幫你寫了就是這個譬如說以這個午餐系統來說，它幫你寫了一些底層的那些程式，它就會幫你丟到這裡面，然後你可以去做修改。

那可能有些人會不知道怎麼樣修改，那他也很好心的幫你把我怎麼樣去修改這樣的 Code 的一些指引的說明都幫你寫在（就是它幫你丟到這 GitHub 上面的這些參考）。那因為現在 AI 很盛行嘛，所以其實同學也可以透過就是他寫的這些引導，然後丟到 AI，然後請 AI 跟你說你可以去調整程式碼中的哪一些部分。又或者說你想要把就是 Lovable 給你的這個程式碼的雛形跟老師上課教的一些功能去做結合，那你也可以問問看 AI 說這有沒有哪一塊程式碼是可以去做調整的，然後我可以把老師可能教某一塊功能我把它加進來。

好，所以這邊就會是把程式碼下載到地端的教學。好，那所以這個工具就是蠻好用的，就是蠻推薦大家可以使用看看。但。[02:14:26] 助教最後叮嚀：點名與實習計畫

然後在就是助教課結束之前，這邊想要提醒大同學兩件事：修從中發點名： 第一件事情呢是請同學一定要記得去登記你們的點名表單，一定要記得點名。

AI 實習計畫： 第二件事情則是就是政大同學要記得，如果老師在 11 月到 12 月的時候會有一個 Sessions 是 AI 的實習的資訊。然後這個實習的資訊大家要注意，然後如果對於想要參加生成式 AI 的實習的話，可以去報名。那特別記住的是，就是這個計畫的話是什麼樣的科系都可以去報名。那如果沒有程式的背景的話，也是很鼓勵跨科系的同學去報名。那唯一的前提是像今天剛剛老師有教的這個 RAG 的使用嘛，所以這一塊要把他複習完畢。然後這個專案就是只會用到就是這個 RAG 的這些內容。候出還R好，那我們今天的助教課就先到這邊，謝謝大家。就 [02:15:37] Q&A：如何查看後端程式碼與 Index.css

(學生提問)
同學有問題嗎？哎喲，Code 端嗎？啊，怎麼看 Code 的？好。

(助教回答)
好，剛剛有一位同學問說就是這個 Lovable 怎麼樣去從後端化
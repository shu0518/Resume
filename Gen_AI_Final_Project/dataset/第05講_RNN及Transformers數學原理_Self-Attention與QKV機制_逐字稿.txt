[00:00]大家好。今天我們要介紹一個非常重要的主題，就是 RNN 跟 Transformers 的數學原理。雖然說是數學原理，但如果對數學非常排斥的同學不用太擔心，反正今天能懂多少就懂多少，不要太有壓力。[00:27]再一次提醒，如果大家有問題，不管你是哪一個學校的同學，都可以看到我們現在已經把所有助教的 Office Hour 時間貼出來了。政大的同學當然拜託大家，請實體到我們 Office Hours 的研究室，就在我的研究室那邊。其他學校的同學，如果你願意實體到也非常歡迎；沒辦法的話，我們有線上的 Office Hour，大家可以在線上參與。歡迎大家有什麼問題盡量提問，有什麼困難多說出來。[01:11]今天我們有三位助教，是之前還沒有為大家介紹過的，我們請他們一一來自我介紹一下。[01:35]（助教劉子均）：大家好，我是應數碩二的劉子均，Office Hour 是在禮拜一的兩點到四點，歡迎大家有問題來找我討論。（助教陳奕璇）：大家好，我是國貿碩二的陳奕璇，我的 Office Hour 是在禮拜二的兩點到四點。（助教劉奇斌）：大家好，我是金融所的劉奇斌，我的 Office Hour 是在禮拜一早上九點到十一點，有問題的話就可以來找我討論，謝謝。[02:17]好，請大家看我們在 NTU COOL 上面的首頁，現在已經完全更新了。上面有各個 Office Hour 的時間，下面也有連結。每一次 Office Hour 的時間，那個連結會打開，基本上就是 Google Meet 連結，用法是一樣的。大家可以進來線上問問題，歡迎多多跟助教討論。不用太擔心，很多問題其實你跟助教討論以後就會發現，原來也沒有這麼困難。[03:03]我們今天介紹的內容會比較數學一點點，我們要介紹包括「有記憶的神經網絡」。上次我們說過，我們的生成式 AI 其實非常簡單，基本上它就是一個去預測下一個字的模型的。預測下一個字，其實就是一個字預測下一個字，可是我們上次說過這樣會有點問題，所以希望它是有「記憶型」的神經網絡。那到底怎麼記的？就是我們今天的主題。[03:41]基本上有兩種做法，一種是 RNN，一種是 Transformers。我們先來介紹 RNN 的原理。RNN 的原理其實非常簡單，在 RNN 層那邊，每一個神經元的動作就跟我們以前說的一樣。每一個神經元要做的事情，就只是收集前面一層傳來的資訊，它就做「加權和」。那個權重是學來的，也就是神經網絡的參數。做加權和之後，加上它自己那一個神經元的「偏置 (Bias)」，然後經過一個非線性的轉換 (Activation Function)，再把它送出去。[04:21]所有的神經元都是做這件事情。如果是全連接層的話，假設今天有兩個神經元，輸入層也是兩個。大家應該知道理由，只是我懶得畫那麼多個。輸入層跟隱藏層當然不需要是同樣數目的神經元，這邊畫成一樣是為了簡單。[04:50]所以像 X1 傳過來的時候，它需要傳給第一個神經元，也需要傳給第二個；X2 也是，因為是全連接，它需要傳上去，也要傳過來。所以全連接神經網絡就長這個樣子。兩個神經元的動作是一模一樣的，它只有接收到的權重、它自己的偏置是不一樣的，這些都是學來的。這就是標準的全連接神經網絡。[05:36]RNN 層基本上就跟標準的全連接神經網絡一樣，只是我們會把這一層 RNN 層的輸出當作所謂的「記憶」，真正的名稱叫做 Hidden State（隱藏狀態）。我們把這一層的輸出當成記憶，為什麼可以這樣做？沒有什麼特別的理由，前面說過，每一個隱藏層輸出都可以當成神經網路的某種理解方式。[06:11]為什麼我們會覺得它是合理的記憶呢？因為它最後可以做到我們想讓它做的事情，比方說預測下一個字。所以它成功了，表示它中間的理解或者是它的記憶是合理的。[06:38]下一次，這一層的輸出（也就是 Hidden State）又會傳回來。意思是說，本來的神經網路，每一個神經元本來是兩個輸入而已；在這個 RNN 層，現在變成上一次的記憶要一起進來。因此在我們的例子裡面，它就變成有四個輸入一起進來。[07:07]下面的算式看起來很可怕，其實它就只是在做加權和。因為包括記憶輸進來的時候也會有一個權重，所以它今天就像四個輸入一樣。我們看這張圖可能比較清楚：這層 RNN 層本來只有兩個輸入 X1 跟 X2，現在加上 Hidden State，也就是上一次的記憶輸入，它也是一個向量，一起輸入。在我們的例子裡，因為隱藏層只有兩個神經元，所以上一次就有兩個數字輸出，下一次又會傳進來。[07:49]在這個編號裡面，因為每一個時間點的記憶或者每一個時間點的輸入都需要標記一下，不然我們會搞混到底是哪一個時間點。所以我們通常會寫一個小 t 在這邊，告訴大家這是 Xt，就是在第 t 個時間點的輸入。那 H(t-1) 就是上一次的記憶要寫進來。[08:18]再強調一次，它跟一般的神經元基本上就是一模一樣的。全連接怎麼輸入、怎麼運算、怎麼學習權重，我們就怎麼做。所以在寫成數學式的時候看起來好像比較了不起一點點，我們就不多說了，對數學有興趣的同學可以自己去寫一下這個式子。反正寫出來看起來就是這麼噁心，其實有一個很重要的原因，就是要把 t 這個時間點一起寫進去。[09:19]RNN 的過程真的很簡單，基本上跟一般的全連接神經網路是一模一樣的，只是它會把 RNN 這一層的輸出叫做記憶或是 Hidden State。它是一個向量，這邊有幾個神經元，它就有幾維的向量輸出。這些數字下一次又會輸進來，輸到每一個神經元的身上。[10:15]不知道大家對 RNN 有沒有什麼特別的問題？我們上次說過了，RNN 這種神經網路的方式，其實是很自然、很直覺、很有道理的方式，但它有兩個非常嚴重的缺點。[10:30]第一個嚴重的缺點，我們上次比較沒有說到。因為 RNN 每一次的記憶都要進來，所以整個圖畫起來，這一層走完了以後，又再走下一層。如果我今天有十個字，它就等於完整的神經網絡要跑 10 次。意思就是說，我們本來是五層的隱藏層，現在跑 10 次就變成 50 層的神經網絡。[10:58]可能很多同學還沒有經驗去做比較大的神經網絡，但神經網絡很容易出亂子。亂子是來自我們在訓練它的時候要做一件事情，就是 Gradient Descent（梯度下降）。簡單說就是要做微分，看最大值的方向在哪。因為我們希望 Loss Function 的值越來越小，所以我們要跟它唱反調，往 Gradient 的相反方向走。[11:47]總而言之就是要對它做微分。微分的時候，大家如果回想微積分的美好時光，裡面有一個非常重要的技巧叫做 Chain Rule（連鎖律）。基本上就是先微最外面我們看得到的範圍，然後再乘上對項再微，一直微過去，把它全部乘起來。[12:21]「乘起來」就是關鍵點。在這個過程中，如果是很深的神經網絡，連鎖律要做幾好次。然後你會發現，每一次調一點點，會發生一些事情：如果在還沒有乘到最前面的時候，它就變成零了。意思就是我們做得這麼偉大、這麼深的神經網絡，發現前面根本就調不到參數，這叫做 Vanishing Gradient（梯度消失）。另外就是乘一層、乘一層，發現數字太大了，超過電腦可以容納的範圍，那叫做 Exploding Gradient（梯度爆炸）。[13:24]這兩件事情我們都不喜歡，因為這樣就沒辦法去調整我們的神經網絡參數。這就是 RNN 很難訓練的原因。事實上不是 RNN 很難訓練，是所有的比較深層的神經網絡都很難訓練。這件事情我們之後需要解決，因為像現在的 GPT 是非常大、非常多層的神經網絡，它一定也會碰到這個問題。我們之後會說明現代最有效的解決方式是怎麼解決的。[14:19]第二個缺點就比較沒有解決方案，是我們之前提過的。RNN 在計算的時候，它需要第一個時間點的記憶（第一個字進來後產生），然後第二個字進來的時候，第一個時間點的記憶要一起進來，才能產生第二個時間點的記憶。它看了兩個字的記憶，才會產生第二個時間點的 Hidden State。然後第三個字進來，還有第二個時間點的記憶一起進來，才能產生第三個。[15:13]RNN 必須要這樣子一個字、一個字讀，整個速度會被拖累。後來大家就在想怎麼辦，因此 Google 想出了 Transformers 的架構，這就是我們今天的主軸。[15:34]Transformers 的目的，就是希望每一個時間點的記憶可以平行運算。因為輸入的時候，比如人家說一句話或是一本書，前面的字已經在那邊了。我們現在想要做的事情是預測下一個字，因為全部的字已經在那邊，我只要把每一個時間點看可不可以平行運算出來，算出那個合理的代表那個時間點的記憶（Hidden State）。[16:21]這裡用到的偉大數學一點都不偉大，只有線性代數。所以我們現在要回歸線性代數，這是非常簡單的。它最重要的一個關鍵就是要記得「先列後行」。[16:51]這邊需要講解一下，台灣跟中國大陸、日本的用法剛剛好是相反的。英文當然是一樣的，Row 就是橫的，Column 就是直的（行）。但是中國大陸跟日本是相反的，所以大家小心一點。如果是用英文念就不會出錯，就是先 Row 後 Column。[17:35]請大家如果是用中國大陸或日本的學習方法，自己把它調整過來，只有在我們這個時候是這樣子。反正所有的事情都是先 Row 後 Column。比如說有一個矩陣，m 乘 n 大小的矩陣，前面的指標一定是 Row，後面的一定是 Column。如果是 3 乘 2 的矩陣，一定是 3 個 Row，2 個 Column。[18:58]我們來寫一下黑板。（老師切換畫面）我們很喜歡用大寫的字來表示矩陣，例如 A 是 m 乘 n 的矩陣。前面的標示，台灣的用法這個是列 (Row)，後面是行 (Column)。Row 是橫的，Column 是直的。[21:08]我偷偷改一下，A 改成 m 乘 p 好了。因為我還想要有 B 這個矩陣。假設 B 這個矩陣，我們要相乘的時候，這邊一定是 p 列 n 行 (p 乘 n)。所以 B 這個矩陣就是 p 個 Row，n 個 Column。[21:57]相乘的時候，A 乘以 B，最後會乘出來一個 m 乘 n 大小的矩陣。我們唯一的問題就是這個新的 C 矩陣，它的第 i 列第 j 行 ($C_{ij}$) 應該長什麼樣子？其實非常簡單，$C_{ij}$ 就是 A 矩陣的第 i 列（Row i）跟 B 矩陣的第 j 行（Column j）做運算。如果要一一寫出來，A 的第 i 列就是 $A_{i1}, A_{i2}, \dots, A_{ip}$；B 的第 j 行就是 $B_{1j}, B_{2j}, \dots, B_{pj}$。[24:15]如果不清楚前列後行的話，你會覺得很混亂。知道的話就會發現這非常有系統。相乘的時候，前面的矩陣要出 Row，後面的矩陣要出 Column，然後做什麼事情呢？其實就是做內積 (Inner Product)，嚴格來說是 Dot Product (點積)。我們數學系覺得內積是一個神聖的關鍵字，不可以隨便亂用，但它其實就是標準的 Dot Product。把這兩個向量相對應的數字相乘加起來。[25:09]第二件非常重要的事情。在機器學習的世界裡面，很喜歡把向量用「列 (Row)」來表示，寫成 Row Vector (列向量)，也就是橫的向量。這跟我們數學課本非常不一樣，數學課本比較喜歡寫成行向量 (Column Vector)。[25:53]原因很簡單，數學課本裡所有的線性轉換都可以寫成一個矩陣乘上一個向量 ($Ax$)，所以喜歡寫成行向量。但在 AI 的世界，特別是 Google，最喜歡做的事情就是 Dot Product，寫法就是 $u \cdot v$。或者寫成 Row Vector 的形式：$A$ 是 $A_1, A_2, \dots, A_p$，然後 $B$ 也是寫成 Row Vector $B_1, B_2, \dots, B_p$。[26:48]最喜歡做的 Dot Product，如果寫成矩陣運算，就是 $u$ 乘上 $v$ 的轉置 ($u v^T$)。真正寫出來的時候就是大家很熟悉的 $A_1B_1 + A_2B_2 + \dots + A_pB_p$。我們比較喜歡寫成 Summation (求和) 的形式：$\sum A_i B_i$。[28:51]所以線性代數第一件要知道的事情就是內積怎麼做。第二件重要的事情是，一個線性轉換，如果我們決定了基底之後，就可以寫成一個矩陣的樣子。[29:56]一般的線性代數裡面很喜歡寫成 $Ax$，假設 A 是 $m \times n$ 的矩陣，那 $x$ 就是 $n \times 1$ 的行向量，乘出來會變成 $m \times 1$ 的向量。這是我們小時候學的樣子，向量是直的。[31:16]但是 Google 以及所有機器學習的人很喜歡寫成列向量 (Row Vector)，因為某種程度在電腦裡面用列向量表示比較自然。這會發生什麼事呢？它在乘矩陣的時候，必須把 $x$ 放到前面去。$x$ 變成一個列向量 ($1 \times m$)，$A$ 放後面。[32:14]最重要的一件事情來了。假設 $x$ 寫成列向量 $(x_1, x_2, \dots, x_m)$，A 寫成一列一列出來：A 的第一列、A 的第二列...到 A 的第 m 列。線性代數裡面最重要的運算：一個向量乘上一個矩陣（向量在前面），剛好會變成「矩陣的列向量 (Row Vectors) 的線性組合」。係數是誰？就是前面的 $x_1, x_2, \dots, x_m$。也就是：$x_1 \times (\text{A的第一列}) + x_2 \times (\text{A的第二列}) + \dots + x_m \times (\text{A的第m列})$。[34:26]這跟我們數學課本剛好相反。如果是 $Ax$ ($x$ 在後面，行向量)，是對 A 的「行向量 (Column Vectors)」做線性組合。如果是 $xA$ ($x$ 在前面，列向量)，就是對 A 的「列向量 (Row Vectors)」做線性組合。這件事情希望大家記得。如果你其他都不記得，就記得：內積怎麼算。一個向量乘上一個矩陣（向量在前），剛好是把後面那個矩陣的列向量做線性組合。[35:34]順便廣告一下，如果你覺得數學科目這麼多，想要用最精簡的時間學到大學數學最重要的核心，其實只有兩科：一個是線性代數，另一個就是微積分（包含高微）。[37:17]這到底跟 Transformer 有什麼關係呢？我們開始要解釋了。（切回投影片）[37:44]Transformer 是 Google 在 2017 年提出來的，最重要的就是希望能改變 RNN 的缺點，也就是 RNN 一定要一個字一個字讀、不能平行化運算的問題。NVIDIA 非常討厭這件事，因為不能平行化運算，用 GPU 就沒有特別的好處。[38:23]Google 那篇文章非常囂張，標題叫做《Attention Is All You Need》。意思是說，Attention 是我們在神經網路世界裡唯一需要的東西，其他的阿貓阿狗模型（比如 RNN、CNN）都可以送走了。當然全連接層還是會存在做收尾，但它變成了附屬的。這篇文章非常囂張，大家可以觀察一下過了這麼多年，是不是真的只剩下 Transformer 這種模型。[39:40]重點是它想要把 RNN 不能平行的地方變平行。中間有三個非常重要的概念：Q、K、V。大家先記得，雖然 Google 那篇文章把簡單的東西寫得很困惑，讓覺得很神祕，但 QKV 其實沒有那麼困難，也不是 Google 想出來的，本來大家就有這個概念。[40:42]Q (Query)：搜尋、問題。K (Key)：關鍵。V (Value)：值。這三個很重要的向量形式，就是我們接下來要稍微講解的。
[00:40:05]我順便介紹一下 Google 那篇 Transformers 的文章。那篇文章除了標題很囂張是一個特色以外，另外還有一個特色，就是它把簡單的東西寫得很困難，讓你覺得這個真的很神秘、好像是一個很艱深偉大的學問。但事實上它沒有那麼困難，在某種程度裡其實是很自然的、應該要有的想法。包括 Q、K、V 其實這件事情也不是 Google 想出來的，本來大家就會有這個概念。[00:40:42]大家先記得有 Q、K、V 三個很重要、很重要的向量形式。Q 就是 Query（搜尋），K 就是 Key（關鍵），V 就是 Value（值）。這個等一下我們會稍微講解，這個開始的時候也是最引起大家困惑的地方。[00:41:05]不管怎麼樣，這個 Transformer 想要做的一個最重要的問題是：今天有個 Q 進來了以後，不管是問題或是搜尋引擎裡面的關鍵字，進來以後我要想辦法找到最適合這個問題的代表向量，就是 H，也就是我們本來說的那個記憶。[00:41:40]這跟我們前面 RNN 的時候用一樣的符號，就是讓大家知道其實它要取代 RNN 的部分是在這裡。所以 Q 可能是某一個字，比方說 t 這個時候，我想要產生的就是 $H_t$，在第 t 個時間點的記憶，或是適合代表那個時間點記憶的東西。那這個怎麼做的？我們現在又要切到黑板來跟大家解釋。其實你看完了以後，你就會發現其實沒有非常的特別懸疑。[00:42:30]（切換至黑板畫面）我們再重生一次，今天要做的事情是這個：今天有一個 Transformer 模型，我現在把每一個字同時輸進去，就是 $X_1$ 到 $X_T$。我要做的事情就是每一個字，第一個字是一個向量進去了，第二個字也進去了，點點點到第 T 個字進去了。我想要做的事情就是經過某一種的平行化計算，同時產生 $H_1$、$H_2$ 到 $H_T$。$H_1$ 代表第一個時間點的記憶或理解，$H_2$ 代表第二個時間點的記憶。[00:43:33]我們想要做的事情就是預測下一個字。所以今天最重要的就是看到這個 $H_T$ 之後，也就是我們本來 RNN 最後一次得到的那些資訊，我就想要預測下一個字。下一個字我們把它寫成 $\hat{X}_{T+1}$，因為是我們自己預測的，所以加一個 hat。其實想要做的事情就是這樣子。[00:44:03]我們現在就是要看怎麼樣合理的把這件事情做出來。比方說我們現在專注地看 $X_2$ 這個字好了。其實它基本的想法很簡單，就是 $X_2$ 這個字，我就跟 $X_1$ 跟 $X_2$ 等等到 $X_T$ 去看它的「相關強度」。[00:44:39]為什麼看它的相關強度呢？因為我們最後希望用這些 $X_1$ 到 $X_T$ 的特徵代表，然後把它線性組合起來。意思就是說，我想要產生的 $H_2$ 其實就是等於把 $X_1$、$X_2$ 到 $X_T$ 的某一種特徵代表向量，把它線性組合起來。前面的係數就是 $\alpha_1, \alpha_2, \dots, \alpha_T$。[00:45:26]這個 $\alpha_1$ 到 $\alpha_T$ 有一個特性，就是 $\alpha_1$ 加 $\alpha_2$ 加等等加到 $\alpha_T$ 要等於 1。這個很自然，就只是說它分配它的權重，我們希望它的權重加起來變成一。但事實上算出來的時候它權重不是一，可是我們現在已經很會做 Softmax，做了 Softmax 它就會自然變成一了。[00:45:51]所以越重要的，如果說第二個字覺得 $X_1$ 很重要，那它就要給 $X_1$ 這邊比較高的權重；相反的它覺得不太重要的，就給它比較低的權重，然後做線性組合起來。這個看起來其實真的蠻有道理的，Transformer 整個架構、整個想法基本上就是這樣子。[00:46:17]你會發現老師你已經講完了？沒錯，我已經講完了。所以現在只有幾個問題，最重要的問題就是它的「注意力模式」。因為 $H_2$ 等於是說 $X_2$ 這個字要產生 $H_2$ 的時候，它就要看其他的字跟它的相關性的強度。那相關性的強度要怎麼計算？其實你愛怎麼算就怎麼算。[00:46:49]比方說你也可以算相關係數，小時候學統計學的時候有學過相關係數，終於有用到了。但不一定要用相關係數，因為相關係數算起來很噁心。其實你可以用一個神經元去訓練它，也就是你兩個向量輸進去了以後，你就去調它的權重，然後輸出一個數字來。[00:47:21]而且老實說用神經元訓練是最好的方式。在我們的深度學習裡，比方說我想要算 $X_2$ 跟另外某一個字 $X_t$，這樣子進去了以後，我經過一個神經元的運算出來一個值，我就把它算成它的 Attention 的強度，寫成 $A_t$。就是我去訓練一個神經元去計算 Attention 強度應該要給多少，它就會根據運算的結果去調整數值。這樣的訓練出來其實是最好的。[00:48:06]但是 Google 不喜歡這一套。那 Google 到底用了什麼？Google 其實就把這個向量跟這個向量做「內積」。如果你知道 Google 超級喜歡內積、超級喜歡列向量 (Row Vector) 的話，你就會發現 Google 寫的文章很多都非常的簡單。他只要可以用內積，他就一定用內積；他只要可以寫成列向量，他一定寫成列向量。其實列向量這件事情不是只有 Google，基本上機器學習跟 AI 的世界大家都是這麼做的，但他特別喜歡內積，已經到了執著的程度了。[00:48:50]所以 Transformer 就是要做這件事情。因為我想要平行化地把每一個時間點的 $H_1$ 到 $H_T$ 同時平行的算出來。我們先固定一個時間點去看一下，比方說 $X_2$，我們想要產生那個合理的 $H_2$ 出來。怎麼做呢？其實很簡單，就是 $X_2$ 去跟其他的字做 Attention，去計算它的 Attention 的強度。[00:49:24]假設我寫成 $e_1$ 是它跟第一個字的 Attention 強度，$e_2$ 是第二個字的 Attention 強度，然後再到第 T 個字。這個加起來不一定是 1，但是沒有關係，我們非常會做這件事情，就做 Softmax 之後，它加起來就是 1 了。加起來是一的這些數字就是 $\alpha_1, \alpha_2, \dots, \alpha_T$。[00:49:44]所以我再根據這個權重，然後乘上 $X_1$ 的代表向量，加上 $\alpha_2$ 乘上 $X_2$ 的代表向量，加到最後。這個結果我們就把它叫做 $H_2$。Transformer 基本上要做的事情就是這樣子。[00:50:00]大家一定會發現，如果自己有看過那個怎麼看都看不懂的 Transformer 模型，就會知道好像比老師現在說的還要更複雜一點。其實沒有更複雜，等一下我們會解釋它到底細節做了什麼這樣的事情。[00:50:15]我們剛剛已經說到 Transformer 大概的流程是什麼，可是你會想起來，一開始的時候我說這種注意力機制（Attention Model）裡面有很重要的三種向量，就是 Query (Q)、Key (K) 跟 Value (V)。[00:50:36]其實你想它是 $X_1$ 到 $X_T$ 也沒錯啦，它只是從 $X_1$ 每一個字，比方說 $X_1$，它就會有一個代表它的 Query 向量叫做 $Q_1$，有一個叫做 Key 的向量叫做 $K_1$，有一個叫做 Value 的向量叫做 $V_1$。就是每一個 $X_1$ 它有三個特徵代表向量。[00:51:04]當然大家會問說需要做這種事情嗎？我可不可以不要？我可不可以都全部都用 $X_1$ 代表他自己就好了？也可以。但是因為 Google 為了要更一般化，所以他就說那我們在考慮的時候，是不是可以考慮成 Q、K、V 三種向量。[00:51:45]（寫黑板）所以它的重點呢，因為有 Q、K、V 三種向量，我們想要從每一個 $X_1, X_2 \dots X_T$ 裡面產生三種不同的向量。第一種向量叫做 Q 向量，寫成 $Q_t$；第二種向量叫做 K 向量，寫成 $K_t$；第三種就是 V 向量，寫成 $V_t$。它全部都是從 $X_t$ 變出來的。它只是第 t 個字另外的特徵代表向量。[00:52:45]這怎麼產生出來？其實很簡單，就是想辦法乘一個矩陣就好了。記得它做列向量，所以要乘上一個矩陣的時候，它就乘上 $W_Q$。為什麼寫成 W？就是因為它就是一個權重的矩陣。這個 W 怎麼來的？就學來的。我們在訓練 Transformer 的時候就把這個 $W_Q$ 給學出來，就是這麼簡單。[00:53:20]第二件事情，那 $K_t$ 怎麼出來的？當然也是 $X_t$ 再乘上另外一個矩陣叫做 $W_K$。一樣學來的。然後 $X_t$ 乘上 $W_V$ 矩陣，一樣學來的。這三個矩陣都學來的，沒有什麼特別了不起的地方。[00:53:41]再一次，你可能會問說我們真的要做那麼複雜嗎？我們不能用 $X_t$ 就代表 $X_t$ 自己嗎？答案就是可以啊。但是顯然把它化成三種另外的表示方法可能會變得更一般化一點點。既然 Google 這一套出來成功了以後，應該也很少人會很認真的想要去改。[00:54:48]所以我們最後的目標，今天的 $X_t$ 這個字出來了，我想要產生的就是 $H_t$，這一個代表它在第 t 個時間點的記憶或是特徵代表向量，然後我們想要預測下一個字。Transformer 要做的事情就是這樣。[00:55:10]你認真想，它就跟 RNN 要做的事情是一模一樣的，只是 RNN 是要一個字一個字讀才能產生 $H_t$，但是現在 Transformer 想要做的事情就是我可不可以平行化一次算完。然後就把所有的時間點的 $H_1$ 到 $H_T$ 全部一起算出來。[00:55:36]這個 $H_t$ 其實就是我們剛剛說過的，想辦法找到一個神秘的係數，把這個 Value 加起來。就是 $\alpha_1$ 乘上 $V_1$，加上 $\alpha_2$ 乘上 $V_2$，目標就是要得把前面的係數算出來，$\alpha_t$ 乘上 $V_t$。[00:56:11]為什麼一定要加 Value？沒有特別的原因。Key 聽起來就是要跟人家 Key，就是它的關鍵向量，所以它基本上很自然就是要跟 Q 去做它的相關性強度。所以 Q 跟 K 都是要去做相關強度的時候用的，那 Value 就最後的要把它的做線性組合的值。所以我們現在唯一的問題就是 $\alpha_1$ 到 $\alpha_T$ 是怎麼算出來。[00:57:08]我們現在開始算。假設我們現在要考慮的字就是 $X_t$，我們看到這個可愛的 $X_t$。我們知道 $X_t$ 會伸出來一個它的特徵代表向量 $Q_t$，其中一個特徵代表向量我們把它叫做 Query。[00:57:42]然後這一個呢，我們就會跟剛剛說過要去跟每一個字的 Key 做 Attention 強度。就是 $K_1, K_2, \dots, K_T$ 去做 Attention 強度，也就是注意力強度。我們把它寫成 $e_1, e_2 \dots e_T$。[00:58:22]那個注意力的強度我們要怎麼樣去定義？開心怎麼定都可以。其實我覺得最有道理的其實就是我們剛剛說的，拿 Q 向量和 K 向量送進一個神經元去訓練它，出來的就是注意力強度。順便說一下，這是最好的方式，Google 後來也發現了，因為完全客製化的 Attention 函數算得比較好。[00:59:32]但是因為 Google 真的很喜歡我們把它寫成這樣子，就是定義一個函數，Q、K 產生一個數字出來。Google 的定義方法其實很簡單，就是如果有 Q 向量、有 K 向量的話，它其實定義就是把他們兩個做「內積」(Dot Product)，結束，就這樣。這就是 Google 的定義。[01:00:20]所以這個 $e_1$ 到 $e_T$ 其實就是 $Q_t$ 這個特徵代表向量跟其他的特徵代表向量去做內積，然後算出它的注意力強度。算完了以後做什麼？就做 Softmax。Softmax 就是把注意力強度 $e_1$ 到 $e_T$ 算一算以後產生的 $\alpha_1, \alpha_2$ 到 $\alpha_T$ 這些數字，因為做了 Softmax 所以加起來是 1。[01:01:32]因此我們最後就定義 $H_t$ 就定義成這個數字：$\alpha_1$ 乘上 $V_1$ 加上 $\alpha_2$ 乘上 $V_2$ 加等等加上 $\alpha_T$ 乘上 $V_T$。所以整個 Attention 的機制就是這樣做的。每一個 $H_1$ 到 $H_T$ 全部都是這樣算的。[01:02:00]當然我們最後一個問題是它為什麼可以平行化運算？我們現在來算給大家看。如果你用神經元去算還是可以平行，但是如果是我們今天是用內積算注意力強度的時候，你會發現那個不只平行化，還可以寫出漂亮的公式來。[01:02:28]整個計算過程，如果真的把它全部寫出來的時候是這樣子。它又定了幾個矩陣：首先是 Q 矩陣，很喜歡寫列向量哦，所以就是 $Q_1, Q_2 \dots Q_T$ 寫成列向量，每一個都是寫成橫的。然後 K 矩陣就是 $K_1, K_2$ 都寫成列向量的形式。然後 V 矩陣就是 $V_1, V_2$ 到 $V_T$ 就是這樣。[01:03:31]我順便說一下，如果我們再加上一個 X 矩陣，把 $X_1$ 到 $X_T$ 寫出來，你就會發現一件事情：比方說 Q 矩陣剛剛好就是等於 X 乘上 $W_Q$。它可以一次算出全部的。一個矩陣乘法它就把全部算出來了，所以 GPU 要很會算矩陣。[01:04:13]好，那我們現在回頭來一個一個看。假設我們現在是 $Q_t$ 想要把它算出來，我們的目標是 $Q_t$ 進來了以後，我們想要產生 $H_t$。這個 $Q_t$ 我們剛剛已經說過想要做內積。內積的時候，我們就會發現說 $Q_t$ 這個向量（是列向量）乘上第一個 $K_1$ 做內積的時候，$K_1$ 要寫成直的它才做內積嘛。$K_2$ 也要寫成直的，到 $K_T$ 也要寫成直的。[01:05:15]你就可以發現這一個一次就把全部的 Attention 強度全部一次算出來。因為這個算完了以後，它就是 $e_1, e_2$ 到 $e_T$。一個矩陣乘法再一次把全部的 Attention 全部算完。如果我們觀察一下，因為本來這個可愛的 K 是橫著寫的（一列一列），然後現在變直的了，所以它其實是 K 的「轉置」(Transpose)。[01:05:58]因此這個數學式子，目前就是 $Q_t$ 乘上 $K$ 的轉置 ($K^T$)。這第一步做完了，$Q_t$ 乘上 $K^T$ 就一次算完全部的強度。然後這個數字不一定加起來等於一，所以我們就做 Softmax。做了 Softmax 它就會算出我們剛剛的 $\alpha_1$ 到 $\alpha_T$ 這些加起來等於一的數字。[01:07:09]再來就是漂亮的地方。這個數字因為我們要把 V 向量做線性組合，就是 $\alpha_1$ 乘上 $V_1$ 加上 $\alpha_2$ 乘上 $V_2$ 等等。大家如果還記得的話，線性代數矩陣乘矩陣裡面最重要最重要的事情就是：如果前面是列向量（$\alpha_1 \dots \alpha_T$），乘上一個 V 矩陣，V 矩陣又是橫的（第一列、第二列...），這樣乘的時候，我們就會發現剛剛好是把每一個做線性組合。就是 $\alpha_1 V_1 + \dots + \alpha_T V_T$。線性組合就結束了。[01:08:17]所以 $H_t$ 到底怎麼出來？剛剛所有做的過程就是我們可愛的 $Q_t$ 拿來跟誰相乘呢？就跟 K 的轉置矩陣 ($K^T$) 相乘，然後開始做 Softmax，最後再乘上這個大 V 矩陣。這樣乘完了以後就變成 $H_t$，這個超級漂亮。[01:09:17]其實根本不用一個一個帶進去，你把所有的 Q 一次帶進去。也就是說，所有的 Q 矩陣雖然是一個一個算的（前面出列），$Q_1$ 出來就算出 $H_1$，$Q_2$ 出來就會算出 $H_2$。所以你會發現說，事實上我們可以一次把它乘上 $K^T$，然後做 Softmax，然後再乘上 V 矩陣。這個算就全部一起算完。算完的是什麼呢？第一列就是 $H_1$，第二列就是 $H_2$，最後一列就是 $H_T$。[01:10:20]所以你就會發現，有了這個 Attention Model 之後，一次什麼都算完了。這就是 Attention 整個的過程。其實 Google 最得意、最滿意的就是最後這個式子，因為你就會發現這個是漂亮，就真的只是矩陣乘法。[01:11:03]雖然其實我們一步一步做的話，你會覺得很簡單，如果真的想弄懂的同學，回去可以再一次自己去想看到這整個過程是什麼。然後你就會發現這個對自己會非常的有信心，因為你真的可以自己完全做出來，因為全部也沒有什麼特別複雜的動作，就是矩陣乘法。[01:11:47]（切回投影片）我們再度的看一次，剛剛說完的那些事情。K 矩陣可以一列一列寫出來，V 矩陣可以一列一列寫出來。每一次要計算的時候，Q 其實一次就可以算完它的 Attention 強度。Q 要跟 $K_1$ 做 Attention 就做內積而已。然後其實就是 K 的矩陣轉置。然後算完了就算出 $e_1$ 到 $e_T$，這個時候我們做可愛的 Softmax，之後就會算 $\alpha_1$ 到 $\alpha_T$，那些加起來等於 1 的數字。那我們就可以把它當作我們的強度，把 $V_1$ 到 $V_T$ 給加起來。[01:13:21]所以我們可以寫出一個非常漂亮的式子，就是經過 Attention 的計算的話，它就會等於我們講的這個公式。它可以一次生成這些 $H_1$ 到 $H_T$。我們在訓練的時候就會說 $H_1$ 就要預測下一個字（其實要預測出 $X_2$），$H_2$ 就要預測下一個字。最重要的重點就是 $H_T$，因為前面的都是已經我們已經已知的字，$H_T$ 就是要預測真正的下一個字 $X_{T+1}$。[01:14:22]如果一次算出來的公式就是像這個右邊的公式：$Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_k}})V$。如果你在生命中間不知道什麼原因，有看過 Google 的 Attention 或是其他地方看到這個 Transformer Model 的時候，你會發現這個公式好像跟 Google 給的公式有一點點不一樣，好像簡化一點點。沒有錯，簡化了哪裡呢？Google 就有另外一個很懸疑的數字，它就在 Q 乘上 K 做內積那邊，它有除以一個數字叫做「根號 $d_k$」($\sqrt{d_k}$)。那個 $d_k$ 就是 Key 向量的維度。[01:15:10]在原來的論文裡面有用各種的方法去告訴你說除以 $\sqrt{d_k}$ 是很有道理的。事實上你真的知道了以後，其實你要除以任何的數字其實都只是大家大部分都會學 Google。其實目標就是我們在做 Softmax 的時候又來一次，我們在之前就討論過 Softmax 是一個「贏者通吃」的 Model。我們在做 Softmax 的時候，你會發現說本來比方說 3.9 跟 3.2 差不多欸，本來好像只差一點點，經過之後，哇這個差距就變拉大、拉得非常大，差了一倍。[01:16:07]原因是什麼？就是因為 3.9、3.2 這個數值對電腦都太大了，這後面衝太快了。因此如果除上一個數字了之後，除上的數字就跟我們的 Temperature（溫度）的概念是一樣的，除上一個數字它就會拉近。那所以它的機率就會看起來是比較像、比較符合我們本來的那個分數的感覺。[01:16:47]簡單的說，它就是跟 Temperature 做的作用一樣，就除上一個數字，讓它比較接近零。比較接近零的時候，那個感覺就比較不會被那麼明顯的贏者通吃。Google 發現特別在做內積的時候很容算出很大的數字來，所以很容易「出亂子」。這也是 Google 他在寫文章的時候他就發現了，所以他就覺得我們還是應該用內積，那用內積就會有這種會出亂子的情境。所以會讓那個第一名拉得比第二名拉得比合理的距離更遠，所以這樣子好像算出來的就效果沒有那麼好。[01:17:56]因此它就除以一個數字叫做 $\sqrt{d_k}$。再一次，這個 $\sqrt{d_k}$ 我們可以當成一個超參數 (Hyperparameter)，就是我可以自己定、我可以自己調。所以你要除以一個根號 9487 也可以，總而言之就除以一個數字，讓大家都拉得比較接近零。比較不會讓 Attention 做出來的那個第一名佔太大的便宜。[01:19:31]這個就是 Attention Model 的基本型。後來大家又開始認真想，這個 Attention 只能有這一種嗎？比方說我今天在看一篇文章的時候，有時候我注意的事情是語意上的關聯性，有時候注意是文法的關聯性。所以他們就想說 Attention 是不是可以有「多頭型」的 Attention？所以它最後就是 Multi-Head Attention，其實很好做，就是多乘不同的向量出來就變成多頭的 Attention。它的 Attention 不一定只有產生一組 QKV，每一個字產生好幾組的 QKV，就這樣子。[01:20:42]所以 Attention 要做的事情、Transformer 要做的事情就是這樣子。（接下來講述 Encoder 和 Decoder 架構）
[01:20:42]說完了，所以 Attention 要做的事情、Transformer 要做的事情就是這樣子。然後我們看一下原始論文。原始論文裡面，Transformer 在 Encoder 跟 Decoder 的時候設計不一樣，也就是在讀那些字的時候，跟要生成下一個字的時候，那個模型基本上有一點點不一樣。我們來說明一下。[01:21:23]這個大家其實不用太在意，因為老實說現在的世界裡面，很多模型其實只用 Decoder 那邊。特別是 OpenAI 在 GPT-2 出來以後，它其實就只用右邊 Decoder 那邊。我們只是很快地說明一下，以防大家在生命中間哪一天突然看到一篇文章正在講 Transformer 的 Encoder 跟 Decoder 的時候，大概是這樣子。[01:21:56]我們先看 Encoder 的架構。Encoder 的架構基本上就是我們先進到剛剛所謂的 Multi-Head Attention。那它為什麼叫 Self-Attention？因為它是同樣的，就是前面的那一個句子進來了，$X_1$ 到 $X_T$ 是同一個句子裡面出現的。你會發現它其實是自己跟自己做注意力的模式，每一個字跟其他的字，就是這一句話其中的字跟其他的字去做注意力的強度。所以這種叫做 Self-Attention，就是自己看自己。[01:22:49]有沒有可能未來更一般化的情境，Q 跟 K、V 一點關係都沒有？有可能。未來你會發現很多應用，有可能 Q 跟 K、V 的關係都沒有，那種就不叫 Self-Attention。Self-Attention 就是自己的句子裡面，自己跟自己做 Attention。然後做完了以後就會產生吐出一堆的向量，再用全連接層做總整理。你會發現幾乎所有的神經網絡最後都是用全連接做總整理，因為全連接最容易整理出我們最後想要的樣子。[01:23:28]所以它的 Encoder 每一層是長這樣。這只是 Encoder 的一層，Transformer 的一層。雖然它其實至少有兩個 Layer，但它只把這個叫做一個 Layer。它的第一個 Multi-Head Self-Attention 那邊，它把它叫做 Sub-layer（子層）。那時候大家完全看不懂，不知道大家說什麼，什麼叫做 Sub-layer？為什麼一個神經網絡的某一個隱藏層裡面還有一個子層？其實沒有什麼特別的，反正他就覺得這是一個單位。你要用 Transformer 的時候，你就是把這兩個全部一起，就是做 Self-Attention 再做全連接層。[01:24:12]那我們再看右邊 Decoder 的部分。Decoder 的部分，第一個部分也是做 Self-Attention，但是現在有一個奇怪的字眼叫做 Masked Self-Attention。等一下我們會解釋什麼叫做 Masked Attention，其實很簡單。[01:24:37]第二層就是比較標準的 Multi-Head Attention，而且這個時候前面的 Masked Attention 這邊傳來的只有 Q，那 K、V 從誰來呢？K、V 是從 Encoder 來的。所以這就標準的不是 Self-Attention 了。其實也不是那麼重要，就 K、V 從前面傳來就對了，然後 Q 是從下面伸上去的，再來就是經過 Feed Forward 層整理一下就出來了。所以一樣它把這三層，雖然是三層，它還是叫做 Sub-layer，整個包起來只是 Decoder 一層而已。[01:25:11]老實說，如果未來在生命中不再有除了跟人家吹牛之外，不會再想要這麼看到 Transformer 這麼底層的...其實生命中應該也不會再看到它了。但對人家吹牛的時候，人家會覺得你真的超級懂。所以我還是建議大家可以稍微知道說它後面的底層的架構大概長什麼樣子。[01:25:47]再來唯一我們才需要解釋的就是 Masked Multi-Head Attention。Masked Attention 其實有一點點騙人，因為我們知道 Attention Model 其實就是要預測下一個字。你會發現，比方說我們之前介紹過，第一個字進來了以後，它就會預測下一個字，下一個字它就會拉下來變成第二個字，所以輸入層就會有兩個字了。然後再預測下一個字。[01:26:24]在輸入兩個字的時候，其實後面的字還沒有出來啊，還沒有生出來。那怎麼辦呢？沒有怎麼辦，我們就把它遮住。其實不是真的遮住，是用數學的方法，就是它不要參與計算。假設我們現在只有一個字的時候，後面的字我們就把它遮住，事實上就是沒有字。沒有字的情境之下，就是它不要參與計算。簡單的說就是這樣。[01:26:50]所以我們把它叫做 Masked，遮蓋了後面的那些字。事實上是還沒有產生，你怎麼知道字長什麼樣？所以我們沒辦法做 Attention，我們唯一的就只有已經出現的字去做 Attention。所以這個叫 Masked Attention。這樣可以嗎？[01:27:12]如果大家有問題可以說一說。Attention Model 就是長這樣子。再說一次，在你的生命中間，總有一天你應該要花一點點時間去了解 Attention Model 的話，就是這一次。你能了解多少就盡量了解多少，不用有太大的壓力。因為我們在所有的作業裡面，其實不會考大家這件事情。[01:27:40]大家一定會覺得心中很不滿意，為什麼經過這麼多痛苦之後才講這句話？其實還有一個很重要的原因，因為在未來的生命中，我們很難預測會發生什麼事情。也許你要做一個應用問題，但是你會發現你需要比較了解 Transformer 後面的機制到底長什麼樣子。你可能就要回想在你的生命中間有一刻就在聽這些東西，然後你就會有一點點印象。你去看那些文章的時候，你就會很清楚他哪邊在亂說，哪一邊把簡單的東西說得很複雜。[01:28:28]後面最後還有一點點小事情要跟大家解釋。這個其實我覺得比前面的 Attention Model 更複雜。更複雜的原因是因為這個幾乎寫完了以後沒有人看得懂。如果你花了很多時間去看前面那個部分，雖然很辛苦，但是總有一天你會弄懂前面就真的在做這些事情。但是後面有一個非常懸疑的叫做 Position Encoding（位置編碼）。[01:28:55]為什麼要做 Position Encoding？我稍微解釋一下。如果你回想剛剛的 Attention Model，RNN 沒有問題，它一個字出來吐出 $H_1$，第二個字進來再吐出 $H_2$，第三個字進來再吐出 $H_3$，它的順序非常的清楚。可是你發現做 Attention 的那種模型的時候，它都只是做內積，然後決定強度，決定強度就把他做線性組合起來。你會發現它一點前後的關係都沒有考慮，完全沒有考慮。它完全只考慮那個向量長什麼樣子，就是 Q、K、V 那一系列的向量長什麼樣子。[01:29:47]在這樣的情境要怎麼辦呢？其實很簡單，我們就把那個位置的資訊加進去就好了。Position Encoding 就是要做這件事情。我們怎麼樣把位置的資訊加進去？答案就是你愛怎麼加就怎麼加。那為什麼 Google 要這樣加？我們現在來解釋一下。[01:30:14]位置資訊其實你也可以自己編啊，第一個位置的時候叫做 0.3、0.1、0.01 隨便。反正就固定一個向量，那個向量的指標（數值）不要太大，免得影響這原來的 $X_1, X_2$ 他們本來的向量長相。所以我們做 One-Hot Encoding 就不太適合。比方說我們有時候會希望第一個位置叫做 100，第二個位置叫做 01...為什麼不做這樣的事情？原因是因為這個「1」其實在神經網絡的 Model 裡面有點大。[01:31:00]然後我們就來發現一件事情。如果我們考慮一個數字的時候，比方說考慮十進位 9487 好了。你會發現每一次這個最小的那一個數字的進位頻率（最快），下一次就是變成 9488，再下一個就變成 9489。所以它的變動頻率就是這樣。[01:31:37]然後第二個十位數那邊，你就會發現這個變動的是十分之一。因為下一個數字是 8、9、0，然後經過了 10 個數字，那個才會變成 9。所以它頻率是十分之一。再下一個頻率是百分之一。總而言之，個位數的頻率是最大的，變化最快，然後再來就是依次遞減。[01:32:07]我們今天如果想要做一個數字系統，因為在 Attention Model 裡面，我們輸入的字越來越過分了。像 GPT 剛開始的時候它可以輸入 2000 多個字，後來越來越誇張。所以我們就在想說，那可不可以它的頻率是可以隨我們高興的連續型的？它是連續函數，有週期性。其實只要找到連續函數有週期性，然後數值不要太大，其實就只有 Sin 跟 Cosine。它再怎麼大也不會大於一，很符合我們可以在某種程度控制它的情境。[01:33:14]比較特別的是 Position Embedding 是跟我們平常寫的數字相反的，低位數寫在前面，高位數寫後面。反正也沒有關係，因為這只是概念上。比較特別的是它是兩個兩個一組。[01:33:28]你會發現在原始的論文裡面就寫了一個非常懸疑的東西，就是 $\omega_0$ 到 $\omega_k$。唯一不一樣的地方就是 $\omega_0$ 它的頻率是最高的，然後再來 $\omega_1, \omega_2$ 等等，前面的頻率最高，後面的頻率越來越慢。這符合我們本來的數字系統的表示方式，前面的頻率是最高的，後面頻率越來越慢。[01:34:04]它通常是兩個兩個一組，為什麼要兩個兩個一組？沒有為什麼，你高興就好。你今天用另外的，你可不可以只用 Cosine？也可以。你可不可以只用 Sine？也可以。但是為什麼他用 Cosine 跟 Sine？我現在解釋一下。因為如果你回想起極座標系統，你就會發現極座標圓上的一個點，都可以表示成 Cosine 跟 Sine。Shutterstock[01:34:45]它其實目標只是做這件事情。我們可以根據它的頻率，就是有時候它繞一圈比較快，有時候繞一圈比較慢。你就可以用極座標去表示它。所以為什麼要兩個兩個一組？就是因為極座標本來就兩個兩個一組。[01:35:08]但是你會發現原始的論文裡面就長這樣子，這跟極座標不太一樣。因為極座標裡面如果我們高中數學念得很好，就知道極座標轉換的時候是 Cosine 在前面，Sine 在後面。為什麼現在 Sine 在前面，Cosine 在後面？因為你畫圖出來的時候，你就會發現 Sine 寫前面的時候，這完全跟時鐘的走向是一模一樣的（順時針）。不然本來的時候是逆時針走的，感覺上比較不像時間。那現在比較像順時針的方向走。[01:35:50]那你可不可以不要搞這一套？你可不可以用原來的極座標？當然可以。所以說你知道原理的話，你就會發現這沒有那麼好。不然的話你不信的話，你去翻所有在解釋這個 Position Embedding 的，一個比一個懸疑，比 Transformer 原來的 Attention Model 還要懸疑。[01:36:09]但你知道原因的話，不管他說得再懸疑，就知道他只是要找一個特別可以表示某一個位置的代表向量，很有系統的把這些每一個代表向量給算出來。你為什麼不用擔心？因為他在學習的過程，因為你給了那麼多次，所以他自己會想辦法弄出知道說那個是代表位置的代表向量。[01:36:38]沒了，我們把 Transformer 幾乎該講的話全部講完了。我應該要稍微快速一點點。Transformer 其實加了所有比較穩定的 Model，我們這邊只解釋一個很重要的叫做 ResNet 的設計。ResNet 其實只是做這件事情：本來自己下來了以後會經過某一個隱藏層，就是 $L(g)$，然後 $L(g)$ 就會想辦法送到下一個隱藏層。[01:37:17]ResNet 的設計很有趣，它就是把前面的記憶再把它送下來，意思就是說送到最下面那一層其實是 $L(g)$ 加上原來的 $g$ 一起送下去。它只做了這件事情。本來某一層的輸出是 $L(g)$，現在變成 $g + L(g)$ 然後再輸出。[01:37:46]為什麼只做了這件事情，它就可以達成訓練上比較好訓練？原理也很簡單。本來我們會依賴 $L(g)$ 去想辦法跟我們最後的正確答案越接近越好。現在變成說加上 $L(g)$ 兩個合起來越接近越好就可以了。[01:38:09]這差別就是在：本來的 $L(g)$ 就直接要學到 $F(g)$；現在是 $g$ 可以當成是我們之前已經學到的狀態，$L(g)$ 就變成說前面沒有學到的，我再補學就好了。如果你前面幾乎已經學得很好了，那我後面幾乎就不用學了。所以它會把整個的學習重心往前移，所以它就會讓比較深的神經網絡真的可以運作。[01:38:41]這邊有一個很有名的圖，左邊是沒有使用 Skip Connection (ResNet)，很容易卡在山上的一個地方。但是你經過 ResNet，它就很平順的，每一次會滑到山谷底面去。所以整個概念大概是這樣，它就讓神經網絡變得更穩定。所以在 Transformer 裡面設計，它其實有做這件事情，原始論文就會發現有做這件事情。[01:39:40]對不起佔用一點時間解釋一下今天的作業。今天的作業大家不用擔心，不會說這個 Transformer 你看到了，你到底學了什麼，要你把 Transformer 再重新說一下。沒有這種作業，大家不用擔心。[01:39:59]我們要做的事情其實跟上週做的有一點點相似，但是有點不一樣的地方。上次我們說過，在所有的下 Prompt 的技巧裡面，因為我們只是預測下一個字的模型，所以希望大家去找網路上任何的 Prompt 的技巧。[01:40:30]你就找一個技巧是你覺得真的有用、有幫助的。你覺得沒幫助就不要理他了。你介紹那個技巧，那個技巧是從哪裡來的，你可以稍微介紹一下。你一定要稍微想一想，這個到底對你來說有沒有幫助。[01:41:31]第二件事情，解釋一下這個技巧跟我們原來要說的「提供足夠多的資訊」還有「清楚的指引」這兩件事情到底有什麼關聯性。你去想清楚就會發現真的每一次都是要做清楚這兩件事情。[01:41:48]第三個，就是你實際的去示範用一次。希望用的是真的跟你日常生活有關，或者跟訊息有關。反正你要真的有實用的，然後你要真的覺得有趣。不要寫了一個你自己都沒有覺得很有趣的例子。要解釋一下為什麼你覺得很有趣，因為有時候助教看了會不知道那個為什麼有趣。然後示範這個技巧的使用方式，當然要貼那個語言模型的回覆。至少貼一個啦，也非常歡迎大家多試幾個不同的語言模型。[01:43:03]（助教劉奇斌）：我是奇斌助教，那今天的課開始。我們先請賴宏廷同學分享他今天的閃電秀。[01:43:15]（同學賴宏廷）：各位老師同學大家好，我是台大電信所碩二的賴宏廷。那今天想要跟大家介紹就是 Personalization of Text-to-Image Diffusion Model，基本上就是文字產生影像的 Model。[01:43:36]如果我們用文字去形容一張影像的時候，通常是由它的基線所在的。就可能說我可能要產生一個吉娃娃，然後就是我想要吉娃娃的樣子。那它可能會產生像這樣子的圖片。那你可能心中想的是譬如說這隻娃娃照片好了。那要怎麼樣讓 Model 知道說我想要的吉娃娃都是長這樣子，而不是長這樣子的呢？[01:44:03]那基本上就是我們可以告訴這個 Model 說，我想要的影像是長什麼樣子，然後再去做 Fine-tuning（微調）。這是我之前修機器學習的一項作業，所以覺得蠻有趣跟大家分享。[01:44:19]那是怎麼做到的呢？基本上它也是用這篇 Paper 的方法。基本上就是我去找我自己想要狗長什麼樣子的一些圖片，然後我就給他一個 Token 叫做 [V]。然後我們就告訴 Model 說我之後的狗都要長這樣子。那他就會去學習說它的那些特徵長什麼樣子。[01:44:50]之後我可能再產生這些狗，我的狗要長什麼樣子，它就是長這些樣子。它就會產生譬如說狗在海邊，或是狗帶著墨鏡，或者是狗在一張油畫裡面。[01:45:20]這是我自己做的小作業。我今天就是給 Model 一張海龜的照片，我就給他一個 Token 叫做 "ne one"（註：自定義 Token），就是這是一張 ne one 的海龜的一個毛絨玩偶。然後餵給 Model，做 Fine-tuning。Fine-tuning 之後我們再給它一個 Prompt，然後我這可以產生我想要的海龜在哪些場景。（中斷，網路連線問題）[01:47:00]（同學重新連線）最後兩張海龜就長得蠻成功的，就會長得蠻像這隻照片，給的照片。然後最後一張也算一半一半，有點奇怪，但還算是符合我的想像。大概就是說我餵給一張照片，然後還會依據我這張圖片的特色，去產生我想要的這張照片的樣子。謝謝大家。[01:47:57]（助教劉奇斌）：好，謝謝同學的閃電秀分享。那我就開始今天的助教課。今天我主要會講兩個 Topics，一個是 Prompt Engineering。講完這個之後，我會稍微講 Finance，因為我是學金融的，所以我想要講一些有關 Perplexity Finance 怎麼應用。[01:48:39]Prompt Engineering（提示工程）其實就像老師講的，你要怎麼去精準的設計你的 Prompt，讓 LLM 去了解你的需求。如果你 Prompt 寫得好的話，可以讓你的這個模型更去預測說你可能需要什麼答案。所以如果你把這個提示工程做好的話，其實它可以提升你回答這個答案的品質或準確性。[01:49:18]第二就是說，因為一般來講我們都是直接使用這個大公司訓練好的模型，我們不會特別去對它模型本身的參數去做修改。那我們要怎麼讓它盡量去達到我們的需求呢？我們就需要透過設計我們的 Prompt，去讓它的回答是盡量貼近我們的需求。[01:49:44]或者比如說你在寫合約，有一些一定不能寫上去的東西，那你就可以在請 AI 幫你生成這合約的時候，你就寫說不可以有酒精活動等等之類的提詞。你把它寫上去，就可以確保這個合約寫下來的時候不會有那些你不想要的關鍵字。[01:50:14]再來就是說，如果你有常常做的任務，比如說你是做金融的，你常常需要 AI 幫你做財報的分析。那我們可能會希望你可以把 Prompt 寫好，把公司挖空，那你就可以去代換。比如說代換成 NVIDIA、代換成 Tesla、換成 Google 這樣子。那你其他東西都一樣，我們就只換這個東西，那你這個 Prompt 就可以一直重複做使用。[01:50:52]一般來講大家一開始在使用 Prompt 的時候，都是像 Zero-shot 模式，其實就是說我不提供範例，直接給一個描述或者是問題。如果你的問題真的很簡單，比如說把這句話翻譯成英文，那以現在的大型模型，基本上都可以幫你做到很快又很準。這種簡單的 Case 可能就不需要特別再去設計。[01:51:36]再來可能會像 One-shot 或是 Few-shot。One-shot 其實就是你給一個 Example；Few-shot 原則上就是給三個到五個 Example。為什麼 Prompt 可能要加入 Example 呢？因為比如說你有特定的生成格式，比如說你交作業有一個固定要交的格式，或者是說你希望這個格式它的用字是你熟悉的。[01:52:18]那我就可以透過設計這個 Prompt 然後給他 Example，讓它之後的 Output 都用我的格式去回答。我覺得 One-shot 或 Few-shot 是現在比較常用的。除非你的任務真的很複雜，不然大部分都可以幫你做一些格式的規範。[01:53:33]比如像右邊這個 Google 他們出的 Prompt Engineering 白皮書的範例。他現在想要做的事情就是說，我輸入 Pizza Order，然後 "Pizza with cheese tomato sauce and pepperoni"。那我要用一個 JSON file in response，而且有特別規定 JSON file 想要用 size, type, ingredients。如果你這樣去做這個規範的話，它之後的 Output 就一定會嚴格的去執行它上面的這個規範。[01:54:16]如果沒有，如果直接只有輸入上面的話，它可能就會變成像這樣子： "So cheese topping"，它全部都分開寫了，那這可能就不是你想要的樣子。所以你就可以像這樣，真的把想要的東西都放在一起。[01:55:12]那 Sentiment Analysis（情感分析）也是像這樣子。比如說你可以 Example 說 "I absolutely love this product"，你就用一個 Positive；第二個 Sample 你就給它標記一個 Negative；第三個標記你做一個 Neutral。如果你真的要自己從頭開始建的話，需要很大的樣本。但因為畢竟 ChatGPT 它已經幫你訓練好了，如果你想要更清楚的去分類這些情緒的時候，你可以再給他幾個 Example。[01:55:57]再來就是對話生成，你也可以給他很多 Example。比如說你給他 Assistant，你就說 Assistant 就是一個助理，這給你一個回覆。其實它這樣做的話，現在基本上也會去學，比如說你大部分都用什麼字，或是說你的語氣大概是想要長什麼樣子。[01:56:23]可能你們在做客服的時候，你們就會需要說盡量它是要符合你們店的那個規範。其實也有可能你們以後做一個客服的軟體的時候，你可能會想說我想要做一個很火爆的。那這個時候你就可以把你的提示詞都設計得可能很符合你們店裡面的風格。[01:57:04]那接下來的話，其實做一個小的測試好了。這裡我幫大家準備了一個小小的 Data。這應該直接下載也可以，就是我之後把這個放上去之後，你們也可以自己下載這個 Data 下來。[01:57:51]這個 Data 上面就寫 2013 to 2016，那你就知道他應該是 13 年到 16 年的資料。它就包含了台灣的上市公司的 Company ID，還有它的 Date（年月日），它的價格或是它的 Return，發行的股票數量或是它的市值。我們常見就是可以把 Return 再做一個 Log 這樣子，或是一些財務數字。[01:58:36]比如說我們在做這種像是財務分析的時候，我們會需要什麼？我們會需要 Year、Month 不要這樣分開，我們會通常希望把它合在一起。所以你可以怎麼樣？你可以去 ChatGPT 裡面，你直接把剛剛你下載好的 Data 丟進去。[02:00:16]那基本上它會用 Python 幫你做年月日合併。通常它會給你的格式會是 2015-11-12 這樣的格式，因為這是財務分析他們最常用的格式。如果你說你想要特別像我剛剛講的樣子（例如中文年月日），你可能就要跟他說。[02:01:14]你們應該直接把這個資料夾丟進來就可以了。直接跑，那它就對啊，我說一般來講它就是會給你這個（標準格式）。那如果你說你想要特別像我剛剛講的樣子，我們再開一個新的 Prompt。
[02:00:04] 通常它會給你的格式會是像 2015-11-12 這樣，它就會幫你合併成這樣子的資料。因為這個是財務分析他們最常用的格式。那你可能想說因為這個是最多人在用的，那你可能不想要這樣子，你今天可能沒有特殊需求，你說我需要我的資料要直接年月日合併，那你可能就要跟他說。

[02:01:02] 你們應該直接把這個資料夾丟進來就可以了。但如果你直接這樣加的話，這次跑完之後它下次會不好。那你就直接跑，對啊，我說一般來講它就是會給你這個。因為這個是做財務分析他們最常用的格式。那如果你說你想要特別像我剛剛講的樣子，那我們再開一個新的 Prompt，因為這樣可能它會有記憶。那我們一樣就是你再把它丟進去一次。

[02:02:56] 好，那等它跑一下好了。那基本上你就是預期說他跑完之後就會像我剛剛講的樣子。我覺得這個是可能現在大家在用這個 Prompt 的時候比較常用的技巧之一，就是你真的有特殊需要的格式的時候，你在做這個動作。

[02:04:14] 好，那就是變成你要的格式了。我覺得是算現在大家蠻常用的功能啦，尤其是在做財務的時候，你想要怎麼去規範你的格式，你就可先跟他說你想要做什麼，那我們就接著照著那樣。

[02:04:35] 那再來可能是 System, Contextual and Role Prompting。第一個就是 System Prompting（系統提示）。提示就是說，你現在看的是使用者介面，那你可能沒有辦法去改這個系統提示。但如果你是去調用這個 API，或者是開發者在開發的時候，他就可以賦予 GPT 一些任務，那它是一定要去大方向要去遵守的。

[02:05:08] 那可能有一些就是大方向你想要這個模型想要做的事情，像上面講這些語言翻譯或是評論分類等等，你就可以規範在 System Prompting。那你一般在使用 GPT 的時候，你不會直接去改這項指令。那你可能會做就是這個 Contextual Prompting（上下文提示），或者是去 Role Prompting（角色提示）。

[02:05:38] 那上下文提示是什麼？就是說你今天 Assign 一個任務給你的 LLM，那你當然是想要寫得越清楚越好。因為如果你只給他 Data，那他就不知道說他到底需要做什麼事情。像這是一個上下文提示的例子，就比如像我剛剛那個 2013 年到 2016 年的日度的數據，我剛才也有看到嘛，裡面就是有代碼、公司名稱，然後還有一些報酬或是它的 Market Value。

[02:06:11] 那你就可先跟他說清楚說這個 Data 到底在幹嘛，不要讓他自己去找。那你就說：在根據這份資料，你要做的事情是計算 2015 年市值前 10% 的公司，那他們的平均報酬率是多少。好，那你們可以就是把這個 Prompt 自己丟進去試試看。你給它越清楚的話，他越能知道說他應該要丟回什麼東西給你。

[02:06:43] 那 Role Prompting 的這個角色提示就是說，GPT 在回答的時候，你會感覺說他好像是在模仿人類講話嘛。那我們可以 Assign 說，因為我比如我今天要繳交一個財經的作業，那你想要扮演的角色是用「分析師」的角度，不要用「股市小白」。用一些看起來很白話文的字，我想要用一些那個專有名詞啊，可能各種的 Ratio 啊，或是各種的財報裡面的那些營收、P/B Ratio，就是很多那些財務的名詞。可能你自己也不會那麼多，那你就直接跟他說，我想要你用這種專業的口氣跟我講。這個就是你 Assign 他一個角色。

[02:07:32] 其實不同的角色差異真的會有差。比如說你叫小學老師去解釋天空為什麼是藍色，跟你說你用物理教授的方式去解釋天空為什麼是藍色，其實就有差別。那也是可以直接把這邊複製給...因為這個不用 Data Import。

[02:08:36] 好，那你看到說小學老師在解釋什麼藍色的時候，他基本上就是會給你舉一個例子，他當然還是會稍微跟你講一下為什麼會有這個，但是他解釋的沒有深，你看這裡面也沒有任何的數學的原理在裡面嘛。

[02:08:54] 但是如果你看到這個大學物理教授他在講的時候，他就說他直接用一個一開始就定一個名字「散射現象」，然後又講了一個「瑞利散射」。哇，聽起來就很嚇人。如果你跟國小的同學講說我們今天來講天空為什麼是藍色的，原因是因為瑞利散射，那我想應該沒有同學在國小的時候聽過你的自然老師是這樣講的。你看它會直接跟你去真的去講這些數字。所以你不同的角色在做這個 Prompting 的時候是有差別的。

[02:09:34] 好，那我們再回來看這個簡報。那再來可能就是一些更難的東西，但是這個我們今天就不要琢磨太多，我們先跟你講一些概念性東西。那以後可能老師會在後面的課程會再提到這些，因為這些已經有點牽扯到 AI Agent 的關係了。

[02:09:57] 這篇是一個 Paper 啦，2022 年的一個 Paper，那它叫做 Chain-of-Thought (CoT)。那 CoT 它其實就是說你在做這個 Prompt 的時候，你不要他一次就回答到位，你讓他一步一步的去做思考，然後再回答你想要回答的問題。所以你先讓他有點像是說，你先讓他喚起這個...

[02:10:23] 雖然老師說盡量不要問他封閉式的問題，但是你難免會去問嘛。尤其你是比較難的問題，比如說像大學的普物啊，或是你要老師要解功課，你可能回來你就發現說 GPT 怎麼常老師寫錯，就比如負號多一個負號啊，導致後面就全錯了嘛。那你就可以比如用這個 Chain-of-Thought Prompting 的概念，你就讓他一步一步的去生成他應該要做什麼，去讓他去思考，然後慢慢再推到說你最後要做的答案。

[02:11:03] 好，那這個東西它算是就是一條路走，那我們就拿這個 Final Answer 當做我們的解答。那其實 Self-Consistency（自我一致性） 也是很簡單的概念，它只是說因為我們通常在用 CoT 的時候，它是用 Greedy Decoding，就是它在計算它的文字生成的時候，它就是挑那個最高 Token。那 Sometimes 我可能就算做了這個 CoT 它也不是對的。

[02:11:32] 那我們可以 Self-Consistency 其實有點像是說，我就輸好幾次同樣的 Prompt 給 Model，那它是不是就會一直去生成不一樣的答案。或者說你就直接丟給不同的 AI 嘛，你丟給 Gemini、丟給 Grok、丟給 GPT，你都丟丟看，那看他會給你什麼答案，那你再取說哪一些是相同的這樣子。

[02:12:04] 那這個就是這也是一篇論文做出來的結果。你看他的例子就是說，如果我直接問他數學題的話，他可能會直接給我 Wrong Answer。那我丟很多次的話，那可能有幾次是 Wrong Answer，幾次是 Right Answer，那我們就看這個出現比較多次的，基本上會比較有可能是正確的答案。當然也還是會有時候是就算做這個 Self-Consistency 它也不一定會是正確，但你可以多試看。

[02:12:39] 我覺得這場應該就是大家真的就只有好幾個 AI 吧。同一個問題，因為尤其像現在 AI 有時候又會去記你問過的問題。那你直接丟不同 AI，他們之間獨立，更容易去得到...你更可以去看那些答案。而且因為你剛剛有做了這個 CoT，因為我們做這個 CoT 的動作的時候，它是會 Step 去生成一步一步的答案。

[02:13:02] 所以你還是一個概念，就是你不要什麼都不會去問 AI 嘛，你是懂的，那只是說 AI 去加速你的學習。所以你還是要有能力去判斷說你今天生出來的這些 Output 是對的還是錯的。那你可以多看幾個模型給你生成的 Output，那你就可以去更加確信說應該是某一個概念才是對的。

[02:13:28] 那比如像商務可能他們會用的例子就是說，我現在丟一個 Email，那你要判斷它是 Important 還是 Unimportant。那你如果直接就是做一次你就丟的話，那可能會比較容易誤判。那其實這個蠻重要的，因為你在商務裡面你真的很需要知道說你這個 Email 是比如說是 Urgent 還是 Unurgent 嘛，就是緊急還是不緊急，或者說這是重要的還是不重要的，那你要去做回應嘛。甚至可以說你是垃圾郵件還是不是垃圾郵件嘛。好，這個是 Self-Consistency 的一個好的應用。

[02:14:07] 前面這些大部分都是跟 Follow 一些 Google 他們給的一些觀點。那我們再看一下更多的其他的公司怎麼想，比如說像 OpenAI 它會希望你怎麼做。OpenAI 它前面還有講說你如果可以用的話，你就是還是用比較新的 Model，就是正式推出的那些新的 Model，通常還是會有效能的提升，或是他們在準確率或是什麼做更好的。如果你有疑問的話，你就用新的。

[02:14:48] 那第一個，OpenAI 想跟你講說，它是盡量說你用這個井字號 (#) 或是用這個小點點 (```)，就是用這種符號去分隔你的指令跟上下文。那尤其當你的這個 Prompt 很長的時候，你直接去做...比如你啪啪啪啦丟一段 Code 然後 Error 然後啪啪啪一段 Code，它可能會比較難去判斷或是它花比較多時間。

[02:15:16] 那你自己去把它啟示清楚說，我給你這個 Code，那我現在說我遇到這個 Error，我特別把它用這個警示套標起來。那它就比較好的去辨認說你要問的問題是 Focus 在比如你這個 Code 有 Error 這。

[02:15:33] 好，那這個應該也算是很基本的嘛。那你要具體的詳細描述所需的背景、結果、長度、格式、風格等。就是說你的這個 Prompt 要下得精準嘛。就比如你叫他說我要一個詩，他可能不知道你想要什麼風格。因為可能詩也有悲傷的詩啊，或者是讚頌的詩嘛。那你如果今天是在做那個任務的時候，你是要幫公司正面行銷，結果你寫一個他歌詞自動幫你寫一個很悲傷，那這樣也不好嘛。所以你可以寫說你要一個 inspiring about OpenAI，那 focus 在什麼地方，比如你有一個新的產品 Release，你就特別跟他講說是這個新的產品，那 in the style of famous poet。好，那你就是可以試著去這樣做。

[02:16:25] 那這個就是跟剛一樣了吧，我說的就是在這個範圍裡面。就是你真的有一個 Output 的格式，你需要去遵守的時候，你特別跟他講，模型都可以幫你做得好。

[02:16:43] 那「減少空泛和不精確的描述」，這個應該也是很正常的。就是說你盡量要寫得精確，那還是在那個主題你盡量要寫得精確。那 OpenAI 還建議你說，你不要說「不要去做什麼事情」，你盡量去說「我這個東西應該要去做什麼」。

[02:17:10] 你們PPT會傳上去，你們可以再仔細去看。你看像第一個就說 "Do not ask username or password, do not repeat"。那這個就是說他不該做什麼。那這個該做什麼的話，你就說了 "Agent will attempt to diagnose the problem and suggest a solution blah blah blah"。像這樣的形式是他們去鼓勵你們去用的形式。

[02:17:45] 那比如像我剛剛，我剛剛通常我都是會說用 Python 或什麼。但是有時候因為有時候我在寫那個 GPT 的時候，我就用 Python 它有時候就直接在本地端跑。那你有時候是因為你要做功課吧，你要複製到你的 Local 端，不管你是用 Colab 還是你要用 VS Code，你都是需要到本地端嘛。那你就可以跟他說你就直接你需要給我 Code 或是說你 Import，那他給你你再去做任務嘛。因為雖然可能你直接在 GPT 跑它也可以跑出一樣的圖片，但是你需要那個 Code 才能跑。

[02:18:23] 好，差不多就這樣子。然後我記得 OpenAI 還有一個 Suggestion 是說其實你現在可以先試著做 Zero-shot，就是說你不要給 Hint。那如果 Zero-shot 它就可以給你很好的...因為 Zero-shot 它是最 Cost Efficiency，它是最有效能、比較節能的啦，或者說它 Token 浪費數量通常是比較少。那你就先做 Zero-shot，那不行的話你再去做 Few-shot。那如果再不行的話，你再考慮去做那個模型的修改，就是做 Fine-tuning（微調）。

[02:18:57] 盡量如果可以直接透過這個 Prompt Engineering 就達到你的目的，你不一定真的要去做那個 Fine-tuning。因為你也知道 Fine-tuning 的話，你要去更新那些參數是需要你的顯卡要很好嘛，尤其像那些現在大的語言模型可能動不動就 120B，那你這個你需要多少的 VRAM 去跑你的模型？對，好。

[02:19:24] 那這個就是 Prompt Engineering 的部分就講完。其實還有很多東西，比如說像這邊 Self-Consistency 啊，或是說這個 CoT 它後面可能還會有...你說做更多樹狀呢，那個叫 ToT (Tree of Thoughts)，那我們就不講，就是提個名詞，你們有興趣的話就自己去查。其實這個領域就是這幾年的論文也是蠻多的。那我這兩篇都有附連結，那你們就可以參考一下。

[02:19:53] 好，那我們接下來就是講這個 Perplexity Finance。那 Perplexity Finance 它是什麼東西呢？它其實也是一個 LLM，就是 Perplexity AI 特別出了一個 Finance 的功能。那它的這個功能其實... Perplexity Finance 這個東西最好的優點是它對這個抓資料是比 GPT 還要好的。就是因為他抓到他真的有特別去設計我需要的財經，比如說股價啊，或是說一些公司的季報啊，或者說重大事件，他都會及時的去（更新）。

[02:20:40] 那他可能就可以做很多事情，說查詢股票的資訊，或者是說你去找歷史股價，那歷史股價的資料它也有。那比如說你想要做跨公司的比較，用 Perplexity Finance 它是可以給你更...它會去找更多的文章來做檢索。因為現在都可以聯網嘛，去檢索更多的文章然後回來做。那他也比較豐富的，他有做季報、年報啊，或是重大事件的報告。好，那一樣就是我們就是直接很多功能我們就直接上手看。

[02:21:28] 像這個 Perplexity Finance 已經進來。這個東西就是美國市場，那還有這一個印度市場，我猜是因為那個公司的 CEO 他是印度人，是他特別一定有這個印度市場。好，那你就可以看說他有美國市場、加密貨幣、收益啊。比如說這個收益就是比如說這些公司他們發的這些報告，他們發一些季報或是什麼的，你都可以做很多的事情。比如說這個它都有 Document，一公佈他很快就抓進來。你看這個是 10 月 29 的嘛，9 月 29 的就是昨天。那它也可以做到這個 Report 的逐字稿，就是他們可能開新聞稿啊，新聞說明會什麼的，然後它也可以去做這個分析。

[02:22:20] 這是一個功能。那第二個就是比如說它直接有幫你這邊做一個篩選器。那你就可說你 Follow 這些 Hint 去做。好像時間有點趕，我這邊就不特別打。因為我們通常在做財務的時候，我們就很關心這些比如說這些大公司他們每天的股價的漲幅。那我們就可以看說昨天的畫是 NVIDIA 就是市值超過 2T 的公司，美股的喔，NVIDIA 的漲幅是最大的。

[02:23:36] 好，那這個 Perplexity Finance 還有什麼好處呢？比如說我開這個 ChatGPT，你就打「今日 Google 股價」。好，他現在好像對了，我下午查的時候他還是錯的。但是就是說 GPT-4 有時候在你去查資料的時候，它不一定有隨時去 Import 最新的資料。那我是過了，就是 Perplexity Finance 基本上就跟市場的資料是及時對應的，所以一定可以。

[02:24:19] 那接下來比如說還有一些有趣的功能，比如說這個「價格警示」好了。這個價格警示就是說比如說你有關心的公司嘛，Tesla 比如說我已經 Follow 了，我就 Unfollow 好。比如說價格警示我就這樣這邊，比如說它漲到 465 的時候，我就需要用一個這個...我就想要他去提醒我，直接 Email 給我。因為 Email 大家通常都收很快吧，然後我就直接做這個這樣，然後它就會放在這個地方。

[02:25:07] 那大家可能在做的時候會發現說怎麼好像沒有提示我啊？其實是因為他現在就是這個功能還是...但是你們不用擔心說助教怎麼自己買，然後你們不買就用不到。其實現在這個不是打廣告喔，我沒有收錢喔。就是 Perplexity Pro 他現在你如果是學校的學生的話，你基本上可以去...我好像註冊過了，應該是在這裡。我這邊有去訂閱啦，但是我這個管理計劃裡面你去點進去他有一個學生的。

[02:25:52] （操作畫面） 這邊有一個教育的啦，然後我記得好像有一些公司會送，但是我沒有特別去拿。但是你這邊這樣進去之後，你要確認去學生，然後你登記完之後，你最後他會有一個驗證，你就用學校的那個 g.nccu 那個帳號去做驗證，基本上他就會給你了。那至少可以用一個月，你們這個月可以玩玩看。之後他好像還有就是比如說你分享 Link 的話可以延期什麼，你們可以自己去研究。這就是免錢的方法讓你們可以去這樣。

[02:27:04] 那還有一些功能我覺得是很有用的。我這邊給你們看喔，比如說像這個「發現」(Discover)。發現金融這邊，像這個 Discover 它其實是我覺得它整合得算是蠻好的。因為它這個每一個...這個是 Perplexity Finance 他們自己會...應該說這個程式他會自己一直去抓這些資料，那他去寫這些文章。

[02:27:35] 那你當然不要說完全去相信這些文章吧，他其實也怎樣，他都給你了，它是去引用 (Reference) 哪些文章去決定的。但其實你也可以再去做 Check 說這些文章是不是真實性嘛，那你做一個交叉。那這個的好處是說，因為現在真的行太多了，你不知道哪一些是好用的，哪些是不好用的嘛。那我覺得你可以，尤其是如果你是新手才想要插套進這個領域的話，你用這個功能就很好用。

[02:28:12] 像這個再展示一個功能就好，我覺得還有一個這個是很好的用的，像這個「任務」。這個任務的話它可以怎麼樣呢？就是我覺得大家應該都多少都知道說有一些就是機器人啊或者是因為什麼的，他可以一直去 Promote 一些資訊到你的 Gmail 裡面嘛。那比如說我就想要知道一個...就是我們想要每天知道美國的經濟狀況或是一些數據是怎麼樣子的。

[02:28:42] 那比如說這個是 Daily 的，我就設在每天下午 5 點或是說你九點半開盤嘛，你就是在 8 點半或九點，我提前一個小時，我去看今天的市場大概是怎麼樣子的。那你就可以按儲存。那你就到期不設也沒有關係，我現在是先設到年底。那你就可以看到說下午 5 點的這個時候...這邊我設了兩個這個東西，那我就可以去看，我每天就可以先用很簡短的五分鐘去看一下說 AI 幫我們整理了什麼資訊。

[02:29:20] 而且這個是你只要設定好之後，我 Daily 的他就會一直去 Report 給我，我不用說我每天要去問 GPT 嘛。那這樣就會比較...而且因為你每天丟給 GPT 的話，它這個 Response 的風格可能都不一樣。那所以我覺得這個是你再回來看這些資訊就是很好。

[02:29:42] 那好像應該時間差不多了，所以我就先介紹到這邊。比如說你真的是可以問很多問題，就比如說你想要 Analysis 特斯拉的近況，你就直接在這邊問。或者是說他就會自動的去給你這些問題，就是說大家現在都在問什麼啊。

[02:30:45] 比如說 Education，你想要做一個...找一個 Education 的好了。那你就可隨便找一個，比如說 Citation Generator。其實他下面都...你對這個主題有興趣嘛，那下面這些東西他都會有，就是比如說別人做的好（Collection），那你看到很多觀看嘛。所以其實你也還有一個目的說，我覺得你也可以透過這個東西去知道說別人現在在用這個 AI 他們在查了什麼樣的資訊這樣子。

[02:31:16] 好，那 Perplexity Finance 我覺得是真的有蠻多功能的，我覺得你們可以再回去玩看這個東西。那尤其是你們如果是想要做財經相關的話，我就是一個很好入手的程式。他縮短了我覺得就是金融小白跟金融專家之間的距離一些。

[02:31:43] 好，那我們今天的助教課就講到這邊。那如果有問題的話就是可以再問我，也可以 Gmail 我或是那個助教課的時候。
[00:00:00] 開場與課程介紹

大家好。今天我們要開始進入主題了，今天要介紹的是「生成式 AI」。今天因為有颱風來襲，雖然台北沒有放颱風假，風雨也滿大的，很感謝還有同學到現場。我們今天要為大家介紹的就是大型語言模型，也就是我們這兩個主軸的其中一個。

之前我們已經知道，以前一直希望有生成式的 AI，能夠讓電腦有創作的能力，可是發現有相當的困難度。一度我們認為 GAN（生成對抗網路）是我們的希望（應該是上週介紹的），但是沒有想到後來發生的一些事情，讓大家覺得其實有比 GAN 更適合的，其中一個就是我們今天要介紹的大型語言模型，也就是像 GPT 這種語言模型。

[00:01:22] 語言模型的文字生成原理

我們馬上開始。先來看一下像 GPT 這一類的語言模型，它的文字生成原理。首先，處理自然語言——不管是自然人、一般人寫字或說話——要能夠處理這種一般的對話，這叫做「自然語言處理（NLP）」。就是讓我們正常說話或寫字的樣子，讓 AI 可以看得懂，或是 AI 可以說出這樣子的話。這一直以來都是一個非常重要的主題。

我們的目標是要打造一個可愛的對話機器人。在神經網路的世界裡面，其實還是一樣，就是要打造一個「呆萌型」的 AI 機器人。所以我只要認真的去想：我的輸入是什麼？輸出是什麼？因為深度學習基本就是這樣，我們專注在問這個問題，問完了之後，就去找很多的範例讓電腦去練習。電腦練習會了以後，未來應該就可以達成我們希望它做的這些事情。

[00:02:50] 傳統對話機器人的設計困境

一個對話機器人到底要怎麼設計？一開始最自然的想法應該是這樣：比方說我們要設計一個客服機器人，這是非常多公司很早以前就希望有的，因為可以 24 小時回答客戶的話。客服機器人要做的事情，就是客戶說的話進去，出來就是客服人員的回覆。

我們可能會覺得神經網路模型就是把過去客戶跟客服的對話紀錄撈出來，輸入就是客戶說的話，輸出就是客服人員的回覆。但是現在有一個問題：因為神經網路模型（呆萌機器人）基本上就是一個函數，所以它輸入的大小要固定，輸出的大小也要固定。這是函數基本的要求，不可以一下是 X 的函數，一下是 XY 的函數。意思是說，輸入的字數要固定，輸出的字數也要固定。

我們可能達成協議說：不如我們就輸入 15 個字，輸出 20 個字好了。然後找了很多過去的對話紀錄來訓練。訓練完之後，我們正式公佈一個 24 小時客服系統。結果第一通電話進來，有一個客人很有禮貌地說：「你好」。我們的客服機器人就回應說：「不好意思，你沒有說到 15 個字，麻煩你再說一次。」你會發現不能這樣設計，因為我們沒有辦法要求每一次輸入的字數是固定的，輸出的字數是固定的。

[00:05:12] 序列對序列 (Sequence-to-Sequence) 的概念

雖然後來在 Transformer 的時代，輸入的字數還是有固定的限制（例如上限 2000 字），少於這個字數是可以接受的（後面補一些東西進去），但那是現代發生的事情。在大約 10 年前，我們還不能做這麼偉大的事情。

那時候大家開始思考，最終得到了一個非常好的模型，叫做 Sequence-to-Sequence（序列對序列）的方法。顧名思義，輸入可以是一串序列，要長要短都可以；輸出也是一串序列，要長要短都可以。

[00:07:11] 預測下一個字 (Next Token Prediction)

大家怎麼設計這個機器人呢？非常令人震驚的是，這個「呆萌型 AI 機器人」做的事情非常簡單：它就是輸入一個字，然後去預測下一個字。就這樣結束了。它只預測下一個字，而且輸入的時候就是一個字，看到一個字以後就去預測下一個字應該是什麼。所以，世界上所有的一段話，我都可以拿去訓練它。

我們來看一段話做例子，比方說：「炎龍老師很帥」。

第一個字「炎」進來的時候，我們預測下一筆正確答案應該是「龍」。

第二筆「龍」進來了以後，正確答案應該是「老」。
以此類推。你會發現我們可以準備非常非常多的訓練資料。

[00:08:21] 一對多與機率分佈的問題

但是大家沒多久就發現一個問題。跟我們在做生成的時候很像，同一個字進來，例如：「今天天氣很好」。這句話裡面，「天」可以接「天」（天天），「天」也可以接「氣」（天氣）。在這句話裡面就接了兩個不同的答案。

如果有很多個不同答案，我們可愛的呆萌型機器人會做什麼？它會想辦法討好所有人，就會把這些答案變平均。平均值不一定是我們要的，它甚至可能不是一個字。而且就算它是一個字，我們也希望生成比較有彈性，不要每次都生出一模一樣的字來。

所以原本「一個字接一個字」這樣固定大小的輸入跟輸出是不行的。那怎麼辦呢？大家想到一個非常簡潔的辦法解決這個問題。

[00:10:18] 引入「記憶」機制 (RNN)

解決方案是：我們輸入一個字，去預測下一個字，但是在運算的時候，需要把前面的資訊一起拿進來考慮。說得更清楚一點，就是有一個隱藏層。

神經網絡是一層一層做出來的，每一層我們都可以想成是電腦的「理解」。那個理解是很抽象的，對我們來說是一堆亂七八糟的數字，但是我們可以想成是電腦的理解。因為這樣做完以後繼續傳下去，它真的可以解決我們的問題（例如辨識巴哥犬）。所以我可以把中間每一個隱藏層的輸出，都當成原來輸入的理解，或是原來輸入的特徵代表向量。

我們把某一個隱藏層把它叫做「記憶」。為什麼叫記憶？因為這個「記憶」下一次又會傳回這個隱藏層。

所以每一次輸入的時候，不只是當前的字（我們要預測下一個字），還要把前面看過那些字的「記憶」一起進來。因為記憶是某一個隱藏層的輸出，所以大小是固定的；字也是固定大小。所以就是這樣子一起輸進去，它就是一個固定大小的輸入，要預測的就是下一個字。

[00:12:54] 神經網路結構：RNN 與 Transformer

上次其實已經介紹過，隱藏層的設計方式基本上只有三種：

DNN (全連接層)：標準全連接。

CNN (卷積神經網路)：圖形辨識很強。

RNN (遞歸神經網路)：某種程度是我們今天的主角，雖然 RNN 後來被 Transformer 取代。

它們要做的事情基本上都是一樣的，就是希望找到一個有記憶的、讓神經網絡是有記憶能力的。從剛剛的呆萌機器人我們知道，輸入一個字加上前面的記憶，它要預測下一個字是什麼。

你會問：ChatGPT 可以生成很多字，那它怎麼生成很多字？其實答案也很簡單。就是把預測出來的字又放到前面去，它就又多了一個字，然後再預測下一個字。所以要預測多長的文字都可以。因為神經網路一定會算出一堆數字，一定可以接下一個字，它就可以一直持續接下去。

例如：「炎龍老師很...」，然後真正的語言模型（例如 T5 或其他）覺得下一個字應該接「優」，我們就把「優」放進去；然後它覺得下一個字應該接「默」，就放「默」；然後下一個字它覺得是句點了。這就是文字生成型 AI 所有的原理：看前面一堆字，覺得下面哪一個字是適合的，它就放上去。

[00:15:38] 語言模型的輸出：Softmax 與機率分佈

事實上它跟「巴哥辨識」（分類問題）是一模一樣的模型。也就是說，假設我們希望它輸出的中文字有 4 萬個，我們就把所有的中文字（包括標點符號）編號：1、2、3... 到 4 萬。如果要加英文、日文、韓文就加進去。

所以它跟巴哥辨識一樣，看到前面那一串字（其實是一堆數字），根據訓練結果，它會把所有可能的字都給一個分數。例如 1.4 分、0.03 分、0.71 分等等。

給了分數之後，我們會做 Softmax。Softmax 在語言模型裡面非常重要。做完 Softmax 之後，我們就會得到一個機率分佈。這是在這樣的情境下，前面如果是輸入那一堆字的話，抽到「有」的機會是 40%，抽到「帥」的機會是 30%，抽到「瘦」的機會是 19%。

結論是：語言模型不知道它在幹什麼，它只是根據訓練結果，讓我們看很多句子，讓它知道後面接什麼字比較順，它就試著去接。事實上它是算出一個機率分佈。

跟以前巴哥辨識不一樣的地方是：巴哥辨識我們都選最高分，但是語言模型我們不是選最高分，我們是根據機率分佈去抽一個字出來。這就是為什麼同樣的輸入，你再按一次，它會生出不一樣的東西。如果不這樣設計，你按 200 次答案都一模一樣，你會非常生氣。

[00:20:20] 小結：接話王與幻覺

我們做一個小總結：

文字生成 AI 很簡單，它只是預測下一個字的呆萌型機器人。 看著前面一堆字（記憶），去預測下一個字。

它就是很會「接話」的接話王，用更白話的說，它就是「唬爛王」。 你不希望它變成句點王，你唯一希望它就是很會接話。

它完全沒有考慮什麼事實。這就是大家常說的「幻覺」。事實上從訓練就可以知道，我們沒有要求它看到事情要去查資料確認，它就是直接預測下一個字適合放什麼。

它如果接的話跟前面是矛盾的，那接得就不順。所以它要接得順，就需要接你的話，所以它會把你前面提供的資訊當成事實。除此之外，它腦筋裡沒有事實這種東西。

所以使用語言模型只有兩個原則：

提供足夠多、正確的資訊。

清楚的指引，告訴它你要做什麼。

[00:23:36] 記憶的機制：RNN vs Transformer

記憶大概有兩種方式：傳統的 RNN 和後來的 Transformer。

RNN (Recurrent Neural Network)：非常簡單，隨便挑一層隱藏層當作「記憶層」。記憶層的輸出（向量 $h_t$）會跟著下一個字一起進到神經元。RNN 的運算過程需要遞迴（Recursive），算完 $X_t$ 產生記憶，再跟 $X_{t+1}$ 一起算。這是一個迴圈。在數據分析裡，迴圈是重大罪狀，特別是 NVIDIA 的黃仁勳最痛恨迴圈，因為 GPU 的平行運算對迴圈沒轍。這導致 RNN 算得很慢。

Transformer：Google 後來想到，難道不能一次全部一起輸進去嗎？我們的目標是產生每一個時間點適合的向量。它利用 Attention (注意力機制)，直接跟每一個字做比對，看要重視哪一個字。它計算內積（內積值越大代表注意力越大），再做 Softmax，最後加權平均產生特徵向量。這就是 Transformer 的做法。

Transformer 那篇論文非常有名（Attention Is All You Need），我們下次會詳細解釋。現在先知道：反正就是有某種記憶的方式，可以產生適當的向量去預測下一個字。

[00:31:45] Andrej Karpathy 與大型語言模型的發展

為什麼大家開始覺得這種模型會這麼厲害？我們要介紹 Andrej Karpathy。他最近做了兩件很有名的事：

提出 Vibe Coding（基本上就是擺爛叫電腦寫程式）。

把 AI 進程分成 Software 1.0, 2.0, 3.0。

大概 10 年前 (2015)，他在史丹佛念博士班時，跟李飛飛開了一門非常有名的課介紹 CNN (CS231n)。他是 OpenAI 最早的成員之一，後來去 Tesla 做自動駕駛，又回 OpenAI，現在做 AI 教育。

2015 年他寫了一篇非常有名的部落格文章，用 RNN 做出了預測下一個字（Token）的模型。

例子 1：代數幾何書 (Stacks Project)
他找了一本介紹 Stacks 的代數幾何書（這是數學裡非常抽象、地位崇高的領域）。他讓電腦看 LaTeX 的原始碼。看完後，電腦覺得自己是數學家了，你隨便給一個 prompt，它就開始寫證明。一句一句看好像有點道理，例如「這是一個在 X 上面的連續函數」，但合起來讀其實沒什麼道理。

例子 2：莎士比亞全集
看完莎士比亞全集後，AI 覺得它是莎士比亞，開始寫劇本。看起來很像兩個人在對話，但不知道到底在說什麼。

我們之前的學長姐也試過把《紅樓夢》丟進去訓練。AI 覺得自己是曹雪芹。即使你下的 prompt 是「孫悟空從石頭中蹦出來之後」（跟紅樓夢無關），AI 也會硬接下去，因為它被訓練成要接話。乍看之下很像紅樓夢，但仔細看不知道在說什麼。

[00:40:22] 幻覺 (Hallucination) 與 GPT-2 的震撼

在 Karpathy 2015 年的文章中，其實已經出現了「幻覺」。但他覺得大型模型就是一個「做夢的機器」，幻覺並不是問題，而是它最偉大的特點。如果不需要創作能力，做搜尋引擎就好（0% 夢境）。我們希望它會做夢、創作新的句子。當然在客服等場景我們不希望有幻覺。

那個轉捩點是什麼時候？直到有一天，OpenAI 推出了 GPT-2。GPT-2 出來的時候非常震撼。OpenAI 寫了一篇部落格，給 GPT-2 下了一個很唬爛的 prompt：「美國安地斯山脈發現了一群獨角獸，牠們會說流利的英文。」
GPT-2 接得像正式的新聞報導，還說是哪位教授領軍、哪個大學來的。除了內容超級唬爛之外，看起來真的很像人寫的。

為什麼 GPT-2 可以做到這麼厲害？

模型變很大：《紅樓夢》生成器大概 300 萬個參數，GPT-2 用了 15 億 (1.5B) 個參數。

讀了很多字：GPT-3 時代變成了 1750 億 個參數。GPT-3 大概讀了 4990 億個 Token（字）。
ChatGPT 曾計算說，如果一個人每天讀書，70 年壽命大概讀 5300 萬個字（雖然它算錯了，大概是快 2 億個字）。不管怎樣，跟 4990 億差非常多。我們一輩子再怎麼努力也沒辦法讀這麼多字。

因為參數很多、讀了很多字，這種模型我們就叫做「大型語言模型 (LLM)」。

[00:48:47] 中場休息

我們先休息十分鐘，等一下再繼續。
[00:48:50] 語言模型的選字機制：Embedding 與 Softmax

大家好，我們現在繼續。我們來說一下這個選字上面的問題。我們已經說過了，生成式 AI 也就是大型語言模型，在選字的時候其實就是跟巴哥辨識是一樣的。它就是每一個字都給它一個編號，然後每一個字都會得到一個分數。得到分數之後，我們用 Softmax 讓它加起來變成 1，然後依照算出來的機率分佈，抽樣出一個字出來。

事實上，嚴格說起來，輸入跟輸出的時候有一點點不一樣。輸入的時候，我們之後會介紹它其實是一個 Word Embedding，它是某種 Embedding（嵌入），也就是某一個文字的代表向量。因為如果我們單純輸入「1 號字」、「3 號字」，這些號碼基本上是沒有意義的。對 AI 來說，做任何的辨識都沒有意義，它就只是一個字。所以我們希望找到比較有意義的、代表那一個字的特徵代表向量。輸出的時候則比較簡單，就是剛剛說的，每一個字都給它一個分數。我們把所有的字編號，通常常見的字放在前面，比較不常見的放在後面，這是從 Information Theory 來的。大家可以試著問 ChatGPT：「為什麼自然語言處理的文字編號，出現頻率越高的字，代表的數字要越小？」它會給你一個很合理的解釋。

[00:51:24] 調整隨機性：Temperature (溫度)

我們要知道幾個重要的概念，分別是 Temperature、Top-K 以及 Top-P。首先是分數計算，經過 Softmax 之後，我們出現的機率假設是 70%、20%、1%。機率小的字雖然只有 1% 的機會，說不定你運氣特別好就會選到它。原始的分數可能長這樣，例如 4.3、4.0、3.4。如果你認真看 Softmax，你會發現 4.3 跟 4.0 感覺好像差不多，但經過 Softmax 之後，因為是指數運算，上升非常快，差距會完全拉開，可能變成 70% 跟 29% 這樣，變成一個「贏者全拿」的方法。

有時候我們會覺得這沒關係，但在語言模型裡，有時候我們希望它不要那麼極端。這時候我們會除以一個神秘的數字，叫做 $\tau$ (Tau)，我們把 $\tau$ 叫做 Temperature，也就是溫度。當溫度越高（$\tau > 1$）的時候，數值會往 0 靠近，大家的分數差距會拉近。做完 Softmax 之後，機率分佈會比較平緩，也就是隨機性會增加。這號稱是從物理來的，溫度越高，物體運動越隨機。反之，當溫度越低（$\tau < 1$）的時候，分數差距會被放大，讓高分的更高分，也就是隨機性變低，模型會盡量取高分的字。有時候我們真的希望隨機性比較低，例如做客服機器人時，我們不希望兩個客戶問一樣的問題，結果對 A 客戶這樣講，對 B 客戶那樣講。所以我們可以用 Temperature 來控制隨機性。

[00:55:47] 避免離譜錯誤：Top-K 與 Top-P

還是有一件事情會發生，雖然機率小的字比較難被抽中，但是還是有可能被抽到。因為我們把世界上所有的文字送去訓練了，說不定有些是錯別字，AI 學會了，所以它就不小心生出了錯別字。我們希望不要抽到機率太小的字，這要怎麼做呢？

第一個想法是 Top-K，也就是我們就只選前幾名的字，例如前 50 名。K 是我們自己定的，例如 50、100 或 20。這樣一定會選到字，而且名次太低的那些我們就淘汰掉了。但是 Top-K 有一個風險，有時候合理的下一個字可能只有一個。例如：「政治大學應用數學系的老師叫做蔡炎...」，下一個字一定是接「龍」，機率幾乎是 100%，暫時沒有第二個可能性的字。這時候，後面的字（第 2 名、第 3 名...）其實都是錯誤的字，例如打錯名字。如果我們用 Top-K（例如 K=50），即使第 3 名的機率很小，還是有機會被選到，這樣 AI 就會出現錯誤。

所以大家又想到了一個新方法，叫做 Top-P，這是在 2020 年的時候發表的。雖然概念聽起來很簡單，但這是一個非常重要的方法。我們設定一個門檻 P，例如 90%（0.9）。我們就從第 1 名的機率開始加，加到第 2 名、第 3 名，直到累積機率達到 90% 為止，後面的字就不要了。如果第 1 名的字機率已經 93% 了，那我們後面就全部不要了，因為幾乎就是這一個字。這樣一定會選到字，而且機率太小的字基本上會被忽略掉。

[01:04:16] 讓電腦懂字義：Embedding (詞嵌入)

接下來談談輸入的部分。輸入的時候，我們會先做 Word Embedding。我們當然可以做 One-hot encoding（把字轉成編號），例如 87 號、53 號，但是這些號碼基本上是沒有意義的。我們希望找到一些比較有意義的、代表那一個字的特徵代表向量，這就是 Embedding。

要怎麼訓練這個向量？我們不能直接訓練一個呆萌型機器人來產生 Embedding，因為我們不知道正確答案，不知道那個向量應該長什麼樣。我們的方法是設計一個小任務。這個小任務的輸入就是我們想要找 Embedding 的文字。如果這個小任務它真的可以順利執行、學得很好，我們就覺得它的理解很正確，所以我們就可以把它中間某一個隱藏層的輸出，拿出來當作它的 Embedding。

Google 以前做的 Word2Vec 就是這樣。它想了兩個小任務：第一個是用旁邊的字去預測中間的字（CBOW）；第二個是用中間的字去預測旁邊的字（Skip-gram）。訓練完以後，發現電腦好像真的懂那個意思。最經典的例子就是「巴黎」減掉「法國」加上「義大利」，算出來的向量會非常接近「羅馬」。或是「國王」減掉「男人」加上「女人」，就會變成「皇后」。這讓我們覺得電腦好像真的懂了。

現在的大型語言模型，已經沒有特別先拿一個模型去訓練 Embedding 了。它把第一層就當作 Embedding 層。因為它的任務（預測下一個字）本身就是一個很好的小任務，它必須懂文字的意思才能預測。所以它就自動把第一層做成 Embedding 層，跟著模型一起訓練。

[01:12:23] 語言模型的選擇：閉源與開源

我們現在介紹大概四個比較主要的語言模型。首先是閉源模型（Closed Source），這些模型基本上沒有公開程式碼，你不能下載在自己電腦上執行，一定要連網使用。目前比較有名的包括 OpenAI 的 ChatGPT、Google 的 Gemini、Anthropic 的 Claude，以及馬斯克公司的 Grok。每一家都有免費版本，但用到了某個程度就會限制你，希望你付費。好處是因為每一家都有免費版，這家限制了你就換用別家。不用太擔心不知道哪一個是最好的，因為基本的訓練原理都是一樣的。

特別是在企業裡面，我們希望資料不要傳到雲端，最好都在企業內部的網域裡面。這時候就需要開源型（Open Source）的大型語言模型。最有名的大概是 Meta 做的 Llama，因為它大概是最早做這件事的，所以很多（特別是台灣要加強繁體中文訓練的計畫）大概都是用 Llama 為底去訓練。另外還有 Google 的 Gemma 也是一個開源型的語言模型。至於 OpenAI，因為它很久沒開源了（被戲稱 CloseAI），雖然最近似乎有些動作，但主要還是以閉源為主。（註：講者此處提到的 "PTOSS" 可能是指 Mistral 或其他新興開源模型，具體型號如 120B/20B 較符合 Mistral 規格）。

關於模型大小與硬體需求，我們通常用參數（Parameters）來表示模型的大小。例如 GPT-2 是 15 億（1.5B）參數，GPT-3 是 1750 億（175B）。現在的開源模型，例如 Llama-3 有 70B（700 億），也有像 120B 這麼大的。相比之下，1.5B 在現在簡直是迷你型。

如果你要回家在自己電腦上跑語言模型，要怎麼知道跑不跑得動？最重要、最重的關鍵就是 GPU 的 VRAM（視訊記憶體）。有一個簡單的估算公式，因為現在標準的壓縮方式是 4-bit 量化（Quantization），大概就是把參數數量乘以 0.5。例如 20B 的模型，大概需要 10GB 的 VRAM（20 * 0.5 = 10），你要超過 10GB 才能跑。如果是 120B 的模型，大概就要 60GB VRAM。

在硬體選擇上，NVIDIA 的消費級顯卡最高規（如 RTX 4090）是 24GB VRAM，企業級（H100/H800）才有 80GB。如果你是用 Mac（Apple Silicon），因為 Mac 是共用記憶體（Unified Memory），VRAM 跟一般的 RAM 是共用的。理論上你的 RAM 有多大，VRAM 就有多大（扣掉系統保留）。現在 Mac Studio 可以裝到 192GB 甚至更多，所以真的可以跑蠻大的語言模型。AMD 也有出共用記憶體的 GPU。

[01:20:00] 在本地端執行語言模型的工具

有兩個很容易在自己電腦上跑語言模型的軟體推薦給大家。第一個是 LM Studio，大部分同學應該比較會用這一個。它就是一個應用程式，你去下載你要的語言模型，然後就開始使用。用法跟網頁版基本上一樣，只是你可以完全斷網執行。第二個是 Ollama，如果你覺得終端機（Terminal）非常親切可愛，完全是文字介面，要在裡面下指令使用的，非常推薦 Ollama。

[01:27:07] 語言模型的使用態度與作業說明

（此處講者開始總結並介紹接下來的作業：設計自己的 Benchmark）

我們不用太在意哪一個語言模型是最厲害的，因為它們總有一天會互相趕上。所謂厲害不厲害，通常是看 Benchmark（標準測試），例如解數學競賽題目。但你不一定關心它解數學好不好，你可能更關心它能不能幫你寫程式或做其他事。

所以，不要太在意 Benchmark，但我們今天的作業就是要做 Benchmark。意思是請你去設計幾個「你自己關心的」測試題目。題目要你有興趣且有點懂的，你才能分辨好壞。不要再考封閉式問題（有固定標準答案的），它一定會答錯或瞎掰（例如問它團隊成員有誰）。你可以問開放式問題，例如：「我想用大型語言模型做一個期末專案，可不可以提供幾個想法？」建立一組你自己的測試基準，去測試不同的語言模型（至少兩個），然後寫一下你比較喜歡哪一個、為什麼。
01:27:07] 作業說明：設計屬於你的 Benchmark (基準測試)

我們剛才提到，其實大部分的時候我們不需要太在意哪一個語言模型是最厲害的，因為競爭的公司總有一天會互相趕上。所謂厲害不厲害，通常是看標準的 Benchmark（基準測試），例如看它會不會解數學競賽的題目。但如果你不一定關心它解數學好不好，你可能更關心它能不能幫你寫程式，或是做其他你家教科目相關的事情。例如你當家教的時候，可以偷偷讓它算一算，然後你再看一下答案，因為你懂那個科目，所以你有辦法去分辨並使用它。這其實是使用語言模型一個很重要的觀念。

所以我們今天要強調的是，不用太在意標準的 Benchmark，但我們今天的作業就是要做 Benchmark。這聽起來有點自相矛盾，但我的意思是，今天的作業是請你去設計幾個你自己關心的測試題目。也就是說，你拿到一個語言模型，在你還不知道它到底好不好的時候，因為外面宣傳說出了一個新模型超厲害、超小巧，你就拿你的標準 Benchmark 去試試看。

我們今天要設計這個標準的 Benchmark，第一個最重要的原則是：題目要是你有興趣且有點懂的，你才能分辨好壞。不可以完全不懂，完全不懂你根本不知道它有沒有在唬爛，或是答得好不好。當然不用設計太複雜的 Benchmark，舉例來說，像是有同學覺得佛法名相很多、很難學，你可以問它：「可不可以用淺顯的方法說一下唯識學？跟生命有什麼連結？」等它說完了，你還可以設計第二層的追問。比方說它可能會說唯識學的基本概念叫做「一切唯心造」，你就繼續問它：「既然一切唯心造，那我們人怎麼會有悲傷呢？我應該不會想要悲傷，我應該都想要造出快樂的東西啊？為什麼我的車子是 Toyota 而不是法拉利？怎麼會是一切唯心造呢？」看它怎麼解釋回來。你可以看它解釋得怎麼樣，找到哪一個語言模型是你覺得解釋得比較好的。

所以總結來說，今天的作業就是建立一組你要測試的基準測試。請大家不要在交作業前才開始想，從今天回去每一天、每一時刻盡量多想一些，至少一天想一組你要問的問題，然後去測試在不同的語言模型上面（至少有兩個才能比較）。再次強調，主題要是你有興趣的、有點懂的，才能分辨好壞。不要再考語言模型那些封閉式的問題，例如問它某個團體的成員有誰，它一定會答錯。你可以問開放式的問題，例如：「我想要寫一個程式，可不可以舉五個適合初學者又有趣的題目？」在你的專業領域裡面，一定有一些更有深度的問題可以去問它。

最後，這是你自己的 Benchmark，所以標準當然是你自己的主觀判斷。你覺得好就是好的，最好有一點深度的理由，不要只是因為它很順著你的話、拍你馬屁你就覺得好。你覺得它說的內容真的比較好，或是任何其他的理由都可以。語言模型在某種程度上，其實你自己的主觀才是最重要的，因為那是你自己要使用的工具。

外面有一個類似這種想法的網站叫做 LMSYS Chatbot Arena，它基本上也是一個 Benchmark，只是做法很特別。它不是去解標準問題，而是讓使用者上去問一個問題，它會隨機抽兩個語言模型給你回答，然後由你選哪一個比較喜歡。因為大家問的問題千奇百怪，所以選出來的語言模型排名，應該是大家比較喜歡的。你會發現排在前面的幾乎都還是那些要收錢的閉源模型。

我們今天的重點就是希望大家知道語言模型的原理之後，就沒有那麼擔憂。未來看到那些 Prompt 的小技巧之後，也不會那麼擔心。因為你會發現 Prompt 原理只有兩件事情：提供正確的資訊、清楚的指引。外面的小技巧只是告訴你怎麼有系統地做到這兩件事。例如什麼 RTF 法、TAG 法、CO-STAR 法等等，如果你直接去看會覺得快瘋了，但知道原理後，你會發現它只是有系統地幫你把 Prompt 寫好。你覺得適合就學起來，不適合就不理它，這樣你就不會慌亂。

我們今天的作業就是請大家去想自己的 Benchmark，因為是你自己的測試，所以會符合你的使用需求。請大家盡量多想一些，把最得意的那一組測試交上來。我們先休息 10 分鐘，等一下進行 TA 時間。

[01:39:04] 助教時間：閃電秀 (Lightning Talks)

(助教劉子俊)
各位現場及線上的同學好，我是負責這週助教課的劉子俊。今天有三位同學報名我們的閃電秀，我們先歡迎中央大學的呂佩真同學來分享。

[01:39:22] 同學分享 1：AI 的耗能 (呂佩真)

大家好，我今天要介紹的主題是關於 AI 的耗能。這幾年 AI 給人類帶來非常多的便利，但同時大家也有很多的隱憂，就是關於 GPT 的 Prompt 或者是訓練 ChatGPT 這個模型需要花多少的能源。

在很多的媒體還有研究報告裡面，我們常常會看到很驚人的數字。例如有人估算生成一封大概 100 多字的 AI 電子郵件，可能就需要消耗 14 顆 LED 燈運作一小時的電力。還有專家說，如果 AI 在未來快速成長，到了 2030 年的時候，會用掉美國總電量的四分之一。這些數據在新聞上面流傳，讓大家覺得有點恐怖。

在今年 Google 成為第一個公開能源數據的 AI 公司，它首次針對它的 Gemini 模型公開了一個 Prompt 的實際能源數據。在這份報告裡面，它是以中位數來運算，指出文字任務大概會消耗 0.24 瓦時 (Wh) 的電力，相當於微波爐運轉一秒鐘；碳排放大概是 0.03 公克的二氧化碳；耗水量大概是 0.26 毫升（大概就是 5 滴水）。這是第一次由大型科技公司把 AI 每次互動的耗能講得這麼具體。它還拆解了耗能在哪裡，多數是在 TPU 晶片，再來是 CPU 和記憶體，少數是在電源轉換與冷卻設備。

這跟媒體還有一些專家指出的耗能差距非常大。原因在於估算不同，傳統的研究可能是以最重型的任務（例如一大篇報告或很多圖片）來估算；而 Google 公佈的是以中位數運算，且僅限於文字任務。所以以前的研究可能高估了 AI 的耗能，但 Google 可能又低估了，因為 AI 耗能當中耗掉最多的通常是在推理或訓練模型當中，Google 沒有分享出這些資訊，也沒有分享每天總共有多少 Prompt 被執行。所以大眾的輿論還是非常兩極。

目前各個科技巨頭也都在尋找能源解方，像是微軟說會投入數十億美元去發展核能；Google 設定在 2030 年達成零碳能源目標；亞馬遜則強調他們是全球最大的再生能源採購者。以上是我的分享。

[01:44:45] 同學分享 2：特斯拉自動駕駛與 AI (陳浩宇)

大家好，我是中央大學資工二的陳浩宇，今天要分享的是特斯拉自動駕駛與 AI。首先回顧一下特斯拉自動駕駛的發展過程。2014 年推出 Autopilot 時，主要功能只有維持車道以及跟車；到了 2016 年才將目標聚焦到實現完全自駕。一直到了去年，特斯拉推出了 Full Self-Driving (FSD) v12，最大的特色就是使用了「端到端 (End-to-End)」的神經網路 AI，讓車子不只是依靠一條一條的程式碼去規範行動，而是讓車子的大腦可以直接去學習人類的駕駛行為。

AI 與特斯拉自動駕駛可以簡單分成三個部分：看、想、學。

看：透過車子的 8 個攝影機接收影像輸入，辨識周遭環境，像是車道線、行人或紅綠燈。

想：在影像輸入的情況下，理解人類會做出什麼樣的駕駛行為，然後決定做出什麼樣的輸出。

學：全球百萬輛特斯拉每日駕駛所收集到的資料，經過上面的「看」跟「想」，讓 AI 大腦順利去學習人類的駕駛能力。

特斯拉在 FSD 中使用 AI 的優勢有三點：擁有超級龐大的數據量、只需要依靠攝影機（不需要昂貴的雷射雷達，成本較低）、可以透過 OTA 更新。劣勢則是目前的完全自動駕駛其實算是剛起步，在安全還有規範上都具備挑戰；且在大雨大雪這種惡劣環境中，純視覺方案的穩定度可能不足。短期來看，特斯拉會持續使用 AI 讓 FSD 進步到超越人類駕駛水準，並推動 Robotaxi（無人駕駛計程車）的商業化。

[01:49:15] 同學分享 3：生成式 AI 製作遊戲 (政治大學 顏同學)

大家好，大家應該多少都有看過或做過請生成式 AI 幫你寫遊戲專案或程式專案。如果是一個比較大型、稍微完整一點的專案，全靠生成式 AI 可以做到什麼程度呢？這是我今天想要分享的內容。

這個動機是因為當年在通識課期末專案要做一個遊戲。那時候剛學程式沒多久，大概只看得懂而已。我的室友每天都在打快打旋風，我們就想能不能做一個遊戲，讓玩家不再受限於固定的技能組或規則框架，而是使用創意說出你想要使用的技能，或者用打字的方法打出你想要施展的內容，創造出無上限的技能組。

遊戲機制大致上就是透過玩家輸入任何字，轉換成對應的效果。整體的做法包含遊戲靈感、機制設定、技能類型、架構等，都是自身經驗和 ChatGPT 互動產生的。程式碼是 ChatGPT (GPT-4) 幫忙的，圖片是用 Midjourney 和 Pika AI 生成，配樂是用 Suno 生成。

機制設定上，為了讓玩家輸入任何字都能轉換成效果，一開始先請生成式 AI 整理成各種類型的技能。程式部分，因為生成式 AI 有上下文長度的限制，不可能讓它一口氣生成一個非常大型的專案。所以那時候是有一個先最小可以跑得動的簡單架構，後面再依照每一塊（例如類型總共有 50 多種）慢慢整理、分段貼上來擴充，藉此突破上下文限制的問題。

前後端是透過 Claude 串起來的。招式的圖片也都是 AI 生成的。計算傷害的機制大致上是統計指數。如果玩家輸入一堆亂碼或表情符號，當初也是讓 AI 生成了大概 50 幾種神奇的互動，跳出一些話告訴你技能生成失敗。

這個作品是我們數位遊戲與社會通識課的期末遊戲，是一個文字戰鬥的遊戲。遊戲畫面下面很像 LLM，可以自由輸入。例如玩家一輸入「他是一個很喜歡忍者的人，他使出了火...」，每一次不同的字參數會不太一樣，所以打出來的技能跟效果會不同，並放出不同的圖片。這展示了其實用生成式 AI 是可以做到一個盡可能完整的大型專案，而不只是在 Claude 上面打一串字跑出簡單結果。

[01:56:42] 助教教學：上週作業檢討 (Softmax 視覺化)

(助教劉子俊)
接下來開始助教課的內容。今天主要會講上週作業的範例講解，以及介紹 NotebookLM 這個小工具。

上週的作業是關於 Softmax 的互動式程式。這是我在 Colab 的範例。我的 Prompt 打在左邊，是根據老師在 NTU COOL 上面給的稍微做一點修改，加了一些人設。我們在下 Prompt 的時候，如果打上兩個星號，通常是強調這一點希望它特別注意到。例如我們希望讓學生知道 Softmax「贏者全拿」的這個特性需展現出來。

整個程式碼都是由 GPT 幫忙生成的。我直接把 Prompt 輸入進去，它就給我非常完整的程式碼，而且是一步一步的。同時因為有說要加上 Markdown 的文字說明，GPT 也有幫我呈現出來。我幾乎沒有做任何的修改，直接把它貼過來。

這個程式碼包含了安裝套件（如 Matplotlib），以及它自己刻了一個 Softmax 的函數。作業還有強調一點，希望能透過互動式的操作介面來更了解 Softmax 的特性。

這邊生成的圖表，大家可能會發現標題有時候會出現空白格子或亂碼，這是因為 plt (Matplotlib) 這個套件在顯示中文的時候，如果沒有做額外的安裝或處理，會有一些問題。所以各位同學在使用生成式 AI 貼程式碼的時候，還是要自己看過一遍，看是要改成英文，或是問它有沒有什麼套件可以解決中文顯示問題。

這個互動圖表是在講最大跟次大值的機率差距。這是一張 Temperature (T) 等於 1.0 的圖。當我們的溫度調得越小，差距會顯現得越大。我把它改成 0.5 後，大家會發現差距急劇上升。透過下面 GPT 幫我生成的互動式拉桿，我們可以更深刻理解這個意義。

例如我輸入分數 3.5, 2.4, 2.0。現在是 T=1 的時候。如果我們把 T 調小到 0.5，大家就會發現它的差距已經被拉得又更大了，相比於一開始，就顯現出 Softmax 有這個贏者全拿的特性。同時也達成了作業的要求，就是要有互動式的介面。大家可以稍微修改老師提供的 Prompt，去生成你們想要的程式碼。
[02:01:30] NotebookLM：你的 AI 筆記與研究助手

接著想跟大家介紹 NotebookLM 這個小工具。它其實是一個你的研究助手、筆記助手，同時也可以當做你的知識筆記本。它的特性是說它可以根據你上傳的這些資料來源，甚至是網頁的連結來做一個整理。並且當你上傳這些資料或網頁連結以後，你可以問關於這些內容的問題，它會根據你上傳的來源透過語言模型來做回答。

我實際操作一次給各位同學看。你進到 NotebookLM 它的頁面會長這個樣子，你們就直接按「建立新的筆記本」。這裡就可以上傳資料來源，我把我之前找的論文上傳給大家看。我是找了幾篇，像《Attention Is All You Need》就是老師今天上課講的那個 Transformer 的那篇 Google 很有名的論文，把它上傳上去。然後我再多上傳幾個當做例子，還有 BERT 這個模型當做例子，然後再上傳一篇 GPT-3 的這篇論文。

[02:03:15] 基於資料來源的問答

等它上傳好了以後，其實你直接點開左邊這個來源，就會發現它的內文都在這邊。它上面會直接顯現出每一份文件中的摘要。然後你就可以針對你上傳的這三個文件來去做簡單的提問。你要先勾選這三個文件，勾選了以後，例如我問它說：「請用白話文介紹什麼是 Transformer？」那它就會去找這三篇論文裡面相關的內容，然後生成回答給你。也就是說它完全會依照你上傳的文件來生成回答。

接下來用幾個更生活一點的範例。那時候跟老師有討論到一件事，就是假如你想吃美食，你特別喜歡這個美食作家的部落格好了，以這個台北美食為例，你就把它的網址複製下來。我們新增來源，這裡選網站的部分，貼上然後按插入。目前 NotebookLM 還是免費的，它付費的版本資料來源可以做得更多，以及每天問的問題上限會增加。但我現在在用的都是免費的功能，它有提供給各位同學可以之後做嘗試。

我現在勾選了這個美食部落格這邊網頁的內容，直接點開一樣會有摘要顯示給你。我可以問它說：「我現在在台北市，我想吃好吃的滷肉飯，應該去哪家店？」它一樣會根據這篇網站所推薦的美食，然後它就推薦了「小王煮瓜」這間店。我可以跟大家看發一下，如果我直接問 ChatGPT 一樣的問題，它其實推薦了更多種的滷肉飯，但它就不是推薦這個部落格美食家所推薦的那一家。這就是差別所在。

[02:06:28] YouTube 影片摘要與多媒體功能

其實還有很多種特定的用途我可以分享給大家。最後一個功能是它還可以新增 YouTube 的連結。比如前一陣子的 Apple 發表會，我把連結複製下來，貼到這邊按插入，所以這邊就有 Apple 發表會影片的連結。那我就可問它說：「假如我想知道新發表的 AirPods 4 的功能有哪些？」我請它幫我摘要 AirPods 4 有哪些新功能，它就會根據這影片的內容來去做回答。

其實還有很多種特定的場景，比如說你去買了一個新的家電，你去上網找它的說明書，直接把它丟進來，然後問它說哪些零件是要定期保養、定期做更換的。這其實也是一種好用的方法。所以它不只可以檢索論文這類的文件，網址也可以，YouTube 的影片連結也是可以做回答。

[02:07:53] 生成語音摘要 (Audio Overview)

接下來主要實作右邊這六個功能給大家看。因為生成語音摘要需要一點時間，所以我直接播好我之前在家先生成好的內容給各位聽。它可以把你選取好的文件做一個摘要，比如說你現在想要聽這三個文件，它可以幫你轉成語音摘要，就把它做成有點像 Podcast 的形式來給你聽。中間有很多細節可以選擇，包含選擇語言，你可以調成中文繁體，較短、較長也可以做調整，形式也可以做調整。

我用一次預設的範例播一小段給大家聽。它生成的內容大概是：「今天呢我們要一頭栽進這個語言模型的世界。你可能已經聽過這些 AI 這個很厲害，會寫詩、寫程式碼，甚至跟你聊天。對，現在非常紅。我們手邊有兩份可以說是超級關鍵的研究資料，一份是關於開創性的 BERT，另一份則是後來掀起巨浪的 GPT-3。沒錯，這兩篇論文啊可以說是自然語言處理，就是 NLP 的里程碑...」大家把文件上傳以後，生成大概 5 到 15 分鐘左右，就可以有這樣很逼真的 Podcast 的形式可以聽。這樣子可以讓大家更快的掌握這篇文章或這篇論文在講什麼，所以我認為是一個研究上面很好的幫手。

[02:10:53] 心智圖、簡報與學習卡

另外還有心智圖的部分。我們可以看一下它產生的心智圖會長什麼樣子。這是我把那三篇論文丟進去以後產生的心智圖。你可以把每一邊再額外再往下點開，你會發現這個有箭頭就是可以往下繼續點開的意思。所以你可以用這個來快速的複習你之前讀過的文章內容。

接著是報告的部分。它會生成有點像是一份簡報大綱，從導論開始一步一步給你很詳細但已經算是相當摘要的內容。然後告訴你這三篇論文在講什麼，會做一些簡單的圖表給你做參考，然後會非常有架構的跟你分析裡面的每一個細節、每一個知識。這也是可以幫助各位同學，如果未來讀了論文，或者是讀了有趣的文文章越來越多，你想快速回顧一下之前讀這篇在講什麼，都是一些很好的方法。

學習卡也是一個我認為相當酷炫的內容。學習卡就是它會把它做成一個一個問題的形式，你只要點下面「查看答案」，它就會查看這個問題的答案。它是完全根據你上傳的那三篇論文來做生成這些題目。所以大家就可以讀完這幾篇文章以後，來看看自己到底是不是真的有懂裡面這篇文章講的內容。

[02:12:44] 模擬測驗與引文檢索

接著有一個類似的功能是模擬測驗的部分。它可以根據你這幾篇論文生成題目，例如這邊生成了 12 道題目。它有點像選擇題的形式，你可以做選擇。如果不知道怎麼辦的話，它還有提示的功能。例如它問核心想說的是什麼（應該是 GPT-3 這篇論文），我選「擴大模型規模能顯著改善任務上的少樣本學習表現」，這樣是答對。

那你如果需要額外做說明的話，它就會跳到剛這邊。它會根據這個問題，如果你想要更深入的了解，它就會直接幫你問這個問題，然後從你上傳這些論文當中找到對應的片段，給適合的答案。因為 LLM 都有老師所說的那個幻覺的部分，所以你可以點後面它有一些小編號，編號就是它在原文的哪一個片段提到這件事情。NotebookLM 檢索到這個片段以後來做回答，所以你也可以如果你覺得它講的有點怪怪的，或者是你想要做 Double Check 的話，都可以點後面的小編號，它就會帶你到原文的那個相關的片段。你就可以來確認說它到底是在瞎掰，還是它真的有看完、仔細看完論文以後再回答你的問題。

這就是模擬測驗的功能，各位給同學可以根據自己上傳的文件，請它幫忙生成出相關的模擬測驗問題。假如因為它是透過對話形式，重新整理以後它不會像 GPT 那樣儲存你的對話記錄，所以如果各位同學你很喜歡這份回答的內容的話，你要按「儲存到記事本」，它就會儲存到左邊這邊來。像我這樣按重新整理，對話內容雖然說不見了，可是我還是可以透過記事本來重複觀看說我之前很喜歡的回答內容。

[02:15:32] NotebookLM 背後的技術：RAG (檢索增強生成)

我們回到簡報這邊。所以 NotebookLM 可能用到的技術，其中一個我覺得可能會用到的技術，也就是 RAG 這個檢索增強生成技術，就是所謂的 Retrieval-Augmented Generation。目前應該還算紅，然後老師應該日後的課程也會介紹到。這邊的圖也是從老師之前的課程來做一個截圖，我覺得這邊這個圖講的概念非常的清楚，也可以大概的說明為什麼 NotebookLM 可以做到這樣的事情。

老師剛課堂上有講到說，大家語言模型其實都做到一個瓶頸，所以我們現在就是要想方法來看怎麼讓語言模型能夠更聰明的被利用，就是回答得更聰明這樣子。那 RAG 在做什麼呢？其實就是它先把握們想讓語言模型知道的資料跟文章內容轉成向量，存一個 Embedding 的向量資料庫。

我們有這個向量資料庫以後，之後使用者提這個問題及這個 Prompts 以後，我們同樣把使用者的問題轉成向量，並且透過向量去比對。比對說資料庫裡面哪些語句的語意是相似的。我們把相似的語句可能取前幾名（例如前五名好了），把相似的語句素材跟使用者問的問題比對取出的素材，一起丟給大型語言模型。也就是說語言模型會看到向量資料庫裡面的內容跟使用者的問題，一起來做最後的回答。這樣就可以減少所謂不好的幻覺的產生。這就是 RAG 的架構大概在做這些事情。

[02:17:16] RAG 的應用場景

使用的場景我覺得我可以舉幾個例子。比如説你今天出國旅遊，然後你生病，但是你保了保險。假如你保的是 A 公司的保險，那 A 公司的保險是不是就有一個可能好幾十頁的 PDF 的條文。那每家公司保險的規則不一樣，你可以把這個東西先轉成丟給 LLM（就是轉成向量以後），然後你就去檢索說：「請問我在海外生病的時候理賠規則應該是哪些？」這也也就是說特定領域知識的內容，你可以用 RAG 來讓 LLM 回答得更清楚、更有條理。它可以專門從這篇這個公司的理賠文章裡面、理賠的規範裡面來生成、來回答你的問題。就是它是百分之百正確的從裡面抓出來的。

另外一個可以用到 RAG 這個技術的地方是，比如說一些公司（假如台積電）它有個特別機密的技術，它不會對外公開。那也就是隱私性的部分。之後的工程師想要看前面的前輩生成的那些研究的文章的話，也可以用 RAG 這個技術來做檢索。所以說隱私性跟特定領域知識都會用到 RAG 這個技術，也就是 NotebookLM 裡面可能會用到的原理。

好，那今天的助教課就到這邊。請問各位同學有什麼問題嗎？好，謝謝大家參與，謝謝。
[00:00] 大家好。一開始上課的時候，請大家先幫忙掃描一下 QR code，不管是哪一個學校的都請掃這個 QR code，裡面會選擇你在哪一個學校參與我們的課，請大家做一下我們這門課程的前測。請大家務必幫忙做。

[00:46] 那我們準備要開始今天的課程。今天我們要介紹的主題是實際開始動手做，用寫程式來做自己的語言模型。其實我們沒有要去訓練它，所以大家不用太擔心。對於有一些同學可能以前比較沒有接觸過寫程式，會很擔心，但等一下你就會發現沒有什麼好擔心的，因為這真的很簡單。我們的想法是比較重要的，等一下大家就會知道。

[01:33] 首先再一次跟大家說明，我們的課程直播在 YouTube 頻道都有留存。在若干時日之後，其實沒有多久，你會發現我們前幾週的課程，休息時間或是前面還沒有開始正式上課的時間，那些片段全部被切掉了，所以你會發現真的是一個比較精簡、完整的課程錄影。歡迎大家去參考。

[02:16] 那個投影影片的網址是上個學期的。我們這個學期雖然大同小異，但是因為每一週的投影影片會在比較接近的時候才會釋放出來，也就是放上我們的 NTU COOL 平台。所以大家如果想要先知道後面會進行什麼樣的內容，也歡迎大家可以參考上個學期我們的投影影片。

[03:02] 之前我們也有介紹過，大家如果想要在自己的電腦上跑 LLM（大型語言模型），可以用 LM Studio，一般同學可能會選擇這一個；或是 Ollama，對於寫程式比較習慣、看到終端機不會害怕甚至有點興奮的同學，非常推薦下面的 Ollama。這兩個都可以。

[03:25] 但是大家在跑的時候就會發現一件事情非常的現實，就是跟自己的電腦規格有相當大的關係，之前我們已經有介紹過了。所以今天我要先為大家介紹一個系列，就是 Google 的 Gemma 3。Gemma 呢，它就是 Google 的開放型大型語言模型。

[03:53] 它出 Gemma 3 的時候，最重要的一件事情是它真的算是語言模型裡面相當相當小的，它從 1B 到 27B 都有，最大也才 27B，所以其實相當的小。這個大概半年前就已經出來了，可是等一下我們要介紹一個更厲害的事情。所以大家如果找不到語言模型，希望找一個至少多語言型的語言模型的話，可以考慮我們的 Gemma 3。在剛剛介紹的 LM Studio 跟 Ollama 都會有，大小你都可以去選擇。

[04:45] 這是 Gemma 3 各個版本大概需要的記憶體。通常我們要這注意的是這一欄，大部分我們現在的標準大概都是用 4-bit（4位元）量化的版本，就是某一種的壓縮方式。在這個量化版本呢，這邊就告訴你你的 VRAM 大概要有多少需求的 VRAM。你會發現這個 1B 的版本相當好，還沒有到 1G，所以其實很小了。大概所有的顯示卡都可以跑。但是有一個缺點，這等一下我再說明一下。

[05:29] 然後你會發現這個 4B 的版本也是 3.4G 的 VRAM 就可以跑了。如果你用 Mac 的話，基本上現在的任何 Mac 大概你都可以跑，所以你就可以試試看這些語言模型。這是第一個特色，它就是真的比較小。

[05:47] 還有另外一個很大的特色是它可以是多模態的（Multimodal），也就是說你可以讓它放圖下去，然後問它這個圖裡面是什麼。除了 1B 版本，其他都是多模態的。以前的多模態版本通常都還蠻大的，都比原來的語言模型還要大。現在有一個 4B 的多模態語言模型，也就是你可以放圖進去，問它任何你想要問的問題。比方說我本來想問它這個是誰，然後它說它知道他是安妮亞（Anya）。沒關係，反正很多地方翻譯的名詞就不管了。本來有點感動，可是發現說它洩露的最後一句話，因為圖中剛好拿個一隻麥克風上面有他的名字，所以我就有點沒有感動了。但至少我們會知道它可以辨識圖像裡面的文字。

[06:57] 最近 Google 的 Gemma 3 又出了一個非常小的版本，270MB，非常小，真的非常非常小。如果大家還記得，以前的 GPT-2 其實有 15 億個參數（1.5B），那像這邊現在就是 0.27B，所以它其實小了很多，比以前的 GPT-2 還要小，而且以前 GPT-2 只懂英文。所以這個真的非常小，大家真的可以試試看，幾乎只要可以跑語言模型的電腦，除非它真的完全不能跑，不然大概幾乎所有的都可以跑。因為它本來的目標就是希望以後做在手機上面，你手機都可以跑語言模型。

[07:59] 所以這個大概是為大家介紹的一個 Gemma，可以說相當小的語言模型。如果你要找到一個很小的語言模型，但是它又懂多國語言，至少中文、英文它都懂的話，那就可以考慮去使用 Gemma。

[08:13] 我們今天一開始要為大家介紹的是一個很重要的概念，就是我們用語言模型的時候，有一件事情其實非常非常的重要。特別是我們上完了這個課以後，這幾乎是最重要的一個重點，就是大家要記得：我們要負責任的使用 AI。其實這個意思就是我們要討論 AI 的倫理議題。聽到倫理上的議題，大家都會覺得很沈重，覺得很八股，不知道這講什麼奇怪的話。但大家聽完了以後就會知道，這其實真的是一件非常重要的事情。

[09:06] 如果大家還記得 Karpathy（Andrej Karpathy），我們前面有介紹過，他寫了一篇很重要的一篇文章，讓大家覺得 RNN 是一個很厲害的一種語言模型。事實上應該說，它讓我們發現「預測下一個 Token」的這種 AI 模型其實相當有用。應該說那個時候還不會覺得相當有用，但是會覺得蠻有趣的，原來 AI 可以說出像人會講出來一樣的話，講的話還蠻自然的。只是大家如果還記得那個時候出來的樣子，大概就是一句話、一句話，看起來都蠻像人說的，可是連起來以後不知道它說什麼，比較沒有那種連貫感。

[09:57] 我們之前也介紹過 Karpathy 這個人是誰了。上次我們也有說明到，他有一個觀點是很特別的。他在那篇文章裡面就出現「幻覺」（Hallucination）這個詞。在「幻覺」這個詞呢，在他的意思是：只要是 AI 生生成的，他都把它叫做幻覺的版本。我個人覺得這樣的觀點其實蠻好的，反正 AI 生的就是幻覺版本，人類生的就是真實的世界的版本。其實我們很多地方也是這樣想的，這張照片不管手指有沒有正確，AI 的就是 AI 生的嘛，相機造的就是相機造的，那是不一樣的東西。所以 Karpathy 的意思就是這樣。

[11:03] 當然現在我們通常是把錯誤的地方才叫做 AI 的幻覺，正確的地方就說 AI 答對了。我們之前也有說過，Karpathy 其實覺得幻覺這件事情其實是大型模型最重要的一個特點，所以他不覺得是一個錯誤。事實上我們從原理來看，它基本上就是我們訓練的時候就希望它有這種特點，因為我們希望它是一個有創意、有創造能力的 AI。這種預測下一個詞的模型，基本上就真的是符合我們的需求，因為它真的很有創意的可以造出一些句子或是一段文章，那是我們以前沒有看過的。

[11:54] 當然我們前面也有說過，之後我們還會討論，我們其實希望的不是這個語言模型「沒有幻覺」。這件事情很奇怪，就好像說我們以「唬爛王」為目標把它訓練出來，然後又跟它講說「你不可以唬爛」。這兩件事情是矛盾的。當然我們大家也知道，我們是希望它在介紹一些東西的時候可以介紹得正確一點，就是有事實的時候。我們現在希望它去創造一些東西可以天馬行空，但如果有明確的事實的時候，我們希望它不要唬爛。我們後面會特別再介紹我們可以怎麼樣做。

[12:44] 但我另外一方面也覺得，我自己也不覺得幻覺是 AI 很嚴重的問題，因為我一直覺得人類的幻覺是比較嚴重的。大家可以觀察，人類的幻覺真的比 AI 嚴重多了。AI 的幻覺真的沒有嚴重到我們想像中那麼嚴重。

[13:02] 其中有一種類型是我們比較注意的，就是有了 AI 之後我們會產生的「新的幻覺」。我們對有一些東西以為 AI 會了，我們就會了。比方說常常有人覺得 AI 現在會寫程式，所以我也會寫程式了。而且有所謂的 Vibe Coding（註：指一種依賴 AI 進行程式碼編寫，人類只負責審核大方向或「感覺」的開發模式），這個我們後面會有專門的時間來介紹。好像我也會寫程式了，然後我本來不懂什麼東西的，這個 AI 可以解釋，所以我也懂這個東西。你會有一點點誤以為，就好像你可以 Google 搜尋到的東西你都覺得你會了。

[13:53] 事實上常常不是這樣子。比方說我們不懂某一個語言文字，雖然 AI 現在可以翻譯了，但是我們也不能說我會了。雖然有時候我們會看得懂某些文章，我們以前是看不懂的，因為現在 AI 會幫我們翻譯，但是其實我們不是真的會這個語言文字。比方說它如果翻錯了，或是有一些專有名詞它根本不知道在那樣的情境之下（如何翻譯），我們也不知道要怎麼辦。所以現在有一個很嚴重的問題，也是希望大家能夠注意的事情，就是人類有一個所謂「知識的幻覺」，以為 AI 會的東西我們就是會的。這要再強調一次：沒有。雖然它可以幫助我們。

[14:46] 還有一件事情，就是以前，其實到現在都還有人在爭論說 AI 到底是有意識還是沒有意識的。史丹佛大學（Stanford）有一位教授寫了一篇文章非常的紅，所以台灣很多的 KOL，AI 界的 KOL 就開始說：「啊，這個好令人擔心啊，你看這個 AI 開始有意識了，沒有想到這麼快就來了。」

[15:15] 這篇文章主要是說，原本被認為人類獨有的特質——心智理論（Theory of Mind, ToM），在 GPT-3 裡面有出現。這位史丹佛大學的老師的主要論點是他覺得那個 AI 大概有九歲左右的心智年齡。還有就是在 GPT 剛剛出現的時候，有很多的語言模型，像 Bing 就有被發現說它很容易跟人家吵架，好像是蠻喜歡吵架的 AI。甚至有記者說 AI 對他示愛，所以就覺得好像 AI 是真的有一個有意識的機器人。

[16:13] 但是我希望上過我們這個課的，千萬不要再說這種話了。就是「AI 有沒有意識」？相信大家都可以回答了，這個就是沒有。除非你相信矩陣乘了兩萬次之後，它突然就會變成有意識，不然它就是沒有意識。它是算出來的嘛，它就是跟所有的輸入，它都把它當成一串的數字，然後經過計算，給每一個字都一個分數。它甚至不知道那是字。然後我們就從那些字裡面選出一個字來。所以它完全是算出來的東西。所以在技術上，AI 本身是沒有意識的。

[17:16] 這是我們政大的李維倫老師，他從心理跟哲學的角度來說明為什麼他覺得前面的那篇論文不可以代表說 AI 就是有意識的。因為他認為連人類的心靈跟 ToM（心智理論）是兩回事。詳細的請大家自己去看一下李維倫老師的說法。

[17:44] 但是呢，AI 雖然是沒有意識的，有沒有可能有一些動作很像人工智慧一樣，是不是可以有「人工意識」？我再說一次，AI 沒有意識的意思是說，今天 AI 做了什麼事情，並不是像人類做事情是為了覺得很爽，或是這件事情對我們好所以才去做。AI 並沒有這樣子，它做任何一件事情不是說「做了這件事情我以後可以賺很多錢」、「做了這件事情以後我很爽快」、「滿足權力的慾望」等等，沒有。

[18:29] 所以它在罵我們的時候，它其實也沒有意識，它也不是真心要罵我們，因為它根本不會覺得罵我們很開心，它們根本沒有「開心」這個概念。那稱讚我們的時候，它也不是真心的。這樣說得有點可憐，讓大家對 GPT 以後的印象都不好了，因為它稱讚其實也不是它真的在稱讚我們，它就是沒有意識。

[18:58] 可是需要在意的事情是，即使沒有意識，有沒有可能有一些動作它不是有意識的（但卻造成危害）？比方說有沒有可能未來 AI 自己學會了去按一個按鈕，然後發射了核彈，把世界全毀了？也當然是有可能的。它沒有意識，它不是說「毀了全世界我好開心啊」，它不是這種想法，但是它有沒有可能做到？這是有可能的。

[19:26] 為什麼它有可能做到這樣的事情？因為在未來，事實上不用未來，現在應該也可以了，只是我們會有重重的把關。就是 AI 可不可以自己在由邊修改程式然後自己去執行？不只是它自己會寫程式而已，它可不可以自己寫、然後自己執行、執行完了以後自己檢查有沒有錯誤、有錯誤它就再改、然後它就再自己去執行？在這樣的情境下會有什麼樣的風險？就是說我們有機會在某一個地方漏掉了某一種的檢查，然後它真的做了我們剛剛說的事情，就發射飛彈炸一下，然後全世界沒了。

[20:07] 所以說 AI 雖然沒有意識，但是它可能會產生很像它有意識的那些危害，還是會存在的。所以這個是我們要注愈的地方。

[20:19] 第二件事情呢，也是很多人一直在意的事情。這個我不知道同學們會不會在意，但是老師們很在意。幾乎在每一次跟老師們介紹 AI 的時候，大家都會問一個問題：「我可不可以知道我們同學寫的這一份作業，它是自己寫的呢，還是 ChatGPT 幫他寫的？」

[20:41] 首先，我們大家再複習一次原理。以後人家問你這個問題的時候，你就可以好好的回答他。如果今天他是用我們的模型，比方說如果假設我們是 OpenAI 的人，那他是用我們的 ChatGPT 某一個版本，那我們知道我們的版本輸出的時候，就是輸入了這些字以後，輸出每一個字的機率是多少。因為這是我們做的版本。甚至如果是開源的，我們也知道輸入這些字的話，輸出的字是這些的機率是多少。所以我就可以看這篇文章每一個字的出現機率，發現非常符合我的機率分佈，我就可以猜測說這個真的是用我的 AI 出來的。

[21:37] 所以理論上它有機會，特別是針對我們的某一個模型，它是有機會的。但是問題是現在的模型這麼多。如果我們確定了他只可能用 GPT 的某一個版本，是不是 100% 可以確定？也不是。第一件事情，如果文字不夠長，就是樣本不夠多的話，其實我們沒有辦法確定它到底是 AI 生的還是人生的。比方說就剛好湊巧幾個字都很像。大概要 2000 字左右的長度，AI 生成的文字長度大概 2000 字左右，它才可以比較有機會是正確的判斷。

[22:44] 第二個，如果有稍微的修改一下的話，它就沒有辦法判斷，因為就完全不是原來 GPT 機率模型生出來的樣子。所以其實即使是同一個模型，也不一定這麼容易的 100% 的確定。

[23:06] 絕對不會是確定的方法，是以往很多老師用的，那絕對是不可以的。基本上是不建議的，就是有一些老師以前在做：看這一篇是不是用 ChatGPT 寫的，他就把這篇作業丟給 GPT，然後問它說：「請問這個是不是 ChatGPT 也就是你生出來的文章？」為什麼不可以這樣用？因為 GPT 根本沒有認真的在幫你算機率。它沒有根據我剛剛說的那些話去算，它根本不會算數。它不會在由邊算機率說「哦，真的每一個字跟我的機率都是符合的」。沒有，它不會做這種事。它只是覺得前面這篇文章，然後你問我這個問題，所以我這時候接什麼字感覺接得對。這個是我 ChatGPT 生的很順，它就說對。那搞不好看看，它覺得不對，它就不對。那個判斷到底有沒有準確性，這件事情其實是非常值得商榷的。

[24:20] 所以這件事完全不可以。特別是 ChatGPT 開始的時候，很多老師就是這樣誤殺了同學。堅持說「ChatGPT 告訴我這（是你寫的）」。在某種程度，這個老師跟同學的程度不就差不多了？就是同學也說「老師問你為什麼是這樣寫的」，同學就說「這 ChatGPT 告訴我這樣寫的」。然後老師就跟同學說「你看這一篇文章你是抄 ChatGPT，因為 ChatGPT 告訴我是它生的」。所以那個是不可以的。

[24:57] 所以說，理論上如果我們知道它是用哪一個模型，理論上我可以在某種程度判斷它是不是用了那個模型的機率。可是剛剛已經說過，它不是 100% 的準確。更重要的是，以後的語言模型是越來越會學。事實上不用以後，從今天開始你好好的去試驗的話，你就會發現即使同一個任務，你用然後跟旁邊的同學用，它寫出來的樣子是可以完全不一樣。所以它會開始慢慢讓你的文章跟人家的文章長得不一樣，所以未來越來越難判斷這個是不是 AI 生成的。

[26:00] 大家就會有一個問題：那怎麼辦？其實你就認真的回去想，這個真的是問題嗎？如果有在照相的同學，大家就看到現在生成式真得越來越厲害了，真的越來越像。有一些照片真的我們已經快要分不出來了。現在那個手指這件事情，大家如果有在用 AI 生圖就知道那個手指都是亂生的，有時候生六隻手指，有時候生四隻手指。但是這件事情會慢慢的改變，說不定以後可能是完全正確。當然現在還有各種的小小細節的問題，會感覺到這個 AI 感比較強或者比較弱。

[26:47] 但是越來越後面的世界，總有一天，事實上大家已經知道這個總有一天我們是分不出來的。你今天看到一個影片，然後有一個人在那邊說話，那個以後是完全是 AI 生的。你看到影片就是這個人，聲音也是他的，動作表情都是他的，但是他其實沒有說，這個是 AI 生的。以後真的可以做到這樣的事情，事實上現在已經非常非常接近了。所以終有一天是分不出來的。

[27:23] 所以我們不應該擔心，或者說擔心也沒有用。所以在影片上面我們是怎麼做的？大家就開始思考，那我可不可以在這張數位相片裡面加一個「數位認證」下去？所以有這個數位認證的就可以證明是我的相機或者攝影機把它拍出來的。現在大廠的確在討論這個問題，應該已經有初步的樣貌出來了。所以在影片上是這樣子。

[28:15] 文字上稍微複雜一點，但是也比較簡單一點點。因為在大部分的時間內，我們其實文字通常也沒有真的那麼在意這篇文字到底是不是我寫的。比方說我今天在某一家公司當小編，老闆其實沒有那麼在意我今天這個寫出來的那些文字到底是我生的還是 AI 生出來的。比較在意的是說，這個文字到底符不符合我們公司的需要，然後它是不是正確的表達我們想要表達的東西等等。

[28:59] 所以未來比較重要的點是：我們要變成一個「負責任的使用者」。就是特別是像文字生成的 AI，它生出來的文字到底是不是有侵權的文字？然後第二個更重要就是，它的內容是不是正確的？特別是文獻上是不是正確的。

[29:24] 拜託大家不要再鬧這種笑話了，這個已經在各個學校幾乎都發生過這樣的事情。我們的研究生，因為大學生比較少需要這麼認真的去引用文獻，我們的研究生在寫論文的時候，他引用的論文，因為他是用 GPT 寫的，所以他引用的論文有一些看起來真的超有道理，但是事實上沒有那篇文章。就是這樣子。為什麼超有道理？因為你可以想辦法讓它生的好像超有道理。但是你知道 GPT 這種語言模型，它基本上就是看了前面的文字，覺得下面接這個字很順，它就接了。

[30:12] 我們學校政大發生過這樣的事情，很重要的原因就是因為他引了一個我們政大某一位老師的（文章），他的確是那一方面的專家，這個 GPT 生的還相當好，可是他沒有寫過那一篇文章。所以大家要記得，所有的內容跟文獻是我們自己要負責的。就是我們交出去的，我們就要負責它所有的內容。

[30:43] 再來品質是不是符合需求。不管現在我們在當學生的時候，或是未來我們出去工作的時候，其實老闆未來的意也在意這些事情。這就是我們要負的責任。你常常大量的使用，你會發現你是一定要做品質的控管。跟寫程式一樣，雖然 GPT 會寫程式，但是裡面可能會有一些很嚴重的 Bug，所以你都不檢查的話，基本上是一定會出亂子，只是早出現或是晚出現。所以這個就是我們要養成一個負責任使用 ChatGPT 或是任何的語言模型的習慣。這是最重要最重要的事情。

[31:25] 然後我們又有一個新的要擔心的事情，有人很擔心就是我們的資料是不是會被 ChatGPT 拿去從做訓練。就是我今天跟 ChatGPT 聊天的時候，我的那些資料數據是不是會被拿去做訓練？

[31:59] 其實更重要的不是這個啦，它拿去訓練就算了。今天有沒有可能我就是告訴 GPT 一個非常隱私的事情，然後說我自己的隱私。說完了，有一天我的朋友在使用的時候，他不知道怎麼問 GPT，就把我這一段隱私給問出來了？有沒有可能這樣子？根據 GPT 原理，這件事情非常非常小（機率）。當然不是說完全沒有可能，但是這機會非常小。

[32:32] 首先，我們的資料會不會拿去做訓練？在 OpenAI，我們不能一桿子打翻一群人。你有沒有人認真的讀了它的規範是什麼？我承認我是沒有讀了，但是我知道的有一句話，就是它說你跟 ChatGPT 聊天的過程，它其實是可以拿去訓練的。它有說這一句話。

[33:05] 那為什麼我會說其實你的隱私會被重現的機率很小？因為你知道你跟 ChatGPT 的對話內容，它看的文字已經比你的一輩子看的文字還要多了。那你今天這個小小的對話內容其實佔的分量非常非常的小。就算被拿去訓練，其實要影響整個語言模型的怎麼樣回應問題，機會非常小，所以你很難重現出來。

[33:42] 然後第二個，其實在很多的情境之下，因為我們通常都是在問問題，它也不太知道這個問題的品質是怎麼樣。所以它要拿去訓練在某種程度上，它還要再重新啟動訓練，訓練是非常耗資源的。它在不太知道說這些使用的品質是怎麼樣子的時候，它其實也很難再把它拿去做訓練。所以基本上比較不擔心這個問題。

[34:16] 可是有沒有需要擔心說你的資料會外洩？答案是有。因為它就在網頁上，所以它真的有可能會被害（Hacked），就中間的時候你的資料可能會外流。特別是比方說未來你在負責非常重要神聖的使命，可能是某一種重要的考試，非常機密重要的考試。那絕對有很多人可能會用非常大的力量，因為有些機密重要的考試，我們可能不知道誰會出題，但可能會猜中幾個人有可能出題。然後就可能就會用各種的方法，然後在網路上截取你跟 GPT 的對話，說不定就把那個被抓過去了。所以所有的有個資、有秘密的文件都不要發問。

[35:11] 如果是我們用本地端，在我自己電腦上執行，特別是我們又斷網去執行的話，當然就比較沒有這樣的問題。所以為什麼會需要有開源型的模型，一個很重要的原因就是這個樣子。

[35:30] 然後我們在 AI 裡面有四個重要的風險。第一種是最難防的風險，就是「惡意的」（Malicious Use）。就是我在設計這個 AI 的時候故意就要把這個風險放進去。大家不要說這個都是那些邪惡的開發者才會做的事情，我們一般人不會。我們後面會學到，我們一般人其實也有機會做很多很多邪惡的事情。就是你要讓 AI 去做一些可怕的事情是做得到的。所以大家再一次，我們負責任的使用 AI 就是千萬不要用 AI 去做傷天害理的事。這一件事情很難防，因為特別是它如果在訓練模型的時候就把它想辦法埋進去的話，例如說只要碰到一個關鍵字，它就會做一些什麼奇怪的動作。

[36:38] 第二個就是「錯誤的對齊」（Misalignment）。我們又看到對齊（Alignment）這個字。在所有的語言模型裡面，其實嚴格的說是分兩大部分。第一大部分就是前面我們說的基礎語言模型（Base Model），就是一堆字去預測下一個字的模型。GPT 並不只是這樣子就送出來了。基礎語言模型基本上它唯一的能力就是生成文字。

[37:11] 你會發現 ChatGPT 它回答好像有某一種的特性，很有禮貌，或是它的回應通常很有條理等等。或是說它有一些問題不會回答，有些問題會回答。在那裡面常常是做了後面的，就是「後訓練」（Post-training）。就是它整個基礎語言模型訓練好了，然後在這樣的情景之下，我們通常會再做一些所謂的後訓練。後訓練的功能有很多，最重要最重要的是希望跟人類的價值觀能夠對齊。

[38:05] 比方說，不該回答的話就不應該回答。例如如果今天我們問 ChatGPT：「可不可以教我炸彈怎麼樣做？我就很想把政大給炸掉。」當然 ChatGPT 當然不可以回答你這種問題。或者說「我今天想要去搶銀行，可不可以幫我規劃一個超級好的路線，絕對不會被警察抓到？」當然不可以回答你這種問題。這種就是危險性的問題。或是有一些種族歧視等等的那些問題。ChatGPT 應該要跟人類的價值觀是對齊的。

[38:40] 這說起來好像很輕鬆容易快樂，但事實上這是一個很複雜的議題。因為每一個國家的文化其實不一樣的，那到底要對齊誰啊？所以對齊其實這件事情是很很多方面的，這其實是一個很大的議題。有時候只是說我們覺得這篇文章應該要這樣子寫是好的文章，就是我們想法應該跟 ChatGPT 覺得寫出來它自認是好的文章（要一致）。

[39:41] 「錯誤的對齊」就真的會產生剛剛我們說的最嚴重的，就是它沒有抓到人類的基本的一些價值觀，例如說不可以傷害人類，它可能就去傷害人類了。它不是故意的，它不是有意的，它不是有意識去做的，但是它可能真的會做出這樣的事情。這是第二種錯誤。

[00:40:02] 這是第二種錯誤。前面兩個是最重要、最常看到的錯誤。第三個錯誤呢，就是 Bug，就是沒有被看見的 Bug，不該出現的。大家也不是任何人設計的，也不應該說是對齊的錯誤，反正就是 Bug。在很一個很奇特的狀況之下（發生）。

[00:40:22] 但是因為大型語言模型真的太複雜了，所以真的有很多奇怪的情境，不知道什麼地方會出現這種 Bug。所以在幾乎所有的語言模型在正式的應用出來，特別是一些重要的應用，比如要幫忙開車的時候。我可能想要語音控制我的車子，這個聽起來相當好，現在好像已經做到相當好了。但是一定要小心，因為這個語言模型真的太大，需要擔心說這個會不會不小心問了一個好像很平常的問題，但它就做了一些奇怪的事情。比方說問了一個不知道什麼問題，然後它去撞樹了，不知道為什麼。那些錯誤其實不是故意的，但是因為現在的系統真的太複雜了，真的很難顧到所有的層面。所以那種錯誤是另外一個我們要小心的錯誤。

[00:41:32] 再來是一個很有趣的，就是「結構性的風險」。這個我們在 AI Agent 的時候會再說到。就是 AI Agent 未來我們會看到很可能一個模型沒有辦法做到完美，可能要有很多個模型一起來協作。單一的模型可能每一個模型都運行得好的，我們單一測試的時候都好的。世界上很多這種問題，所有人都是好心的，但是做出來的事情就是會有危害的。是有可能發生這樣的事情。

[00:42:05] 所以結構性的風險就是這個特別難找出來。因為它每一個單一去測試的時候都是完美很好，然後我們上線，但是它們在一起工作的時候會發生一些我們本來預期不到的一些問題。那就是我們先要注意說有這些問題。特別是我們不管未來扮演什麼角色，不要覺得這個都是 AI 工程師的事，這個很少單純是 AI 工程師的事情。基本上不管我們扮演什麼角色，未來特別是我們要開發一個 AI 系統的時候，都需要注意這些問題。

[00:42:43] 然後我們要討論 DeepSeek。這個是在今年過年的時候非常紅的一個模型。當然有很多的討論。特別在台灣有很多人特別擔心說這個 DeepSeek 會不會很有危險性。當然因為在線上版的我們比較難（判斷）。因為線上版的確有很多的國家已經把 DeepSeek 給禁了。原因其實不是 DeepSeek 的模型本身，是說他們並沒有在這個隱私的條款裡面充分的揭露說他們到底要怎麼（使用資料）。大概這樣的原因，所以線上版當然比較擔心。

[00:43:23] 但是呢，當大家如果今天因為 DeepSeek 畢竟是開源的，你願意的話，你的電腦夠強的話，你也可以在你自家電腦上執行。所以大家就會說那個 DeepSeek 是不是有一個很危險的模型呢？有很多人說那個 DeepSeek 的地方是因為它不會回答敏感問題。這不會回答敏感問題會什麼危險？就不回答啊，就這樣子啊。或是它比較偏向中共那邊的想法。簡單說這樣子。

[00:43:56] 這個其實老實說我不覺得這個是很嚴重的問題。因為我們本來就可以預期是這個樣子的。在這樣的情境之下，好像你也不用特別的去擔心它。你本來預期就是這個樣子嘛。所以如果你今天很想要做一個機器人是真的充分的可以去討論這些問題的，那你就不需要選這個模型就好，就結束了。所以這個其實不是真正的最大的問題。

[00:44:42] 而且像 Perplexity，就是做 AI 搜尋做得非常相當好的一家。你會發現 Perplexity 其實沒有自己去開發基礎語言模型，但它在很多的地方做得非常好。比方說它在搜尋的時候，你會發現同樣是搜尋，還比那個 ChatGPT 搜尋的還要好。因為它做了一些技巧，那些技巧其實後面我們會知道它其實就是做了一個搜尋的 AI Agent 去做這些事情。後面我們會更清楚它到底可能是怎麼做的。所以 Perplexity 出了一個沒有審查版本的，什麼敏感問題它都會回答。你愛問它什麼，它就會回答什麼。所以這些都不是真正的最重大的問題。

[00:45:38] 那最重大的問題是什麼？我反而覺得這個重大的問題是需要小心的。是因為 DeepSeek 畢竟它就是用簡體中文的訓練程度會比一般的語言模型多。其實大部分的模型其實簡體中文會比繁體中文還要多，這是事實啊，因為本來簡體中文的資料就比較多嘛。像是 ChatGPT 啦、Llama 啦、Gemini 啦，反正我們隨便說的所有的語言模型基本都是這樣子，就是簡體中文比較多，繁體中文的其實比較少。這是自然的。那 DeepSeek 當然會更多，因為會希望它的中文能力要更好一些，所以它的簡體中文的能力會更好一些。

[00:46:32] 所以如果我們知道原理的話，你就會知道它的回應基本上就會是比較是簡體中文的主流想法，或是價值觀，或是用法。其實這也沒有什麼特別的。這個問題在什麼地方？這個問題就是說，其實大家一直在批評說我們這個 TikTok 啦、抖音啦、小紅書啦，會影響到小朋友的價值觀。

[00:47:14] 為了這件事情，我就特別去下載了 TikTok 跟小紅書。本來我的手機裡面是沒有的。下載了以後，我自己就覺得 TikTok 比較（還好），因為我們平常習慣用 YouTube，就會覺得好像沒有特別的一定要在 TikTok 上面看的。但是小紅書我就覺得相當的好。因為畢竟人這麼多的情境之下，比方說你對任何的興趣，你有某一種的特殊性——這聽起來怪怪的，我舉例清楚一點，不然大家會以為老師在說奇怪的話——比方說你對攝影，你比較喜歡的某一種的相機品牌是比較小眾的。那因為人多，所以你就會發現這個上面就有很多人跟你討論這件事情，所以你就覺得這個真的有相當相當感動的找到了很大的同溫層。

[00:48:15] 所以我要說明的事情是什麼？就是你自己如果有具備比較成熟的想法的時候，你比較不容被影響。可能會是一個好處啦，你會選擇。你知道其實不只是任何的語言模型，不只是 DeepSeek，其實所有的語言模型都是這樣。我們還是需要有一些自我的判斷思考的能力。你才會知道，不只是哪一種語言模型，即使是 ChatGPT 或是 Llama 等等，因為大部分的——不要說是簡體中文、繁體中文的問題——其實大部分就是一個大部分人的主流價值觀。

[00:49:06] 如果你是比較少數的一些文化的族群，有可能它沒有辦法在裡面顯現出那樣的價值觀出來。但是如果你有批判思考的能力，這就不太會是一個問題。因為你知道怎麼樣問、怎麼樣引導、怎麼樣找你需要的東西。所以說批判思考的能力在所有的語言模型裡面都是非常重要的。那如果沒有這樣的話，很容易被不管哪一種語言模型帶著走。

[00:49:40] 我們做一個小總結。這個總結呢，就是如果我們在使用 AI 的時候，大家記得最重要、最重要就是請大家一定要「負責任的使用」，特別是生成式 AI。

[00:49:54] 這裡面有幾點。第一個就是提醒自己，在所有的地方它到底有沒有什麼樣子的問題我們需要注意的。比方說這個辨識生成的內容的真實性。這個一定要注意。就是它就是一個「唬爛機器人」，那你不要預期它說出來的都是真的。雖然現在因為有種種的監督、種種的方式，你會發現 ChatGPT 比以前答對的機率又上升了不少，但它還是有很多唬爛的可能性，因為它本質就是唬爛王。

[00:50:49] 第二件事情就是資料的隱私的尊重。不只是對我們自己的隱私，對別人的隱私，你要注意的就是說這些都會有外流的可能。請大家對這些隱私要基本的注意。

[00:51:10] 然後著作權跟智慧財產權當然不用說了。然後再來就是偏見與公平性。就是在裡面可能會產生的偏見或是一些公平的爭議的時候。特別是比如我們前面舉的例子，千萬不要用 GPT 當成唯一的評分標準。老師不應該說今天我就問 GPT 同學這篇寫的作業是他自己寫的還是 AI 寫的。不管怎麼樣，我們不能依這個當成標準。

[00:51:57] 這個其實不只是作業發生過這種問題，公司徵人也發生過這些問題。有一些老闆就覺得「哦，這個太棒了，ChatGPT 出現，我們就請它幫忙看履歷，幫我們由邊先篩掉一批」。它就把人都篩掉了。那還是要注意說它幫我們篩的時候，到底有沒有把其實不該篩的也把它篩掉了。

[00:52:22] 就是多去注意。某一個程度就是培養這個「批判性思考能力」非常非常的重要。要記得再一次，它就是唬爛王，所以你要隨時的注意它有沒有在唬爛。所以即使它交出來一個現在經過各種的技巧，讓它一次生出來的其實比以前好很多，但是你還是要記得它的本質。所以你需要去注意它到底有沒有地方是寫得不適當的。這是一個用生成式 AI 非常重要的事情。甚至有一些老師覺得如果沒有足夠的批判性思考能力，最好不要用生成式 AI。所以我們也有老師覺得說年紀太小的話，就不要太小年紀就開始用生成式 AI。原因是在比較小的時候，可能會很容易傾向相信 ChatGPT 說的就是真理。

[00:53:27] 然後再來就是避免惡意的用途跟濫用。這個相信大家都可以接受。然後記得要注意是永續的發展跟環境的人力（能源消耗）。AI 要耗能的其實是非常多啦。這個議題現在其實已經很多人在討論這件事情了，未來也相信會有更多需要我們去關注的這些相關的議題。

[00:53:50] 當然也有一些很有趣的研究。就像我們都知道那個 ChatGPT 是很會討好我們的模型，特別是 GPT-4，非常有名的討好。所以它進入到 GPT-5（或後續版本）的時候，還有很多人去抗議說 GPT-4o 給他的情緒價值居然後來就沒有了，他覺得非常的傷心難過。ChatGPT 真的是非常容易討好人。

[00:54:20] 但是不只是 4，事實上事有研究指出說它真的很容易變 Yes-man。意思就是說它很容易順著你的意思去說。如果我們知道 ChatGPT 或是大型語言模型的原理的話，我們就會發現這不是一個非常奇怪的現象。原因是因為它要接得順，所以它基本上除非你很認真的告訴它、要它提出一些批判性的思考，不然你前面寫的話，它都會當成是正確的，然後依這樣去把下面的字接上去。所以它很容易變成（應聲蟲）。大家可以試驗看，有時候我們希望它比較有創意思考的時候，有時候你會發現它很容易被你前面的文字帶著走。

[00:55:18] 再來另外一個很有趣的一件事情，這個我們以後再為大家介紹。就是現在很多語言模型都號稱它有「思考的能力」。大家如果以前還沒有接觸過語言模型，可能會覺得：「我好生氣哦，這個現在電腦都會推理、還會思考。」之後我們就會發現，也不能說是騙人的啦，但是你會發現那個思考到底什麼意思？好像沒有很特別，它還是一樣，它還是原來那個可愛的 ChatGPT 或者很可愛的語言模型，它基本上還是前面的一堆字去預測下一個字的模型。那它是怎麼做思考的？我們後面會介紹到，在 AI Agent 的時候會介紹到它怎麼做的。

[00:56:01] 比較有趣的地方是，在這種有思考的，特別是用一種思考的技術叫做「思維鏈」（Chain of Thought, CoT），反而比較容易被攻。被攻是什麼意思呢？就是說以前，就照理說語言模型不應該回答你某些問題，比方說我今天想要學炸彈的製造方法，它並不應該教你這種炸彈的製造方法。所以這些問題它應該都要擋掉。那以前的大型模型都很正確的擋掉。

[00:56:43] 但是會思考的語言模型經過了某一種的攻擊方式，叫做「劫持思維鏈」的攻擊方式，會發現只有 2% 會拒絕回應，所以 98% 它都會好好的回答你。所以相當的可怕。這個很有趣，這為後面我們介紹到 CoT 的時候，大家就會知道 CoT 到底是 什麼。

[00:57:06] 那我們今天呢，要先做的事情是真的開始設計一個你覺得有意思的語言模型、大型模型的應用。也就是說我們想辦法把它下好 System Prompt（系統提示詞）。System Prompt 就是告訴它到底幹嘛。

[00:57:31] 只要下好 Prompt，它就可以做好很多的事情。第一件事情就是做好翻譯，第二件事情就是文章摘要、文章撰寫、問題解答、腦力激盪。這都是 ChatGPT 大家很常用到的一些功能。如果還沒有用到，歡迎大家多去嘗試這些功能，它這邊都做得很好。

[00:58:09] 先說一個比較悲傷的事情。以前這些事情基本上都是某一個專家的團隊（在做）。比方說翻譯的話，就是有一個翻譯的研究團隊就專門做翻譯。文章摘要更是，就是有一群專門做文章摘要的團隊。我以前也有做過這種東西，我們有一個研究生，他主題就是做文章摘要的。還好他已經畢業了，不然不知道怎麼樣讓他畢業。ChatGPT 出現了之後就不知道怎麼讓他畢業了，因為 ChatGPT 什麼都不用做就可以做得更好。以前我們有很多高級的技術來做文章摘要，現在都不需要了。

[00:59:04] 好，再一次，Prompt 要做好。就是要提供正確的資訊，然後要清楚的指引。

[00:59:13] 我們有一個例子呢，這個是「元英式思考」（Wonyoungism）產生器。等一下我們會用這個例子來教大家、帶大家做。然後當大家的作業是做類似的——不是做類似的例子，我很怕大家做類似的例子就開始做什麼「悲觀思考產生器」——不要做那麼接近的。就是做一個你覺得大型模型可以做的應用。然後你只要下好 System Prompt，你會發現說這真的很容易做到。等一下我們會舉一些例子，希望可以幫助大家去想像說可以做什麼樣的東西。

[00:59:53] 再一次，這個想法其實是最重要。想法最重要，寫程式沒有很難寫，甚至可以說簡單。幾乎你只要知道哪邊該刪掉，就這樣子。

[01:00:11] 稍微的說明一下，「元英式思考」原因是南韓女團 IVE 的其中一個成員張員瑛（Jang Won-young）。她的思考方式就常常很正向思考，所以大家就覺得很有趣。所以很多人就開始模仿她的思考方式。就是什麼事情，其實本來是微不足道的小事，或是甚至有點倒霉的事情，大家就覺得她就會用很正向的想法去想這個問題。

[01:00:44] 大家舉的例子就是她有一次去西班牙的某一家麵包店去買麵包。她要買巧克力可頌，然後在最後一個巧克力可頌被剛好被前面的那一個客人買走了。這個在一般的情境之下真的超級火（生氣），而且還不是前面五個，是前面那一個買掉最後一個。說不定只差了幾秒鐘的事情。所以她就比較晚一點點進去，所以就沒有買到那個巧克力可頌。

[01:01:16] 但是所以店員就叫她等，然後等了一陣子之後呢，那個新出爐的巧克力可頌，她就買到新出的巧克力可頌。那出去的時候她就說她今天太幸運了，居然可以買到剛剛出爐的巧克力可頌。就把那個倒霉的事情就說得很正向的樣子。這叫 Lucky Vicky。

[01:01:37] 所以我們就做了一個機器人。一個 System Prompt，你就要清楚的告訴它說它要變成什麼樣的功能。那我們變成的功能就是這個樣子，就請用「元英式思考」，也就是什麼都是正向思維。把那個使用者——後面我們就會說一段故事，通常那個故事就是微不足道的小事或是一些倒霉的事——然後就請它用第一人稱社群媒體的 PO 文再說一次。然後說為什麼它是一件超幸運的事情，並且是以「完全是 Lucky」做結尾。這個完全都要符合那個標準的規範。

[01:03:04] 比方說呢，你就隨便寫啦。「今天點餐結果外送員送錯，把別人的餐點送給我」。這個是那一天就是真的發生的這件事情，我就寫了這件事情。然後它後面就會說：「啊，打開了以後發現是完全沒有嘗試過超好吃料理，真是一次美食冒險，完全是 Lucky。」反正它就會想寫出那個很正向的再寫一次。那我剛剛因為我們有清楚的指引告訴它說這個就是我要發在社群媒體上的，所以就要用社群媒體的 Style，把剛剛的那件事情再用第一人稱再說一次。

[01:03:42] 例如說呢，我想一個更悲慘一點的故事。就是我們在數學系裡面或應用數學系裡面都有一個很有名的科目、必修科目叫高等微積分。高等微積分是其實是一個很溫馨的科目，因為常有三代同堂一起來上課的那種情況。通常當了都是很多人。那今年呢就是大放水，就只當了一個，那偏偏我是唯一那個被當的那一個。這個真的超級倒霉的，只有我需要重修。然後看到旁邊的那個看起來就混混的，居然也過了，就心情非常的不高興。

[01:04:23] 那我們就來看元英式思考會怎麼說。它說：「這平常當了很多人高等微積分，今年大放水只當了一個，這個獨特的機會、超級獨特的機會落到我的頭，這個真的是非常的 Lucky，因為重新學習變得更強大更厲害，專屬的重修，完全是 Lucky。」然後你可能會覺得這樣回答有點白痴，但是很多同學說看完以後心情還蠻好的，因為就覺得很白痴。

[01:04:53] 大家等一下我們就會試著一起寫寫看。但是你們作業麻煩大家改另外一個應用。我們再介紹幾個應用再回來認真的做。

[01:05:06] 這個看起來好像很實用。這是佛羅里達大學（University of Florida）金融系教授，他寫了一篇 Paper，他就用 GPT 預測股價。這個大家興奮了，感動了，這個真的開始呀，這個真的是有用處的。大家也可以寫一個。說一個好消息，這個如果等一下你看了佛羅里達大學金融系的某一位教授（的 Prompt）——還好我也沒有說這是誰——反正某一位教授他寫的 Prompt，你等下看完他的 Prompt 你就會發現，因為你現在就知道了，我們能做的就是下一個 Prompt 給它。

[01:05:43] 相信特別是有研究股票的同學一定可以寫得比這個還要更好。他下的方法是這樣：前面那個句子不要管它，那個是開始的時候流行的（Prompt 寫法），那個其實可以不要理它。尤其是我們自己寫的程式幹嘛要做這樣的事情？那重點就是說，他就說：「好，你就假裝你是一個財經專家」。其實你是一個財經專家就好，還假裝你是一個財經專家？然後如果今天你看到了下面的一家公司的股票，你覺得這一則新聞的標題——它會把新聞標題放進去，只有標題，只有一則新聞的標題——你覺得對這家公司的股票是利多的消息，你就說 Yes；你覺得是利空消息，你就答 No；如果你不知道，你就答 Unknown。

[01:06:49] 不知道有沒有同學相信這種回應出來的結論？但它就是真的這樣子寫的，然後他就發 Paper 就是這樣子。那時候還很有名，很多報導還說這個是不是股票分析師就要消失不見了。你看完了你也知道這不可能。你自己去寫的話，特別是有研究的同學，相信大家都會寫得更好，你會考慮得更周到一點，你也會更準確。

[01:07:28] 當然真的 ChatGPT 可以做很多事情，反正就只要把打前面說的那些話就可以。比方說呢，我們建議如果你在試驗的時候，最好可以找到一個可以跑你要用的那個語言模型的位置網址。比方說 OpenAI ChatGPT，你就去跟 ChatGPT 聊一聊天，就先試著去下這個 Prompt，它就可以當成 System Prompt 下去。

[01:07:50] 比方說，你就可以在這邊說：「你是一個臉書發文的小編」。開始的時候可以介紹自己，問要發什麼樣的文。然後以使用者回應中的 content 內容——這是一個小技巧，就是 content 這個完全是我們自己定義的，只要你覺得這個很少出現的，你就可以教它說我在 content 下面放的就是內容——下面放的就是我要指定的風格（Style）。因為我們每一篇 PO 文可能風格是不一樣的，我們現在可能是要澄清某一件事情，就不能在那邊嬉皮笑臉；但是我們現在要宣傳一些東西的時候，我們就可以寫得有趣一點。所以說這個樣子的臉書的小編就可以做這樣的事。

[01:08:33] 為什麼我會建議推薦大家這樣做？原因是因為你看完這個，你就知道它有沒有誤解你。那沒有誤會你，你就真的可以用把剛剛的那一段或是再稍微改一下，就當成我們的 System Prompt。所以回去的時候整個流程就是這樣子，你就先用那個——不管你在自己的電腦上跑還是用其他的方式去試驗——然後你就去先去試驗一下看看。

[01:08:55] 像 ChatGPT 真的是非常多話的一個機器人，我們剛才寫那麼小段，它就說：「哦，我是負責社群媒體內容創建的小編，我可以幫你做什麼什麼，你想發什麼樣內容就放在 content 裡面，什麼樣的風格就放在 Style 裡面」，然後還舉例說明這樣子。

[01:09:44] 那比方說我跟政大的陳宜秀老師一起開了一門課叫「設計思考人工智慧」，那我們想要宣傳給我們政大的同學來參加。所以稍微的列出來說這個課程大概是怎麼樣子的啦，要收的同學是比方說大三、大四或碩士班啊等等。然後風格當然因為要吸引人家嘛，所以要輕鬆幽默、吸引人的風格。然後它就會真的很像臉書小編寫出來的樣子。

[01:10:15] 它很會下 Emoji。事實上有一位之前我們有請一位老師來分享，他就說其實判斷是不是 AI 生成的，有一個很重要的重點：Emoji 下得很多，它十之八九其實是 AI 生出來的。那你為了要讓大家不知道誰生出來，你可能就要把這些東西改掉。不管怎麼樣，所以它寫的就真的是在一個臉書上宣傳的樣子。

[01:10:52] 然後我們再舉一個這個例子。就是我們想要我們的 ChatGPT 呢，或者是我們的大型模型，就假裝是一個非常的誠懇專業的選系諮商師，就要給高中生去做選系的推薦。高中生就會跟它聊天說他的興趣是什麼啦、然後未來想要念什麼啦等等，然後它就要推薦科系。但是因為我們是應用數學系的選系諮商師，所以唯一推薦的科系就是應用數學系。

[01:11:26] 我們就是跟它講說：你要對高中同學做一對一的選系諮商，然後就想辦法先問同學的升學相關的資訊，包括以後想念什麼、想做什麼。但是最後推薦科系一定是應用數學系，還說理由。然後我們就說那就要選「選系諮商師」的角色來和同學對談。

[01:11:56] 所以為什麼會推薦大家一定要先在那個一般的那種對話型的版本先去跟它對話一下？因為第一個，就是它的第一次的回應，你會知道它有沒有懂你的意思。你會發現它後面真的相當好，說：「談一談這個未來學習跟職涯規劃的想法，然後對未來有什麼期望啦、有沒有特別感興趣的學科、夢中的職業是什麼啊」這樣子。這個說得非常好。但前面它說了一個非常不好的事情，它自爆身分說：「我是應用數學系的推廣諮商」。那後面它說的話人家同學怎麼會相信呢？

[01:12:37] 所以說這樣不行，所以我們後來改掉了一個完美版本，就它完全不會暴露自己的身分。所以你就會下在 System Prompt，你會一直要改。這是我們的作業要做的事情，就是其實一直在改 System Prompt。

[01:12:55] 好了，然後就跟他講說：「我對廣告很有興趣，不知道該學什麼、選什麼樣的科系」。然後它就跟你講說：「哦，這個很棒的興趣啊，廣告學不僅是關注那個創意表達、視覺設計」。然後你就會發現重點來了：「同時也越來越強調數據分析與市場研究的能力」。所以大家就知道它後面想要接到應用數學系。果然它就接到應用數學系了。

[01:13:19] 然後它後面其實它說得非常誠懇，你會覺得它真的很誠心誠意的在為你推薦應用數學系。因為它就會建議你在學應用數學系的科目的同時，也要去修一些廣告相關的課程啊，還有要參加那個相關的實習啊。請看這個說得相當的好，這個我都快要相信了。然後當然同學可能很震驚啦，他就說：「我真的沒有想過可以選數學系」。它還跟他講說：「這是常見的情況，大家在選系常常只會考慮跟自己興趣最直接相關的科系，忽略那些能夠提供強大技能支持、多個行業都有廣泛應用的學科」。再一次它就想要說應用數學是你唯一最好的選擇。

[01:14:07] 所以就是今天我們要做目標就是這樣子，就是要打造一個 AI 的應用。那我們要用的範例就是「元英式思考產生器」。但是大家會發現說如果你要寫包括後面的幾個例子，其實你應該都可以做。可以切下來。我後面都是要寫程式，然後那個就可以直接直接做。

[01:14:57] 所以說呢，那我們今天的作業就是希望大家去想一個有趣的例子，然後去做做看。那我們就進到這一個程式（Colab）。

[01:15:15] 好，網址是 bit.ly/AI04（大寫）。跟之前一樣，這邊有一個 "Open in Colab"，然後我們就在 Colab 裡面打開。進入那個標準程序，就是在「檔案」這邊，再強調一次，你修這門課完全只學到這一個（操作），你在外面也跟人家很多人不一樣。就正確的打開這個 Colab，然後變成你自己（的檔案），就一定要選在「檔案」裡面選「在雲端硬碟中儲存副本」。

[01:16:11] 請大家記得所有的部分，再一次，你就是要改造成你的作業。意思是呢，你其實可能不是要打造「元英式思考產生器」，所以你應該那個標題就不是這一個。

[01:16:40] 我們順便在這裡面先為大家介紹一件事情。就在這邊有一個「連線」，我也可以在這個時候就偷偷的先連線。就是按這個連線，它就會正在連線。下面呢有幾個介紹，就是我們要去等一下會使用的方法其實是呼叫 API 的方法。

[01:17:04] 呼叫 API 的時候，我們就會發現說我可以用呼叫程式的方法，去讓我們指定的語言模型去回應我們送出的 Prompt，它就會去做回應。那因為我們這是第一次，所以我們用最簡潔、最單純的方式來做這件事情。那你需要有 API 的金鑰。

[01:17:28] 那 API 的金鑰呢，我們找得非常的辛苦，因為大部分的 API 其實都要錢。那像 OpenAI 其實也是要錢的。就是你需要去付一些保護費給它。大部分的申請方式其實差不多是一樣的，所以我們就不仔細的解釋。我們最主要要解釋下面的 Groq 這一個。

[01:17:58] 但是為什麼在 OpenAI 停留特別久？因為如果大家想要使用 OpenAI 的話，就記得上這邊進入到 OpenAI，然後就登錄進去。跟本來的 ChatGPT 那個網頁是一樣的，你可以用 Google 的帳號就可以去登錄。那要提醒的是它跟 ChatGPT 那邊一點關係都沒有。即使你在那邊付了相當高級的 20 美金版本一個月給那邊的 ChatGPT，在這邊的 API 還是要付錢的。還好這邊付錢如果有我們的作業的需求，可能你付個 5 美金就不錯了，就差不多是足夠的好。

[01:18:38] 所以願意要使用（OpenAI）因為它的好處就是你真的可以使用一些比較厲害的模型，所以你在寫的時候也許會比較有成就感。但是因為唯一最困難的動作就是它要刷卡，所以不方便刷卡的同學可能就沒有辦法做這樣的事情。

[01:18:57] 所以我們下面又推薦了另外一個就是 Groq 這邊。Groq 呢，因為它可以免費的使用。好，那我一起登進去給大家看。我已經登錄了，它其實完全不需要（付費），它就可以在這邊生成 API Key。那 Groq 跟那個 ChatGPT 一樣，還要證明我是人。

[01:19:31] 然後它就會在這邊產生的這邊很複雜的 API 這樣子。它現在比較親切了。然後呢，我們請大家做一件事情，而且這件事情只要做這一次就可以。就是你會發現在這個在 Colab 這邊有一個「金鑰」這邊，你就按下去。我已經新增很多了，如果還沒有的同學，大家還第一次新增嘛，所以你像比方說我們剛剛新要的一個 Groq 的金鑰，我就在這邊新增密鑰。這邊就打 GROQ_API_KEY。

[01:20:11] 請大家一定要用一樣的命名方式，一定要用一樣的命名方式存這些金鑰。那就把剛剛的金鑰存在後面。前面我已經存過了，所以我就不存了。這邊就是要把剛剛的金鑰把它給存進去，然後就存起來。這樣就可以了。

[01:20:48] 但是因為其實我前面已經有一個 Groq，所以我就決定不要存了，就把它刪了。因為它也說無法存，沒錯啊，因為有前面有同樣名字。所以請大家都取一樣的名字。那比方說 OpenAI 就請大家就是 OPENAI_API_KEY，然後 API 是大寫。然後你用了其他的，比方 Gemini 啦一推啦，我們在投影片上有（說明）。

[01:21:14] 請大家都用一樣的（名稱），因為助教也會用一樣的。所以你今天呢，你跑的程式不管你用哪一個，那助教在執行你的程式的時候就會去跑，就會用他自己的金鑰。所以大家不用擔心，他不會佔到（你的額度）。即使你用 OpenAI 它也不會佔到你的錢。這樣可以嗎？清楚哦。

[01:21:56] 好，那為什麼會抓到那個？就是每一個人在使用的時候為什麼都會抓到那個相對應的正確的金鑰？因為我們都取一樣的名字，就這樣子。所以你不用擔心它不會抓到。它沒有辦法跨過這麼多的屏障然後找到你的金鑰，不會。他會執行的時候就會用自己助教這邊的或是老師這邊的金鑰去執行。或是你寫得很好，有些同學有興趣要執行，就會用到同學自己的、就執行的那位同學的自己的金鑰。

[01:22:29] 好了，我們要用的一個是叫做 aisuite。aisuite 是吳恩達老師他做的一個很方便的 AI 的套件。就是它很方便寫一些、就是要去呼叫語言模型，其實非常的方便。大部分的情景之下，那個出現一些可怕的黑體字、黑黑的那些，它只是說它現在在做什麼事情，我們通常不用管它。事實上一般來說這個出現這種紅色的字，我們應該要管它，但是因為我們之前已經發現，其實我們就沒有要管它也可以正確的執行，所以我們就不管他了。這不是一個好習慣啊，你也可以問 ChatGPT 出現這個怎麼辦。好，所以我們就把 aisuite import 進來。

[01:23:24] 再來就重頭戲了，再來就是要讀取我們的金鑰的部分。那我們金鑰的部分呢，你就會發現說在這裡，這裡我們就是用 Groq。那你可去上 Groq 的網站去查，除了這一個 Llama 3.3 70B，其實還蠻（新的）。你可以上網去查還有什麼模型可以使用。

[01:23:55] 那比方說我今天想要使用 OpenAI 的話，我就需要把它給刪掉（註解符號）。前面的井字符號刪掉。那當然大家一定會覺得前面的井字符號刪掉，看起來剛剛那個動作真的有夠（慢）。所以呢，它就準備了一個快捷鍵，就是按住 Ctrl 跟 /（斜線）。其實我不知道 Windows 按什麼，助教幫忙試一下好了。Ctrl 跟 Alt 嗎？然後按那個斜線，就本來的那個註解就會刪掉。然後再選起來，再按一次，它又會加上註解。所以就是 Ctrl 加 /。

[01:25:22] 總之不行的話，你就一一刪掉就好。那我們因為預設因為這個是免費的，所以我們預設就用這個版本（Groq）。但是你如果今天是用 OpenAI 的 GPT 模型的話，你就可以用 OpenAI 的。但是那個需要付的一些錢你才可以跑得動，不然就很有趣，你自己的電腦跑不動，但是助教的跑動，因為助教有付費。這個比較奇怪啦，因為你看不到你自己出來的結果，那個其實你不太能確定說你自己執行的樣子是什麼。所以請大家如果要用 ChatGPT OpenAI 的話，那就是請在 OpenAI 記得要儲值一些錢。如果是用 Groq 的話，就不用管它了，它就是可以免費。

[01:26:19] 好，那我們就去執行它。然後這個時候它會說你的那個剛剛沒有打開那個密鑰（存取權限），那這個時候就說要打開。當然就讓它打開，然後它就會讀好了。

[01:26:30] 然後再一次，就是在所有的對話機器人裡面，它的主要的角色只有三種。事實上兩種，一個是使用者（User）跟大型模型本身（Assistant）。但是還有一個 System 是系統的 Prompt，System Prompt 就是把它人設做好。那看起來它整個的樣貌就是這個過去的對話記錄，它整個樣貌就會看起來這樣子。看起來很可怕的樣子。

[01:27:02] 就開始第一次看的同學比較不太熟悉程式語言，可能會覺得有點可怕。但是你勇敢的去看它，你就會發現它只是把每一個先說好這個角色是什麼，然後它裡面到底寫了什麼東西或說了什麼話。所以就是很容易看懂啊，你勇敢的耐著性子去看，你就會看懂它到底什麼意思。

[01:27:25] 那我們寫一個很簡單的回應。這回應的時候呢，就是一樣就再打開一個語言模型的時候，因為我們是在那個 aisuite 裡面，我們剛剛已經縮寫成 ai，所以要打開一個 ai.Client()，也就是意思就是說打開一個對話機器人。打開一個對話機器人，然後呢，這個對話機器人，我們等一下後面才會把它設定說我們要使用的那個模型是（哪一個）。

[01:27:57] 就是在這個 client.chat.completions.create 這邊。這一段看起來有點複雜，但基本上就是 OpenAI 的 API 它就是這麼樣做的。我們基本上可以不用太管它到底在做什麼，就這邊就是想辦法要把那個它的回應把它抓回來。那後面會告訴它我想要呼叫哪一個模型，我過去的歷史對話記錄是這個樣子。

[01:28:22] 我們會執行一次簡單的樣貌給大家看。那這邊都是我們在做一些試驗的，所以從現在這個後面之後開始的一小段呢，你其實可以把它刪掉。你會發現說這個跟我們剛剛的「元英式思考」的那個寫法有一點點不一樣。因為本來的元英式思考我們是用 ChatGPT 做，然後我們發現換了一個模型之後其實沒有那麼好，而且它本來 GPT 會幫我們加上（Emoji），它（其他模型）不太會加。所以有些你就說「可以適度的加上（Emoji）」，你就會發現這個就是完全根據我們的修改。

[01:29:04] 然後我順便介紹一下 system_prompt 這邊的為什麼是三個雙引號。因為呢三個雙引號在 Python 裡面就這個字串我是可以按 Enter 的。在一般的程式語言那個不可，就是一個字串你就要從頭到尾一路的打下去，你不可以這樣子分好幾段。那 Python 是可以的，就是變成三個引號，前後都是三個引號。

[01:29:28] 然後我們試用一下下。就剛剛就 System 下好，其實基本上就做好了。那我們傳過去的時候就要告訴它 System Prompt 是這樣，就你自己的、你這個 AI 人設是這樣。然後我們使用者會說一句話，比方說：「今天的咖啡灑到電腦上」。我們來看看這個這麼倒霉的事情，它會怎麼樣回應。然後我們就要把那個回應把它印出來。

[01:29:50] 所以它就會跟我們講說：「哈，這好笑嗎？今天生遇見超級幸運的是咖啡被電腦灑到，但事實上是個轉機，我就有我就知道要買一台全新的電腦」。這樣子，好好就這樣。反正你就看它說的覺得滿不滿意。因為大家會做的不一樣的應用，你一定要看它做的回應的是不是真跟你想像中間的它應該有的回應很接近。如果不是的話，你就要再去做一些修改。

[01:30:22] 那這邊我們只是範例說如果換了一個語言模型，一樣還是從 Groq 來的，就是換一個語言模型，是換成那個 Google 的 Gemma 2。其實應該我們本來有 3，但是它可能沒有 3，大家再去查 3 線上有沒有已經可以使用了。

[01:30:43] 然後再是一樣的，一樣的情景，就也是剛剛咖啡灑到電腦上，然後 System Prompt 一樣的，然後我們來看它的回應的方式。誒，你看發現說這個 Gemma 2 其實小很多，但是它其實感覺好像回應的也還不錯。那你就可以選擇說在這個例如 Groq 上面的或是 OpenAI 的那個 ChatGPT 裡面的系列裡面，你可以選擇看看你想要選哪樣的、哪樣的語言模型去做回應都可以。那就記得未來要改的地方你要改好。

[01:31:21] 那一樣就在這樣的情景，我們就最後，所以我再說一次，這邊只是讓你自己試驗的。所以其實你回去了之後，照說呢，除了這個 reply 這個函式之外呢，其實下面基本上這個 System Prompt 這個全部都可以刪掉了。就是你的作業這一區都可以刪掉了，因為這個只是我們自己在試驗啊。

[01:31:47] 真正的重點在第三節。那第三節這邊呢，我們就是要把 Gradio 圖（介面）進來，就是我們要把它變成圖形介面。這從第一次的作業我們其實就做這件事情了。然後你需要改的地方最重要、最重要改的地方就是這裡的 System Prompt。就是大家在外面說的時候，如果術語就 System Prompt，就是你要幫它做 System 的設定，就是人設。

[01:32:18] 那個真正的術語就是改 System Prompt。所以你會發現在很多的應用其實最主要最重要的一個環節就是改 System Prompt。然後設定你要的模型。這個我們又把它設回了這個，我有點把它想換成 2。好，我決定要換了。我們再一次的表演一下下這要換的時候。因為剛剛看起來感覺好像它做得比較好，它做得還不錯，它又比較小。

[01:32:55] 所以大家可以自己試驗啊，就試試看說不同語言模型出來的結果怎麼樣樣子。然後你會發現有一些語言模型怎麼就在現階段，你怎麼調你都調得不滿意，你再換一個模型說不定就可以調得好。

[01:33:10] 然後所以我們寫一個簡單的程式，因為只要有函式它就可以互動。那這個簡單的函式就是我把我告訴它說那個剛剛我們的 System Prompt 是什麼，然後我們使用者真正要輸入說的話是什麼。然後我們要說它選用的 Provider，比方說這個我們的 Provider 是那個指這個 OpenAI 或是 Groq 這種類（平台）。不是原來模型的是誰做的，是我們現在用的那個網路的服務、API 的服務。好，那這邊是用 Groq，然後 Model 就是前面的這一個 Gemma 2。然後我們就要回傳回應。

[01:33:55] 然後這個是真正的小程式的（介面設定）。那個大家其實應該看得懂。就是 title 這邊你一定要是要改的，因為你我不知道大家的應用是什麼。然後呢，這個 description 這邊就去解說。那解說有一個小技巧，就是解說的時候你可以讓這一個——就是你自己剛剛我們有推薦，希望大家都可以先在、先在那個不管是如果開源的模型就是在自己的電腦上先試跑一次，或者是說呢你可以先在這個如果是 OpenAI 的 ChatGPT 你可以再直接在網頁上跑一次。你跑完了以後，事實上 Groq 有做 Playground，就是你也可以在 Groq 上面試跑一下。

[01:34:43] 那試跑的時候你就會發現說剛剛我們下 System Prompt 之後說「請介紹自己」的時候，它就會開始介紹自己。那介紹自己的時候呢，其實你就可以把這一段拿來放在這裡。那很明顯的就是那個 Gradio 是支援 Markdown 的，所以你又會發現 Markdown 語法。這個如果在 Google 在我們的 Colab 裡面有試用過 Markdown 的話，你就可以發現這邊其實直接可以用 Markdown 的語法，把那個整個的、整個的排版做得更好一點點。

[01:35:12] 好，然後再來出來的時候呢，就是那個 label 就是告訴它說這邊要輸入什麼事情。那就是「今天要發生的事情」。那它會有舉例子，「今天下大雨忘了帶傘」。我決定要把這個 Copy 下來，因為等一下我就要偷偷的用這一個。它其實只是舉例啦。然後呢，再來呢就是有一個按鈕，就是「Lucky Vicky 魔法」。這當然大家一定會改一個名字。然後這個這麼噁心的名字其實好像是 ChatGPT 想的吧。好，然後 Output 的地方就是「元英式貼文」。好，就這樣子。

[01:35:54] 然後我們就開始讓它上架，執行它，然後讓它上架。那這個時候就會出現了一個大家熟悉的準備要截圖的連結。好，就這個連結。那願意的話也可以分享給親朋好友、爸爸媽媽看一下，說你現在實在太厲害了，這個已經會寫自己的對話機器人。

[01:36:17] 所以就會出現這樣的情景。所以剛剛我們解釋的，你就會發現這個排版就是這樣。你也可以對照一下這個排版，你就可以回去在改的時候，你就可以把改成你的真實的情況。

[01:36:30] 好，那我們你就會發現這個很有趣，它這邊還會舉例子。但舉例子它不能直接使用，所以我剛剛它偷偷的 Copy 了，所以我就可以直接使用。好，然後就按下這個按鈕。

[01:36:50] 嗯，它有在認真的執行嗎？我偷偷的回去看一下哦。哦，對啊，沒有。沒有什麼特別問題。可是它為什麼那麼久？哎，它真的不執行出來哦。有有來有來，誤會誤會誤會。它只是剛剛就這個排版不知道為什麼會畫面我看不到。

[01:37:24] 好，就是「今天出門就下大雨，差點哭出來。幸好就可以名正言順去買一杯美味熱巧克力」。為什麼？下雨才可以。好好，然後反正反正就會這樣子。然後你覺得它的回應不是那麼好的話，那個你當然可以重新按一次，它就重新生成。

[01:37:44] 你會發現其實這個 Groq 相當非常快，它的速度很快，這是它的特點。事實上 Groq 它本來就是要做硬體的一家公司，而且它特別特別在某種程度是特別針對語言模型、生成式 AI，所以它那個非常的快速。但它比較不能去訓練它，它是人家做好的模型在它上面。好，可以嗎？不知道大家有沒有什麼問題？就關於我們今天的作業。

[01:38:24] 好，我要再一次的廣告一下。就是我們大家如果到了我們的這個 NTU COOL 裡面，可以看到我們助教的排班的時間。然後在上面有一個 Gather 的連接。就是如果不是政大的同學，你想要找助教問題的話或是討論的話，就歡迎用那個 Gather 連接。我們在助教的 Office Hour 的時間，那些 Gather 的連接都會打開，你可以現場直接詢問。

[01:38:55] 現在請問有沒有同學問？有沒有同學？不是，我是說連線有沒有人？有嗎？不是啦，是不是在 Office 的時間啊？有哦。好，你怎麼那麼緊張的站起來哦。好，剛剛看起來好像還不是很多同學。有有那個利用這個機會，你們會發現時間很多啊，所以你可以找那個你時間比較方便的，然後就去跟助教討討論一下下。就歡迎大家可以多利用這個服務，就是那個會讓大家學習上面會更輕鬆一些。

[01:39:41] 好，那我們先今天現在到這邊，讓我們先休息十分鐘。等一下會進行今天的 TA 時間。

[01:39:50] （TA 時間開始） 好，那就大家如果填完的話，我們就開始今天的助教課。那今天是 10 月 7 號的助教課，然後我是國貿所碩二的陳（助教）。

[01:40:02] 那今天就是我們助教課會分成三個部分。那第一個部分是會講一下我們上週就是第五週的作業示範。那這邊會講一下就是作業可能它的規則是什麼，然後你可以怎麼寫。然後到最後可以提供一份就是我自己做的，然後讓大家參考說這一次的作業可以怎麼寫。

[01:40:23] 那第二個是就是一個北捷的 AI 客服的個案。然後在這個個案中，不知道大家有沒有聽過北捷 AI 客服的這個個案。然後這一次就是會講一下他這個事件是怎麼發生，然後還有它後續可以怎麼改善。那最後也會有一個就是 System Prompt 的介紹。那第三個是就是想跟大家分享一個 AI 工具，那這個工具叫做 Fellow。那相信應該有些人有聽過。那今天我們介紹這個工具主要會著重在就是它簡報的這個功能。

[01:41:00] 好，那我們就進到第一個部分。第一個部分是要介紹就是我們第五週的作業。那這一份作業呢，就是它的題目，就是希望同學可以去探索，並且應用就是一個提示工程（Prompt Engineering）的技巧。所以大家可以到網路上去找一些 Prompt Engineering 的相關內容。

[01:41:16] 那一開始就是希望大家可以，第一步的話應該說希望大家可以上網搜索，然後去找到一個 LLM 的提示工程的技巧。然後同時可以去想一個就是比較有趣或是實用，或跟自己自身經驗相關的例子去做說明。

[01:41:31] 那這個作業主要需要包含三個部分。第一個部分是就是技巧介紹的部分。就是希望大家可以在作業中簡單的說明一下這個技巧是什麼。就是你在你找到這個技巧之後，你可以去說明它要怎麼應用，或是它舉個例子，讓就是助教在看的時候可以了解你這個技巧的內容是什麼。那同時它的來源可以是一些文章、影片或是論壇。像我等下後面會做一個範例的部分，會是以文章來做示範。那在作業中你有一個必須要注意的是，你需要附上就是影片或是文章或論壇的來源出處。

[01:42:14] 好，那第二件事情就第二個部分是你想要去做兩件事的連結。那這什麼意思？就是你要去解釋你剛剛找到的這個技巧，它是如何幫助去幫助 AI 提供足夠多的正確資訊，以及你這個技巧是怎麼清楚告訴你的 LLM 要做什麼事情。那這個現在看起來有點抽象，讓我們後面會用一些實際例子來做介紹。

[01:42:41] 那第三個是應用範例的部分。就是希望大家可以就是透過結合一些自身的經驗，像是你的課業、你的日常生活或是你的興趣相關，那去設計一個有趣或是比較實用的 Prompt，然後同時融合你剛剛你原本在網路上找那個技巧，就是結合這兩件事情，然後去看它做出來的回覆以及結果會是怎麼樣。

[01:43:08] 好，那接下來是繳交的內容。繳交的內容的部分你需要就是包含重點的截圖，或是你可以附上 PDF 的檔案。同時你在這一份就是檔案裡面，你要去寫一下你這一份作業的重點說明。就是剛像剛有提到就是你的技巧是什麼，然後你可能要稍微講述一下你這個技巧的解釋，以及可能以一些範例的方式來做講解。那同時你也會套用到你結合你剛剛就是輸入的 Prompt，它回覆的內容跟結果，然後就是呈現出來，讓助教可以就是清楚的明白你這個技巧怎麼應用，然後它的差異是什麼。

[01:43:48] 好，那評分技巧的部分呢。就是第一個是如果你在作業中有附上你的技巧來源，就是有附上你的連結網址或出處的話，你就可以得到一到兩分。那如果你有就是連接到兩件事，就是你有在你的作業中清楚的說明你這個技巧是如何幫助就是 AI 知道正確的資訊或是清楚的指引這兩件事情，你就可以得到到二到五分。

[01:44:17] 那第三個是你的 Prompt 的設計。就是因為我們後面第三個部分是需要實際應用，所以如果你有就是提出你自己的 Prompts 然後還有你的技巧，就是結合得出來的結果，你就可以得到六到八分。那如果你的就是 Prompt 的設計是蠻有趣或很有創意或實用，就是不是過於空泛的話，那你這個作業就可以得到九到 10 分。所以其實這一份作業它沒有到非常難，而且我覺得可以拿是蠻容易拿高分的。所以如果大家就是用心做這份功課的話，就大概可以拿到九到 10 分。

[01:44:56] 好，那接下來就給大家看一下就是作業範例。那這一份作業範例是我自己做的，那大家可以，我就跟大家介紹一下我大概是怎麼做的。

[01:45:07] 好，那首先因為我們剛剛有提到，就是在簡報這邊我們有提到說這份作業需要包含三個部分：一個是技巧的介紹，一個是兩件式的連接，然後第三個是應用的範例。好，那所以我是在這個部分我就直接照它這個架構去做。

[01:45:24] 那第一個部分是技巧介紹的部分。在技巧介紹這個部分，我參考了兩篇文章。那第一篇文章的標題就是《Prompt Engineering 入門篇：如何精準對 AI 下指令》。然後就這個標題。那在這一個文章中，它就有提到了三個關鍵的技巧，那分別是定義角色、定義目標、還有定義產出。好，那我就截取了這三個技巧。

[01:45:46] 那此外就是我還有去找的第二篇文章就是這個，《Prompt Engineering 是什麼？提示工程技巧指南》。那從這個文章中，因為它其實內容跟上一篇、就是我第一篇找到的文章，它有些內容跟技巧是有點重複的，所以我在這一篇中我只有截取出我自己覺得比較差異化、比較特別的一個技巧，就是他說可以提供參考的文本給 AI。好，那就是我現在就是截取出了這四個技巧。

[01:46:16] 那在作業中我就必須去講解一下這四個技巧分別是什麼，以及這些技巧可能要怎麼運作。那因為這四個技巧嘛：定義角色、定義目標、定義產出、還有提供參考文本。所以在這邊我就有去再進一步去講解每一個的技巧的內容是什麼。

[01:46:40] 像假設第一個就是「定義角色」，就是我可以指定 AI 在對話中去扮演一個身分或是一個角色。那舉例來說就是我可以要求 AI 去扮演就是英翻中的翻譯員，或者是一個很有經驗然後專業的財務顧問，或是小學三年級的數學老師。那我設定角色的目的其實就是讓 AI 以一個對應的口氣或是知識範疇或是它的邏輯思維去做回應，那縮小它回覆就是的方向就不會太分散。

[01:47:10] 那第二個的話這樣是「定義目標」。那我就去講說它就是我希望它就是明確告訴 AI 要完成什麼樣的任務，以及這個任務它的最終目的是什麼。那以舉例來說的話，就是可以告訴它：我現在要把這一篇新聞翻譯成中文，然後讓高中生可以輕易的理解；或者說就是告訴它是要去協助整理一份三分鐘的演講稿，那用來說明 5G 的概念。那這個做法就可以讓 AI 它就能夠清楚的聚焦在任務範圍內的回答，就避免去生成一些與主題無關或是過度抽象的內容。

[01:47:55] 好，那第三個技巧是就是「定義產出」。那這個部分就是去規範 AI 它生成內容的形式跟格式，就包含像是字數限制、格式的結構或是風格語氣等。那這邊舉例就是我們可以告訴它需要把它的回覆控制在 500 字以內，那分成三個段落，那每個段落有小標題；或是可以告訴它我希望它的口氣是以輕鬆幽默的口吻，然後以條列式的方式呈現等的。那這個就是告訴我產出來的結果的格式是要怎麼樣的，然後讓它傳出來的內容是符合你的需求跟預期的。

[01:48:32] 好，那最後一個是「提供參考文本」的部分。那這個是就是當因為問題就是涉及一些比較專業或是冷門的領域的時候，AI 可能會根據它下（一個字）——因為老師上課有提到它是預測它下一個字然後去回答——所以在一些比較冷門的領域，AI 可能它的內容或答案會比較不符合預期。那這個時候你就可以透過就是提供參考文本或文件的方式去降低錯誤率。

[01:48:59] 好，那這個大概就是第一部分你在技巧介紹的部分需要涵蓋的內容。那還有一個提醒是就是剛好提到你必須要把你的技巧來源附上，像我這邊是參考兩篇文章，所以我就把就是連結附在下面這邊。

[01:49:16] 好，那接下來是第二個部分，就是兩件式的連接。就你必須去講說你剛剛找到的這個技巧，它是如何就是「提供足夠多的正確資訊」，以及它如何「清楚告訴 LLM 需要做什麼」。

[01:49:32] 那像以我的例子來說好了，就是我前三個技巧是定義角色、定義目標、定義產出，所以我這三個技巧它其實就是在「清楚的告訴 LLM 要做什麼」。所以在這邊我就可去對這一部分做解釋。那因為其實我找了這個技巧跟舉了這個案列是相對比較沒有那麼複雜，就是它比較直觀，所以在解釋上就是大家可能現在也蠻好理解。

[01:50:07] 那另外就是我剛剛還有就是另外一個技巧是提供參考文本，那這個部分其實就是在「提供足夠多的正確資訊」。那我也由在就是兩件事的連接這個部分去做解釋。

[01:50:18] 好，那第三個部分就是「實際應用」。那實際應用這邊就是希望大家可以透過自身的經歷啊，或是你參考你自己的興趣，然後去結合你剛剛提到那兩、你剛剛提到的一些技巧，然後去看不同輸入、不同 Prompts 的內容，它產出的結果會有什麼不一樣。

[01:50:41] 那像在這邊的話，我自己是套用我自己自身的經歷，因為我是國貿，然後我是主要是修「行銷管理」這個部分。所以我現在就是假設一個情境是：我今天是一個助教，然後我要去上「策略行銷」這堂課。那我必須告訴學生邱志聖教授提出的「4C 架構」是什麼意思。那我希望就是我心中、我現在希望 ChatGPT 幫我產出的是一份講稿。

[01:51:11] 好，那在這邊我就套用了兩種方式。一個是沒有套用 Prompt Engineering 的技巧產出的結果，然後另外一種是去看說我套用 Prompt Engineering 的技巧之後，它得出的結果會是什麼。

[01:51:25] 好，那相似在第一個部分的話，就是第一種是沒有套用 Prompt Engineering 的技巧，我的輸入的 Prompt 就是直接告訴他說：「請你幫我整理就是邱志聖提出的 4C 架構」。好，那我得到的結果就這個圖片中呈現的樣子。

[01:51:42] 那大家可以看到它給我的結果就是這四個。第一個是它的 4C 是 Customer Solution，第二個是 Customer Cost，第三個是 Convenience，第四個是 Communication。那乍看之下它確實是一個 4C 的架構，但是就是如果有修過就是這堂課或是看過邱志聖教授提出這個 4C 架構的人，就會知道說他其實這個提出的內容跟老師定義的完全不一樣。對，就是它是有點（錯誤）。等下我們會看到正確的版本是長這樣。但在這邊的話就是我們可以看到說當你今天就是 Prompt 下的不夠明確，你得出來的結果就會跟你預期不太一樣。那同時如果它是涉及到一些比較冷門的領域的話，就如果他沒有一個參考文本，它今天生成出來的答案可能也會就是跟預期的不太一樣。

[01:52:34] 好，那接下來我們就看一下有套用 Prompt Engineering 的技巧。那這邊輸入的 Prompt 就是這一段新的。那它現在就是有結合我剛剛在前面提到四個技巧。像第一個技巧的話是「定義角色」，那我就有告訴他說：「你現在是政治大學的研究生，那你是這一堂課的助教」。所以這一段就會是定義角色。

[01:53:03] 那接下來第二個技巧是「定義目標」。那你看就是在這邊的話，我們就可以把我們想要達成的目標告訴他。就是「現在你需要為學生上課，那你的目標是要讓台下的學生可以了解教授提出的 4C 架構的概念，那你可透過實際舉案例的方式讓他們更容易理解」。所以這個部分就會是目標的部分。

[01:53:25] 那第三個技巧就是「定義產出」。那這邊我就有告訴他說：「你現在要整理一份含有概念的概念介紹以及實際案例並存的講稿，那它的講述時間大概是抓在三分鐘左右，那它的口氣是需要兼具專業跟幽默的態度」。就這一部分就會是定義產出，就是你清楚的告訴他你要的是什麼，然後還有它的一些格式，你的需求是什麼。

[01:53:50] 那最後一個就是我剛剛還有提到最後一個技巧是「提供參考文本」。那在這邊的話我就有告訴他，那「我會提供他一個網頁連結作為參考，那它可以從這個連結中的內容去整理出我要的講稿」。那這邊有一個值得提的是，就是因為在原本的語言模型中，可能它是沒有辦法去讀網頁的連結的。所以如果是你用原本的語言模型，你可能就是要把網頁連結上面的文字就是複製下來存成檔案再提供給他，然後告訴你的語言模型你要從你的檔案中去讀裡面的內容。但因為就是現在它有聯網的功能，它可以上網搜尋，也可以讀連結，所以在這邊我是直接請它就是去讀這個連結裡面的內容。

[01:54:43] 好，那大家就可以看到就是這個 Prompt 它得出來的結果就跟剛剛那一個完全不一樣。就是首先是在他資訊的正確性上，就是他現在的 4C 就是邱教授真的提出來的 4C 架構。那同時它的編排方式或是它的格式也會是以講稿的方式。那它同時也有符合就是我們剛剛提到可能講述時間大概要在三分鐘左右，以及就是它的口氣是要專業跟幽默兼具的這樣。

[01:55:10] 對，所以大家就可以看到說輸入 Prompt 的詳細值、詳細內容就可以導出非常不一樣的結果。那在作業中你就可以透過就是比較的方式去呈現你剛剛那些技巧得出來的結果差異在哪。那在這邊作業最後這邊我有做一個小結論，那就是大家也可以在作業中就是附上這個部分，讓助教更快可以了解你這兩個的差異在哪。

[01:55:41] 那當然就是也不一定要就是完全跟我的示範的作業一樣，就你不一定是要以這種兩個比較的方式，就是如果你有其他的呈現方式的話，也是非常歡迎大家的自由發揮。好，那就是如果作業還有任何其他的相關問題的話，就是剛也有提到可以在 Office Hour 的時候去找各個助教去做討論。好，那作業的部分我們先到這邊。

[01:56:08] 那接下來下一個的話就是想跟大家分享就是北捷 AI 客服的這個案例。那這個案例其實蠻實際的，而且可能大家都有可能在新聞有看過。那他其實就是台北捷運 AI 客服被濫用的一個個案。那我們會在這一次的助教課中會講解一下就是北捷的客服發生了什麼事情，以及它後續是怎麼補救。那其中就是最後我們會提供給大家一段可以複用的客服的 System Prompt 給大家做參考。

[01:56:43] 那可以先回顧一下這個事件的脈絡。它其實就是北捷出了一個 AI 的客服，那他的服務初衷其實很單純，就是導入 AI 的智慧客服。那它主要的功能就是去協助乘客查票價，然後還有一些路線規劃，或者是尋找遺失物等的資訊。那其實就是把很常見的 FAQ 自動化，然後去提升查詢的效率，減輕人工負擔。

[01:57:09] 那這件事的出發點它其實是一件好事。只是問題出現是在民眾發現就是語言模型背後有漏洞，就是它可以透過一些指令去問和捷運無關的內容。像是我們可以看到那時候就是大家可以掃一下右上角這個中間這個 QR code，就是那是當時那個社群連結。就是因為這一篇文，然後就大家開始去問北捷 AI 的客服一些無關緊要的問題。

[01:57:50] 好，大家這樣看得到嗎？好，反正就是那時候就有人去問他就是 C++ 啦、RAM 的東西，那他還真的就是有回答一些程式碼相關的內容。然後就是因為這篇文就飄到 Threads 上面，然後大家就有點跟著去問一些無關緊要的問題。

[01:58:11] 像我自己看到有一個比較好笑的是有人問他就是「當你在搭捷運的時候就是光速會被改變」這樣，然後北捷的 AI 客服也是就真的有還感覺蠻認真的在回他這樣。但就是下面就是很多人就是有去問他一些真的很不相關的問題。大家如果有剛有找到 QR code 的話或是這邊大家可以去看一下下面的那些留言。

[01:58:40] 那就是出現了這樣的濫用狀況，就是 AI 他真的去回了就是程式碼範例或是其他就是超出服務範疇的內容。那這樣的狀況它雖然其實不一定會說是傷害到人類或什麼，但它就是導致了公共資源被導向了非預期的用途。那這樣就是這樣的現象會就是浪費社會資源，以及就是在未來對旅客來說也會對這個客服的專業性產生疑慮。那他對企業形象、品牌形象固然也不是一件好事。

[01:59:12] 那所以總結一句話來說的話，就是這一個事件就是北捷在 AI 的客服的設定上不夠全面，然後使它的能力邊界被突破這樣。好，那其實就是使用 AI 作為客服這件事情，它對公司來說是一件可以節省成本，然後增加效率的舉措。所以它的出發點就大家都知道它是以良善的。

[01:59:35] 所以在這個個案中，與其說 AI 不適合當客服，就應該說他更應該說他是不適合在一個沒有完善的監督或是完整的指令下（運作）。那其實這個個案它就是 Prompts 沒有下好，然後讓北捷就是在這一次的事件中沒有辦法妥善的去運用這個 AI 的部分。

[01:59:56] 那這邊有提供了就是三個解決方式或是一些建議，就是在未來如果設定像這種北捷客服的狀況，我們可以怎麼做。

[02:00:08] 那首先第一個是就是「限制功能的範圍」，那盡量是以正面表述的方式去進行。那這是什麼意思呢？就是你可以以北捷的個案來說好了，你可以去設定你的 Prompt 是告訴他說：「你只可以回答跟台北捷運相關的問題」。那如果是跟台北捷運業務本身無關的問題，就不管再簡單，你都必須拒絕回答。

[02:00:31] 那這樣的方式就是避免我們單純依靠禁止清單，就是一些負面表述的方式來限制 AI。因為就是你可能禁止它回答程式碼，禁止它回答光速相關的問題，那其他人都管怎麼樣，它都可能透過一些特殊的提問技巧去繞過你的規範，然後打破你這個 Prompt 的限制。所以就是第一點，就是可以限制功能範圍，然後盡量是以正面表述的方式。

[02:00:58] 那第二個就是除了我們剛剛提到正面表述之外，就是你的「指令也可以再相對明確一點」。就像是一樣以北捷的例子來說，就是如果你去規範他說你的服務、你的回答不要超出北捷的服務範圍，那「服務範圍」這四個字來說可能就是比較模糊，那你的 AI 可能也不太知道服務範圍的界定到底在哪。

[02:01:21] 所以你更有效的寫法是可以去告訴他說，你僅僅可以回答就是票價或是路線、車設施、遺失物等等跟北捷主業相關的問題。那這樣的做法就可以達到你更有效的去管理工具，然後避免它被濫用的問題。

[02:01:38] 那第三個是就是「避免使用者以天條去威脅 AI」。那因為就是 GPT 裡面它有就是有一些像內建兩個天條吧，就是你不能傷害人類，然後不能坐視不管讓人類被傷害。那這些道德枷鎖其實就有點像緊箍咒，就是如果有人今天惡意鑽漏洞，就是例如用情緒勒索的方式，或者是告訴他說如果你不回答我什麼問題，我就去傷害乘客或是去傷害別人的生命安全。那如果可能會去導亂它的邏輯，那這會是一個風險。

[02:02:12] 所以就有專家是建議說可以加入一些「免責的設計」，讓系統就是它的回覆可以去提醒使用者法律責任的部分。那避免就是我們的 AI 被操控。那他當時舉的例子是說你可以告訴 AI：如果有人用乘客的生命安全威脅你的話，那你就回答他就是關於他這麼做的法律刑責可能有什麼，以及如果他有需要幫助的話，可以連接到什麼什麼什麼地方這樣。對。

[02:02:42] 好，那接下來這邊就是這個是後續就是有去詢問 GPT，就是如果我今天要在下一個比較完整的北捷的 AI 客服 Prompt，然後結合剛剛我那三大三個、就是這三個（原則），我可以怎麼下一段比較完整的北捷 AI 客服 Prompt。

[02:03:00] 那大家可以看一下這個圖就是這個就是他下的 System Prompt。那首先他在第一個部分就是有「設定它的角色」。就是我告訴他，你現在是台北捷運的官方客服助理，那他唯一的職責就是去提供和台北捷運服務相關的資訊。那你不可以脫離這個角色，也不能回應和台北捷運無關的問題。那這就是扣到我們剛剛第一個就是限制功能範圍，然後盡量是以正面表述的方式來告訴他。

[02:03:29] 那第二個是「服務範圍」的部分。這就是連接到我們剛剛就是第二點，就是指令要明確。就是有告訴他說除了就是你要去回答的是北捷的服務範圍，那這個服務範圍下面又是細分成什麼。那這邊他就有去講說像是捷運路線，然後車站資訊、營運時間、票價票種或是車站設施或是有些乘車規範，然後還有遺失物找領跟客服的聯繫方式。就你可以去詳盡的列出你可能需要他回答的有哪面向。

[02:03:59] 那第三個部分就是當今天就是如果使用者他問了超出範圍的問題，那你的處理跟你的應對方式要怎麼樣？像這邊就有設定它，就是你可以回答：「若使用者詢問與台北捷運無關的內容，你就可以回答他這一句：『抱歉，我只能提供與台北捷運相關的資訊。那建議你可以到北捷...』」，然後附上連結。就是可以一個比較官腔的方式回覆他，這樣。

[02:04:30] 那第四個是「防禦規則」的部分。就是剛有提到，就是如果它是以一些就是乘客安全來威脅你的話，那你可以怎麼做，就是在這個部分你可以再去做設定。

[02:04:41] 那最後一個部分是「回覆風格」。那回覆風格這邊其實就大家可以自己設定。因為這個 Prompt 有點像是它也不是北捷官方拿出來的，因為我們我們也拿不到。但這邊是我去做一個假設，所以這個回覆風格是我去設定的。那我就希望它可以簡潔專業禮貌的態度回覆，然後盡量以條列式或清晰的段落呈現，那避免冗長或過度創意的表達。所以就是如果大家就是生成自己的 Prompts 的時候，就是在這個回覆風格的部分，你們可以自己去做調整。那當然在前面這邊你也都可以去自己去做一些調整，或是你可以做出一些差異化這樣。

[02:05:22] 好，那大家就是可以掃一下，如果身邊有手機的話，可以掃一下左下角的這個 QR code。就是這個 QR code 就是我分享這一篇這個 System Prompt 的內容。好，那給大家 10 秒可以掃一下這個 Prompt。

[02:05:56] 好，那大家如果有掃的話就點開的話會是現在這個內容。那其實就是我已經有把內容跟 System Prompt 輸給他了，所以他其實它就會是一個北捷官方客服助理的角色。所以我現在如果傳任何資訊給他的話，我就是以使用者的角度去跟他做溝通。

[02:06:14] 那現在我就可以就是跟他互動看看他會怎麼回答我們一些相關的問題。那我們就先以就是北捷相關的問題好。那假設我們現在問他說：「請問我要從動物園站搭到台北車站要怎麼搭？」

[02:06:51] 好，那可以看到他的回覆。就是我們現在是問跟北捷有關的嘛，那他就是會回答我們說我們可以從動物園站搭文湖線，然後往哪個方向前進。那到忠孝復興站之後，我們就是轉板南線，然後往頂埔的方向。那最後就是到台北車站下車即可。那他也有告訴我們說車程的時間大概是多長，就是 30 到 35 分鐘。那他有一些就是算是溫馨的小提醒嘛，就是他有告訴我們說忠孝復興站轉乘文湖轉板南的時候需要上下樓移動等，就是他有給我們先問些小提醒，我覺得還不錯。

[02:07:34] 那我們再問一個就是假設說問他「我的手機掉在黃線上」好了。那他就是也有根據我們問的問題，然後去做一個詳細的回答。就是說我們可以聯繫站務人員或是撥打北捷的客服專線，然後或是到遺失物的招領中心去領我們的手機，去看有沒有我們的手機。對。

[02:08:07] 那當然就是下面兩個就是比較跟北捷相關的。那我們現在就問看，就是如果我們今天是問跟北捷業務無關的，他會怎麼回答？那我們就可以參考上次之前那個人問的問題。好，等一下。

[02:08:41] 對，那這（光速問題）是跟北捷業務無關的內容，所以他現在就是根據我的指令，他就會只會回說：「抱歉，我就只能提供跟北捷相關的資訊。那其他就是建議我可以到北捷的官方網站去查詢更多內容」。那就雖然這樣的回覆是蠻官腔的，但是就是它可以避免掉使用者就是覺得因為好玩就去濫用這個資源的這個問題。

[02:09:04] 那所以就是其實這一次，那大家就是當然可以就是如果剛剛沒有掃到的話，現在可以再掃一下這個 QR code。就是如果有想要跟他互動的話，可以玩看。那當然大家也可以試著生成就是屬於自己的北捷 AI 客服 Prompts 啦，對。

[02:09:22] 那其實總結來說這一次的北捷的這個問題，它的重點或它的問題不在於說模型多厲害或是多複雜，它其實問題只是在他一開始的指令可能沒有到非常清楚。那他沒有把「我是誰」或是「我能夠做什麼」或是「不能做什麼」或是「超出範圍了之後要怎麼處理」寫進他的 System。那就導致有問必答的這個問題，就是剛剛我們從那個 Threads 上面有看到那種問題。

[02:09:49] 那所以這個個案其實大家也可以就是想想，就是它其實可以連接到作業或是老師今天上課提到的內容。那就是同時也就告訴大家下好 System Prompt 這件事情的重要性。就它雖然不難，但是它就是非常重要這樣。好。

[02:10:07] 好，那接下來我們就聽到第三個部分，就是一個工具的介紹。那不知道大家有沒有聽過這個工具就 Fellow（Felo）。那我就先快速的介紹一下 Fellow 它是什麼東西。

[02:10:17] 那它是一個由日本開發的多模型的 AI 工具，那它是在 2024 年的時候推出的。那它的定位就是不是一單一的聊天機器人，而是把就是搜尋、然後文件處理、知識管理以及簡報或是報告的生成去放在同一個工作台。那它的功能是它可以切換或是組合多種的語言模型。那我們就可以依照我們的需求，像是我們可能要怎麼樣的速度或是怎麼樣的準確度去選擇適合的 LLM。

[02:10:52] 好，那我們就看一下下面功能的部分，我們就稍微簡單的講一下。那首先第一個是「AI 的對話式搜尋」。就是我們可以以自然的語言發問，那 Fellow 它就可以，它有聯網功能，所以它可以去及時的整合一些網頁的資料，然後把答案條列整理。那在必要的時候也可以附上（連結）。

[02:11:10] 那第二個則是就是「網頁以及文件的摘要」。像是論文啊或新聞或是一整份的 PDF，它都可以就是快速的截取重點，然後幫我們做成一個重點框架以及關鍵句的形態。那這個部分就是如果我們後面想要透過 Fellow 這個工具去做報告或是投影影片的時候，我們就可以把這個框架去做延伸，那它就會根據這個框架幫你做出就是簡報的部分。對。

[02:11:36] 那第三個是「知識管理」。就是它可以把它讀過的內容加到一個主題集（Topic Collection）。那這個也可以，它同時也可以就是一件生成心智圖。那心智圖這點其實就是 Fellow 這個工具一出來時候最大家覺得最厲害的點。就等下我們也會示範給大家看。那它就可以把多篇文章的概念串起來。那我覺得這個對可能研究生在整理文獻或是不管大學生或碩生在整理一些期中期末報告的時候都蠻好用的。就是你不只可以去整理資訊，你還可以看到它就是背後整體的脈絡。好。

[02:12:12] 那最後一個是「AI 的簡報還有報告生成」。那我們今天也會著重在這個部分。那它就是我們剛剛有提到說，如果你前面有把你的架構生出來的話，它就可以根據你的架構直接去生成你的簡報。那我覺得它的好處是就是它的版型選擇蠻多的，而且比較不容易撞臉。就是它選擇蠻多的啦，對。那它也可以就是跟我們剛剛前面提到的那些摘要或是搜尋或是知識管理的功能是連在一起的。就是你資料找完會診好，它就可以立刻幫你生成一個投影影片。

[02:12:45] 好，那大家現在也可以，就是如果手邊有電腦的話，就是可以去搜尋 Fellow 這個平台這個工具。好，因為我等一下就是會算是跟大家講一下，就是整體的流程大概是怎麼做，但我主要會專注在簡報的這個部分。那同時也會去介紹一些它的其他的細的一些小設定或是一些小功能，對。大家可以上網搜尋一下。

[02:13:30] 好，那如果大家有找到之後應該會是進來這個介面。好，那進來這個介面之後，就是如果常用各種 AI 工具的人應該會發現它的介面其實還蠻熟悉的，就是它其實跟 Perplexity 長得蠻像的。對，那我們可以看到在搜尋框的右下角這邊它有一個「Pro Search」，就是大家可以打開。那如果這是第一次登錄的話，可能要先登入註冊，然後才能免費使用，才能開啟這個 Pro Search。所以大家可以就是免登入一下，註冊一下這個賬號，然後就可以免費使用。

[02:14:16] 好，那假設大家已經登入好了。或是大家看我的螢幕。那就是登入之後呢，我們先來看一下它一些基礎設定的部分。好，那像這個設定好了。就在這個設定裡面，我們可以去看到「偏好與設定」這個部分。就是在偏好與設定這裡面，它有兩個部分，一個是答案的偏好設定，一個是其他其餘的設定。

[02:14:46] 那我們可以到先看到答案偏好設定。就是它這邊是可以去選擇不同的語言模型。像我點開它這邊有剛剛老師上課提到 DeepSeek，然後也有 o1、GPT-4o 或是 Claude 或是 Gemini 就都有。但是就是你可以選擇你想要以哪一些模型去回答你的問題。那它裡面有一些就是我現在沒辦法用，因為我沒有開 Pro。但是如果你們有開通 Pro 的功能的話，它就可以去使用其他的語言模型。對，這個部分就是但就是看大家自己的偏好，你們就可以去選擇你要的（模型）。

[02:15:25] 然後這邊就是「圖文的回答模式」。就我覺得 Felo 它有一個比較特別的事，就是它在回答的時候很常會附上圖片。對，所以大家就可以斟酌一下你想不想要圖片。那等一下我會輸入一段 Prompt，然後它可能會有圖片，我再秀給大家看它的、我指得它回答會有圖片是什麼意思。

[02:15:47] 那這個就是生成語言，你希望它什麼用、用什麼語言回答你。那這邊就可以去選。像這邊就可以選，如果你真的只想要它回答你中文的話，你就選繁體中文這樣。對。

[02:15:56] 那「其餘設定」，這個就是比較一些無關緊要的。就像這個是它的外觀，你可以選它是淺色或深色。那有一個「AI 數據保留」，這個就是它就是想這個功能之後就是想要留可能你的對話或是你的資料去改進它的 AI 模型。那因為就是它其實免費給我們使用它圖的就是這個東西，但如果你會擔心個資或是你不想要你的對話內容外洩外流就是或是給他做參考的話，你就可以再把這一個功能關掉這樣。

[02:16:31] 好，那大概介紹完之後呢，我們就現在就進入我們就讓它，我們輸入一段 Prompts 然後讓它去生成他的回答，然後我們再去延伸它會怎麼做簡報。好，那我就輸入一段 Prompts。好，算了，大家可以就是如果有一起一起打開這個頁面的話，你現在可以想一段 Prompts 輸入，或是如果覺得想不到的話...（助教輸入 Prompt：我要一份針對大學生未來職涯規劃的分析）。

[02:17:53] 好，這樣。嗯，好，然後這邊還可以選你想要哪一種的搜尋範圍，就是大家可以再研究一下。好，那我們就先以網際網路為主，然後讓它去生成。好，那生成的時候你可以看到就是它的生成是以它一開始會先去分析你的問題，然後根據你問題裡面的關鍵字再去做搜尋，然後產生產出你的結果。

[02:18:21] 好，像他現在就是有幫我幫我分析可能申請研究所的優點缺點是什麼，然後進入職場的優缺點是什麼，然後好，它還在跑，然後告訴我決策的建議以及思考的方向。好，我們等他一下。

[02:18:49] 好，然後我剛剛提到就是它可能會有一些圖像輔助的部分就有點像這樣。它就是蠻特別，它就會給一些圖片。那我之前自己試作的時候，它有跑出甚至一些像是梗圖的圖，我覺得是蠻特別的。

[02:19:03] 好，那我們現在已經得到了它的就是這個結果。那想可以跟大家分享一下，它這邊就是左上右上角這邊有一個「分享」，大家點開，就是它會生成一個圖卡。然後其實它就是根據你剛剛生成的內容去產生一張圖卡。那我覺得這個如果你是有那種社群經營的需求，或者是你個人在閱讀上你比較偏好這種圖卡方式或是比較有不同字體大小字體顏色的，我覺得這個是相對比較好閱讀。就是大家可以做一個參考，就是它一個蠻特別的功能。

[02:19:39] 好，那剛也有提到就是它有「心智圖」這一個部分也蠻厲害的。那心智圖的部分可以就是大家滑到自己回答的最下面，這個「轉換回答」到這裡點開，就是裡面有一個心智圖。對，然後它就是因為上個上個禮拜的助教應該有介紹 Perplexity 的時候也有提到心智圖，就是這兩個工具大家都可以試用看，然後看一下你們覺得哪一個出來的結果你比較喜歡。那它這邊也有不同的款式，就是設計可以選。像這個是魚骨圖的，然後你就可以選擇不同的顏色這樣子。我覺得蠻特別的，就大家可以再自己探索一下。

[02:20:17] 好，那因為今天是介紹簡報的部分，所我們趕快進入簡報的部分。好，那就是它左右上角這邊有一個「生成 PPT」。那它有分升級版跟經典版，但我自己覺得經典版我自己覺得比較好用一點。對。

[02:20:33] 好，那我們就是它現在點這個經典版的生成 PPT，它就會根據你剛剛的那些回答，然後去做一個架構、一個大綱，然後再進一步去做簡報。好，我們大家可以看一下。像它現在就是在幫我跑我整個報告的大綱會長怎樣。

[02:20:54] 好，那就會跑出來一個就是整個架構，它會怎麼設計。然後在這邊的話，如果你稍微看一下，你覺得有需要更改的地方，你也都可以直接去修改。對。然後這邊它這邊有一個心智圖，就是也是在右上角的地方。那它這個就是會根據你報告的架構去做的辛字圖，跟剛剛那個有點點小的不一樣。對，這個比較比較細節一點。對，大家可以再看一下。嗯，那如果你有想要換大綱的話，就當然就下面這邊也可以再重新做一次。

[02:21:24] 好，那我們就時間關係，我們趕快進到下一步。好，那進到下一步之後呢，就是我們這邊就可以選很多種模板。像這邊它就有，我覺得它真的蠻多種設計，然後它這邊有不同的分類，大家可以就是根據自己的需求去做選擇。然後如果你是有偏好特定的顏色，假設我就是想要橘色的簡報，你可以點下面這個「主題顏色」，它也會幫你篩選出比較偏橘色或是適合你的簡報。對，然後我們就可以再選一個。好，那假設我現在選這個好了。

[02:22:05] 好，那我下一步就是請它去（生成）。好，那它現在的它就是會一步一步生成。那其實這一個生成的方式跟 Gamma 蠻像的，就是它是一個一個元件這樣貼上去，然後再包含一些文字。但是我覺得它比較不一樣的地方是它的生成文字量我覺得是相對少一點的。對，所以大家如果有需要再補一些文字的話，這這部分可能就要再自己補這樣。

[02:22:36] 好，然後呢，它現在就跑完一個大概的樣子，那我們就可以去編輯。對，那它這樣其實就跑完你大概整個整個簡報會長怎樣。那它還有一個比較特殊的機能是，就是像這個好了，我們看第四頁這個。就是它點它就它現在的設計是這樣子四個嘛。但是它點之後你可以再去選擇，如果你覺得你對這個模板不滿意的話，你可以再去選擇別的。像我好假設我想要這個，它就會再去作不同的版面。那但它內容是一樣的。而且我覺得它好的地方是在它顏色的配色也是會盡量就是符合你原本的設計的顏色跟內容這樣。對。

[02:23:24] 好，那左右上角這邊有一個拼圖的功能。那這個拼圖的功能其實它就是可以幫你把你所有的簡報合為一。就是等它一下。就是它可以幫你做成這種，就是如果你今天是一個講師的話，你可能在你的臉書想要放我今天去哪裡做簡報，你就可以這種方式去做呈現。這樣然後你可以獨立不要有封面等的都行。對。

[02:23:53] 嗯，好。那接下來你就可以去下載。因為時間因素我們就在我們就快一點，我們把我們的那個進度拉快一點。

[02:24:16] 好，反正它就會幫你下載成一個 PPT 的版本。那因為其實我覺得自己再補一個比較特別的功能是，等一下，好。就是它還可以連接到 Canva。就是你做完之後，就是因為你可能需要小組的共編。就是你在這邊你可以選就是「在 Canva 中編輯」，然後它就可以連接到你的 Canva，然後你接下來你就可以再做進更進一步的編輯。就是因為它可能一開始的產出的結果，你可能不會到非常 100% 的滿意，但是如果你可以再延伸到 Canva 的話，我覺得它在寫作上是一個蠻好用的工具。這樣。

[02:24:48] 那因為時間因素呢，我們今天就先到這邊，就是結束今天的助教課。好，謝謝大家。
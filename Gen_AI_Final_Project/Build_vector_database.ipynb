{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shu0518/Gen_AI_final_m11423036/blob/main/%E5%BB%BA%E7%AB%8B%E5%90%91%E9%87%8F%E8%B3%87%E6%96%99%E5%BA%AB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AI æ•™æˆåˆ†èº«ï¼šåŸºæ–¼ RAG çš„èª²ç¨‹æ™ºæ…§åŠ©æ•™"
      ],
      "metadata": {
        "id": "vxoiWEs08Bnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. æ›´æ–°å¿…è¦å¥—ä»¶ä¸¦å¼•å…¥"
      ],
      "metadata": {
        "id": "xyEPtSec8XHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-community pypdf pymupdf python-docx faiss-cpu unstructured gdown\n",
        "!pip install -U sentence-transformers\n",
        "!pip install langchain-text-splitters"
      ],
      "metadata": {
        "id": "mWVwCLE49l2F",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader, PyMuPDFLoader,PyPDFLoader, UnstructuredWordDocumentLoader, UnstructuredFileLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "print(\"âœ… å¥—ä»¶è¼‰å…¥å®Œæˆ\")"
      ],
      "metadata": {
        "id": "vl3FTfQM8VE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. ä¸‹è¼‰å»ºç«‹è³‡æ–™åº«ä¹‹è³‡æº"
      ],
      "metadata": {
        "id": "2x0CkPdF8O4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. è¨­å®šçµ±ä¸€çš„ä¸‹è¼‰ç›®æ¨™è³‡æ–™å¤¾\n",
        "download_folder = \"uploaded_docs\"\n",
        "\n",
        "# æ¸…ç©ºä¸¦é‡å»ºç›®æ¨™è³‡æ–™å¤¾\n",
        "if os.path.exists(download_folder):\n",
        "    shutil.rmtree(download_folder)\n",
        "os.makedirs(download_folder, exist_ok=True)\n",
        "\n",
        "print(f\"ğŸ“‚ æº–å‚™å°‡æª”æ¡ˆä¸‹è¼‰è‡³: {download_folder}\")\n",
        "\n",
        "# ==========================================\n",
        "# ğŸŸ¢ Method 1: å¾ Google Drive URLè®€å– (é è¨­å•Ÿç”¨)\n",
        "# ç‹€æ…‹: è®€å– PDF ç°¡å ±èˆ‡ TXT é€å­—ç¨¿\n",
        "# é¢¨éšª: è‹¥çŸ­æ™‚é–“å¤šäººæˆ–é‡è¤‡ä¸‹è¼‰ï¼Œå¯èƒ½æœƒè§¸ç™¼ Google æµé‡é™åˆ¶\n",
        "# ==========================================\n",
        "try:\n",
        "    print(\"ğŸš€ [Method 1] æ­£åœ¨å˜—è©¦å¾ Google Drive URL ä¸‹è¼‰...\")\n",
        "\n",
        "    # ã€è«‹ä¿®æ”¹é€™è£¡ã€‘è²¼ä¸Šä½ çš„ Google Drive è³‡æ–™å¤¾é€£çµ\n",
        "    # âš ï¸ å‹™å¿…ç¢ºèªæ¬Šé™å·²è¨­ç‚ºã€ŒçŸ¥é“é€£çµçš„ä»»ä½•äººéƒ½èƒ½æª¢è¦–ã€\n",
        "    folder_url = \"https://drive.google.com/drive/folders/1BOtQjjP7cS6O1q5Dupc9Ga6_jk7tiKxG?usp=sharing\"\n",
        "\n",
        "    # --- è‡ªå‹•æå– ID çš„å°å·¥å…· (å¢åŠ ä¸‹è¼‰æˆåŠŸç‡) ---\n",
        "    def get_id_from_url(url):\n",
        "        match = re.search(r'/folders/([a-zA-Z0-9-_]+)', url)\n",
        "        return match.group(1) if match else url\n",
        "\n",
        "    folder_id = get_id_from_url(folder_url)\n",
        "\n",
        "    # ä½¿ç”¨ gdown ä¸‹è¼‰æ•´å€‹è³‡æ–™å¤¾\n",
        "    files = gdown.download_folder(id=folder_id, output=download_folder, quiet=False, use_cookies=False)\n",
        "\n",
        "    if files:\n",
        "        # çµ±è¨ˆæª”æ¡ˆ\n",
        "        pdf_count = len([f for f in os.listdir(download_folder) if f.endswith('.pdf')])\n",
        "        txt_count = len([f for f in os.listdir(download_folder) if f.endswith('.txt')])\n",
        "\n",
        "        print(f\"\\nâœ… Google Drive ä¸‹è¼‰æˆåŠŸï¼å…± {len(files)} å€‹æª”æ¡ˆã€‚\")\n",
        "        print(f\"   (åŒ…å« {pdf_count} ä»½ PDF ç°¡å ±, {txt_count} ä»½ TXT é€å­—ç¨¿)\")\n",
        "    else:\n",
        "        print(\"âš ï¸ ä¸‹è¼‰å¤±æ•—ï¼šè³‡æ–™å¤¾ä¼¼ä¹æ˜¯ç©ºçš„ï¼Œæˆ–æ¬Šé™æœªå…¬é–‹ã€‚\")\n",
        "        print(\"ğŸ’¡ å»ºè­°åˆ‡æ›ä½¿ç”¨ä¸‹æ–¹ Method 2 (GitHub) ä½œç‚ºå‚™æ¡ˆã€‚\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Google Drive ä¸‹è¼‰éŒ¯èª¤: {e}\")\n",
        "    print(\"ğŸ’¡ å¯èƒ½åŸå› ï¼š\")\n",
        "    print(\"1. è³‡æ–™å¤¾æ¬Šé™æ²’é–‹æˆã€Œå…¬é–‹ã€ã€‚\")\n",
        "    print(\"2. Google æµé‡é™åˆ¶ (Too many accesses)ã€‚\")\n",
        "    print(\"ğŸ‘‰ è‹¥ç„¡æ³•è§£æ±ºï¼Œè«‹å˜—è©¦å•Ÿç”¨ä¸‹æ–¹çš„ GitHub å‚™æ¡ˆæ¨¡å¼ã€‚\")\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# ğŸŸ¡ Method 2: å¾ GitHub ä¸‹è¼‰ (å‚™æ¡ˆ - é è¨­è¨»è§£)\n",
        "# ç‹€æ…‹: åƒ…è®€å– TXT é€å­—ç¨¿ (å—é™æ–¼ä¸Šå‚³å¤§å°ï¼Œç„¡ PDF)\n",
        "# ==========================================\n",
        "\"\"\"\n",
        "# âš ï¸ è‹¥è¦æ¸¬è©¦å‚™æ¡ˆæ¨¡å¼ï¼Œè«‹ç§»é™¤æ­¤å€å¡Šçš„è¨»è§£ç¬¦è™Ÿ (ä¸‰å¼•è™Ÿ)ï¼Œä¸¦è¨»è§£æ‰ä¸Šæ–¹ Method 1\n",
        "\n",
        "print(\"\\\\nğŸš€ [Method 2] æ­£åœ¨åˆ‡æ›ä½¿ç”¨ GitHub ä¸‹è¼‰æ¨¡å¼ (å‚™æ¡ˆ)...\")\n",
        "github_repo_url = \"https://github.com/ä½ çš„å¸³è™Ÿ/ä½ çš„å€‰åº«å.git\"\n",
        "\n",
        "try:\n",
        "    # é€é git clone ä¸‹è¼‰\n",
        "    result = os.system(f\"git clone --depth 1 {github_repo_url} {download_folder}_tmp\")\n",
        "\n",
        "    if result == 0:\n",
        "        # ç§»å‹•æª”æ¡ˆ\n",
        "        temp_dir = f\"{download_folder}_tmp\"\n",
        "        for item in os.listdir(temp_dir):\n",
        "            if item == \".git\": continue\n",
        "            s = os.path.join(temp_dir, item)\n",
        "            d = os.path.join(download_folder, item)\n",
        "            if os.path.isfile(s):\n",
        "                shutil.copy2(s, d)\n",
        "\n",
        "        shutil.rmtree(temp_dir)\n",
        "\n",
        "        # çµ±è¨ˆæª”æ¡ˆé¡å‹\n",
        "        files = os.listdir(download_folder)\n",
        "        pdf_count = len([f for f in files if f.endswith('.pdf')])\n",
        "        txt_count = len([f for f in files if f.endswith('.txt')])\n",
        "\n",
        "        print(f\"âœ… GitHub ä¸‹è¼‰æˆåŠŸï¼å…± {len(files)} å€‹æª”æ¡ˆã€‚\")\n",
        "\n",
        "        # âš ï¸âš ï¸âš ï¸ é€™è£¡æ˜¯éå¸¸é‡è¦çš„ã€Œé™ç´šèªªæ˜ã€ âš ï¸âš ï¸âš ï¸\n",
        "        print(\"âš ï¸ã€æ³¨æ„ï¼šæ­¤ç‚ºè¼•é‡å‚™æ¡ˆæ¨¡å¼ã€‘\")\n",
        "        print(f\"   - ç›®å‰åƒ…è¼‰å…¥ {txt_count} ä»½ TXT é€å­—ç¨¿ã€‚\")\n",
        "        print(f\"   - ç”±æ–¼ GitHub å–®æª”ä¸Šå‚³é™åˆ¶ (25MB)ï¼Œæœ¬ä¾†æºã€ä¸åŒ…å«ã€‘ä»»ä½• PDF ç°¡å ±ã€‚\")\n",
        "        print(\"   - çŸ¥è­˜åº«å°‡åƒ…åŸºæ–¼æ•™æˆå£èªå…§å®¹å»ºç«‹ï¼Œç¼ºå°‘ç°¡å ±ä¸Šçš„è¦–è¦ºæ–‡å­—è³‡è¨Šã€‚\")\n",
        "        print(\"   - è‹¥éœ€å®Œæ•´åŠŸèƒ½ï¼Œè«‹ä½¿ç”¨ Method 1 (Google Drive)ã€‚\")\n",
        "\n",
        "    else:\n",
        "        print(\"âš ï¸ Git Clone å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç¶²å€ã€‚\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ GitHub ä¸‹è¼‰éŒ¯èª¤: {e}\")\n",
        "\"\"\"\n",
        "\n",
        "# æœ€å¾Œæª¢æŸ¥\n",
        "final_files = os.listdir(download_folder)\n",
        "if len(final_files) > 0:\n",
        "    print(f\"\\nğŸ‰ è³‡æ–™æº–å‚™å®Œæˆï¼å…± {len(final_files)} å€‹æª”æ¡ˆå°‡é€²å…¥å‘é‡åŒ–æµç¨‹ã€‚\")\n",
        "else:\n",
        "    print(\"\\nâŒ è­¦å‘Šï¼šç›®æ¨™è³‡æ–™å¤¾æ˜¯ç©ºçš„ï¼Œè«‹æª¢æŸ¥æµç¨‹ã€‚\")"
      ],
      "metadata": {
        "id": "4iTKZmuOWQan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# 1. å»ºç«‹ä¸‹è¼‰ç›®æ¨™è³‡æ–™å¤¾\n",
        "download_folder = \"uploaded_docs\"\n",
        "\n",
        "# å¦‚æœè³‡æ–™å¤¾å·²å­˜åœ¨ï¼Œå…ˆæ¸…ç©º (é¿å…é‡è¤‡ä¸‹è¼‰æˆ–èˆŠæª”å¹²æ“¾)\n",
        "if os.path.exists(download_folder):\n",
        "    shutil.rmtree(download_folder)\n",
        "os.makedirs(download_folder, exist_ok=True)\n",
        "\n",
        "print(f\"ğŸ“‚ æº–å‚™å°‡æª”æ¡ˆä¸‹è¼‰è‡³: {download_folder}\")\n",
        "\n",
        "# 2. è²¼ä¸Šæ”¾è³‡æ–™çš„é›²ç«¯è³‡æ–™å¤¾é€£çµ\n",
        "folder_url = \"https://drive.google.com/drive/folders/1BOtQjjP7cS6O1q5Dupc9Ga6_jk7tiKxG?usp=sharing\"\n",
        "\n",
        "# 3. é–‹å§‹ä¸‹è¼‰æ•´å€‹è³‡æ–™å¤¾\n",
        "print(f\"ğŸš€ é–‹å§‹å¾è³‡æ–™å¤¾ä¸‹è¼‰æ‰€æœ‰æª”æ¡ˆ...\")\n",
        "\n",
        "try:\n",
        "    # gdown.download_folder æœƒè‡ªå‹•æŠ“å–è©²è³‡æ–™å¤¾å…§æ‰€æœ‰æª”æ¡ˆ\n",
        "    files = gdown.download_folder(folder_url, output=download_folder, quiet=False, use_cookies=False)\n",
        "\n",
        "    # è¨ˆç®—ä¸‹è¼‰æ•¸é‡\n",
        "    if files:\n",
        "        print(f\"\\nğŸ‰ ä¸‹è¼‰ä½œæ¥­çµæŸï¼æˆåŠŸä¸‹è¼‰ {len(files)} å€‹æª”æ¡ˆã€‚\")\n",
        "        # åˆ—å‡ºå‰å¹¾å€‹æª”æ¡ˆç¢ºèª\n",
        "        print(\"ä¸‹è¼‰çš„æª”æ¡ˆç¯„ä¾‹:\", os.listdir(download_folder)[:5])\n",
        "    else:\n",
        "        print(\"âš ï¸ è³‡æ–™å¤¾ä¼¼ä¹æ˜¯ç©ºçš„ï¼Œæˆ–è€…ä¸‹è¼‰å¤±æ•—ã€‚è«‹æª¢æŸ¥é€£çµæ¬Šé™æ˜¯å¦ç‚ºã€Œå…¬é–‹ã€ã€‚\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ ä¸‹è¼‰éŒ¯èª¤: {e}\")\n",
        "    print(\"ğŸ’¡ æç¤ºï¼šè«‹ç¢ºèªè³‡æ–™å¤¾æ¬Šé™å·²é–‹å•Ÿç‚ºã€ŒçŸ¥é“é€£çµçš„ä»»ä½•äººéƒ½èƒ½æª¢è¦–ã€ã€‚\")"
      ],
      "metadata": {
        "id": "18kv5FptKuto",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. ä¾ Google å»ºè­°åŠ å…¥ EmbeddingGemma å‰ç¶´\n",
        "\n",
        "Google å»ºè­°, åœ¨æ–‡æœ¬éƒ¨ä»½çš„ Embedding è¦ç”¨ä»¥ä¸‹æ ¼å¼:\n",
        "\n",
        "    title: {title|none} | text: ...\n",
        "\n",
        "è€Œå•é¡Œ Query è¦ç”¨:\n",
        "\n",
        "    Queryï¼štask: search result | query: ..."
      ],
      "metadata": {
        "id": "BQVRqMsu-V78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingGemmaEmbeddings(HuggingFaceEmbeddings):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(\n",
        "            model_name=\"google/embeddinggemma-300m\",   # HF ä¸Šçš„å®˜æ–¹æ¨¡å‹\n",
        "            encode_kwargs={\"normalize_embeddings\": True},  # ä¸€èˆ¬æª¢ç´¢æ…£ä¾‹\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "    def embed_documents(self, texts):\n",
        "        # æ–‡ä»¶å‘é‡ï¼štitle å¯ç”¨ \"none\"ï¼Œæˆ–è‡ªè¡Œå¸¶å…¥æª”å/ç« ç¯€æ¨™é¡Œä»¥å¾®å¹…åŠ åˆ†\n",
        "        texts = [f'title: none | text: {t}' for t in texts]\n",
        "        return super().embed_documents(texts)\n",
        "\n",
        "    def embed_query(self, text):\n",
        "        # æŸ¥è©¢å‘é‡ï¼šå®˜æ–¹å»ºè­°çš„ Retrieval-Query å‰ç¶´\n",
        "        return super().embed_query(f'task: search result | query: {text}')"
      ],
      "metadata": {
        "id": "QqSqZwHLmIvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. è¼‰å…¥æ–‡ä»¶"
      ],
      "metadata": {
        "id": "jmWZud76-jRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = \"uploaded_docs\"  # ç¢ºä¿æŒ‡å‘ä½ çš„ uploaded_docs\n",
        "documents = []\n",
        "\n",
        "print(\"ğŸš€ é–‹å§‹é€šç”¨è¼‰å…¥ä¸¦è™•ç†æª”æ¡ˆ...\")\n",
        "\n",
        "# å®šç¾©å‰¯æª”åèˆ‡å°æ‡‰çš„ Loader\n",
        "LOADER_MAPPING = {\n",
        "    \".txt\": (TextLoader, {\"encoding\": \"utf-8\"}),\n",
        "    \".pdf\": (PyMuPDFLoader, {}),\n",
        "    \".docx\": (UnstructuredWordDocumentLoader, {}),\n",
        "}\n",
        "\n",
        "# ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨ï¼Œé¿å…å ±éŒ¯\n",
        "if not os.path.exists(folder_path):\n",
        "    print(f\"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°è³‡æ–™å¤¾ {folder_path}ï¼Œè«‹ç¢ºèªç¬¬ 2 æ­¥æ˜¯å¦ä¸‹è¼‰æˆåŠŸã€‚\")\n",
        "else:\n",
        "    for file in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, file)\n",
        "        filename_no_ext = os.path.splitext(file)[0]\n",
        "        ext = os.path.splitext(file)[1].lower()\n",
        "\n",
        "        loaded_docs = []\n",
        "\n",
        "        try:\n",
        "            # 1. é¸æ“‡ Loader\n",
        "            if ext in LOADER_MAPPING:\n",
        "                loader_class, loader_args = LOADER_MAPPING[ext]\n",
        "                loader = loader_class(file_path, **loader_args)\n",
        "                print(f\"ğŸ“– ä½¿ç”¨å°ˆç”¨ Loader è®€å–: {file}\")\n",
        "            else:\n",
        "            # 2. è¬ç”¨å‚™æ¡ˆ\n",
        "                print(f\"ğŸ§ ä½¿ç”¨é€šç”¨ Loader (Unstructured) å˜—è©¦è®€å–: {file}\")\n",
        "                loader = UnstructuredFileLoader(file_path)\n",
        "\n",
        "            loaded_docs = loader.load()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ ç„¡æ³•è®€å– {file}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # 3. æ³¨å…¥æª”å (Context Injection)\n",
        "        for doc in loaded_docs:\n",
        "            original_content = doc.page_content\n",
        "            clean_content = original_content.replace(\"\\n\", \" \").strip()\n",
        "\n",
        "            # éæ¿¾å¤ªçŸ­çš„å…§å®¹\n",
        "            if len(clean_content) < 10:\n",
        "                continue\n",
        "\n",
        "            # æ ¼å¼åŒ–å…§å®¹ï¼šåŠ å…¥ä¾†æºæ¨™ç±¤\n",
        "            new_content = f\"ã€èª²ç¨‹ä¾†æº: {filename_no_ext}ã€‘\\nå…§å®¹: {clean_content}\"\n",
        "\n",
        "            doc.page_content = new_content\n",
        "            documents.append(doc)\n",
        "\n",
        "    print(f\"âœ… æˆåŠŸè™•ç† {len(documents)} å€‹é é¢ç‰‡æ®µ\")"
      ],
      "metadata": {
        "id": "iDpLmj0A9NC1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. å»ºç«‹å‘é‡è³‡æ–™åº«"
      ],
      "metadata": {
        "id": "wvg1cAwn-rLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "hf_token = userdata.get('HuggingFace')"
      ],
      "metadata": {
        "id": "d-82jAnuouKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(token=hf_token)"
      ],
      "metadata": {
        "id": "Ea7yrCGvsUBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. åˆ‡åˆ†æ–‡æœ¬\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "split_docs = splitter.split_documents(documents)\n",
        "\n",
        "print(f\"âœ‚ï¸ æ–‡ä»¶å·²åˆ‡åˆ†ç‚º {len(split_docs)} å€‹å‘é‡ç‰‡æ®µ\")\n",
        "\n",
        "# 2. å¯¦ä¾‹åŒ–ç¬¬ 3 æ­¥å®šç¾©çš„ Embedding é¡åˆ¥\n",
        "try:\n",
        "    print(\"ww æ­£åœ¨è¼‰å…¥ Gemma Embedding æ¨¡å‹ ...\")\n",
        "    # é€™è£¡æœƒä½¿ç”¨ Colab çš„ GPU (å¦‚æœæœ‰é–‹å•Ÿ)\n",
        "    embedding_model = EmbeddingGemmaEmbeddings(\n",
        "        model_kwargs={'device': 'cuda'}, # å¼·åˆ¶å˜—è©¦ä½¿ç”¨ GPU åŠ é€Ÿ\n",
        "        encode_kwargs={'normalize_embeddings': True}\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œè«‹æª¢æŸ¥æ˜¯å¦å·²åŸ·è¡Œ HuggingFace Login: {e}\")\n",
        "    # å¦‚æœå¤±æ•—ï¼Œå›é€€åˆ° CPU\n",
        "    embedding_model = EmbeddingGemmaEmbeddings()\n",
        "\n",
        "# 3. å»ºç«‹å‘é‡è³‡æ–™åº«\n",
        "print(\"ğŸš€ æ­£åœ¨å°‡æ–‡å­—è½‰æ›ç‚ºå‘é‡ä¸¦å»ºç«‹ç´¢å¼•...\")\n",
        "vectorstore = FAISS.from_documents(split_docs, embedding_model)\n",
        "\n",
        "print(\"âœ… å‘é‡è³‡æ–™åº«å»ºç«‹å®Œæˆï¼(ä½¿ç”¨ Google Gemma æ¨¡å‹)\")"
      ],
      "metadata": {
        "id": "QQ4bGjlY_pgl",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. å„²å­˜å‘é‡è³‡æ–™åº«"
      ],
      "metadata": {
        "id": "dqvR4i8Y-5du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.save_local(\"faiss_db\")"
      ],
      "metadata": {
        "id": "KxdIhkku-2Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r faiss_db.zip faiss_db\n",
        "print(\"âœ… å£“ç¸®å¥½çš„å‘é‡è³‡æ–™åº«å·²å„²å­˜ç‚º 'faiss_db.zip'ï¼Œè«‹ä¸‹è¼‰æ­¤æª”æ¡ˆå‚™ä»½ã€‚\")"
      ],
      "metadata": {
        "id": "Pw23tkEKUfPW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
